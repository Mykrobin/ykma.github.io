<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>A FULLY HOMOMORPHIC ENCRYPTION SCHEME</title>
    <url>/2020/08/13/A-FULLY-HOMOMORPHIC-ENCRYPTION-SCHEME/</url>
    <content><![CDATA[]]></content>
      <tags>
        <tag>TODO</tag>
      </tags>
  </entry>
  <entry>
    <title>AOS-LEC-11-Scalable-Synchronization</title>
    <url>/2021/07/06/AOS-LEC-11-Scalable-Synchronization/</url>
    <content><![CDATA[<h2 id="多核VS对称多处理器"><a href="#多核VS对称多处理器" class="headerlink" title="多核VS对称多处理器"></a>多核VS对称多处理器</h2><p><img src="https://cdn.jsdelivr.net/gh/LavaBeastMurfitt/cdn/images/aos-slide-11-01-SMP.png" alt=""></p>
<h2 id="NUMA架构"><a href="#NUMA架构" class="headerlink" title="NUMA架构"></a>NUMA架构</h2><p><img src="https://cdn.jsdelivr.net/gh/LavaBeastMurfitt/cdn/images/aos-slide-11-01-NUMA.png" alt=""></p>
]]></content>
      <tags>
        <tag>THU-AOS</tag>
      </tags>
  </entry>
  <entry>
    <title>Advice for PhD</title>
    <url>/2021/02/17/Advice-for-PhD/</url>
    <content><![CDATA[<h3 id="Twenty-things-for-the-start-of-PhD"><a href="#Twenty-things-for-the-start-of-PhD" class="headerlink" title="Twenty things for the start of PhD"></a>Twenty things for the start of PhD</h3><p>Recent PhD graduate Lucy A. Taylor shares the advice she and her colleagues wish they had received.</p>
<p>This is an article [<a href="https://www.nature.com/articles/d41586-018-07332-x" target="_blank" rel="noopener">1</a> ] from the Nature Careers Community, the authors share their professional experiences and advice. </p>
<h4 id="1-保持生活和科研工作之间的平衡"><a href="#1-保持生活和科研工作之间的平衡" class="headerlink" title="1. 保持生活和科研工作之间的平衡"></a>1. 保持生活和科研工作之间的平衡</h4><p>Maintain a healthy work–life balance by finding a routine that works for you. It’s better to develop a good balance and work steadily throughout your program than to work intensively and burn out. Looking after yourself is key to success.</p>
<h4 id="2-多与导师交流自己的需求"><a href="#2-多与导师交流自己的需求" class="headerlink" title="2. 多与导师交流自己的需求"></a>2. 多与导师交流自己的需求</h4><p>Discuss expectations with your supervisor. Everyone works differently. Make sure you know your needs and communicate them to your supervisor early on, so you can work productively together.</p>
<h4 id="3-尽可能多的投入时间阅读经典文献综述"><a href="#3-尽可能多的投入时间阅读经典文献综述" class="headerlink" title="3. 尽可能多的投入时间阅读经典文献综述"></a>3. 尽可能多的投入时间阅读经典文献综述</h4><p>Invest time in literature reviews. These reviews, both before and after data collection, help you to develop your research aims and conclusions.</p>
<h4 id="4-早点确定目标"><a href="#4-早点确定目标" class="headerlink" title="4. 早点确定目标"></a>4. 早点确定目标</h4><p>Decide on your goals early. Look at your departmental guidelines and then establish clear PhD aims or questions on the basis of your thesis requirements. Goals can change later, but a clear plan will help you to maintain focus.</p>
<h4 id="5-好记性不如烂笔头，记录需要做和做过的所有事"><a href="#5-好记性不如烂笔头，记录需要做和做过的所有事" class="headerlink" title="5. 好记性不如烂笔头，记录需要做和做过的所有事"></a>5. 好记性不如烂笔头，记录需要做和做过的所有事</h4><p> “I don’t need to write that down, I’ll remember it” is the biggest lie you can tell yourself! Write down everything you do — even if it doesn’t work. This includes meeting notes, method details, code annotations, among other things.</p>
<h4 id="6-整理工作和工作地点、文件和各种记录"><a href="#6-整理工作和工作地点、文件和各种记录" class="headerlink" title="6. 整理工作和工作地点、文件和各种记录"></a>6. 整理工作和工作地点、文件和各种记录</h4><p>Organize your work and workspace. In particular, make sure to use meaningful labels, so you know what and where things are. Organizing early will save you time later on.</p>
<h4 id="7-尽早着手论文"><a href="#7-尽早着手论文" class="headerlink" title="7. 尽早着手论文"></a>7. 尽早着手论文</h4><p>It’s never too early to start writing your thesis. Write and show your work to your supervisor as you go — even if you don’t end up using your early work, it’s good practice and a way to get ideas organized in your head.</p>
<h4 id="8-把毕业论文打散为SMART五部分"><a href="#8-把毕业论文打散为SMART五部分" class="headerlink" title="8. 把毕业论文打散为SMART五部分"></a>8. 把毕业论文打散为SMART五部分</h4><p>Specific 明确工作内容</p>
<p>Measurement  可衡量工作量</p>
<p>Attainable  可实现的工作</p>
<p>Relevant  相关工作</p>
<p>Timely  需要及时做的工作</p>
<p> Break your thesis down into SMART (specific, measurable, attainable, relevant and timely) goals. You will be more productive if your to-do list reads “draft first paragraph of the results” rather than “write chapter 1”. Many small actions lead to one complete thesis.</p>
<h4 id="9-完成比完美更重要"><a href="#9-完成比完美更重要" class="headerlink" title="9. 完成比完美更重要"></a>9. 完成比完美更重要</h4><p>The best thesis is a finished thesis. No matter how much time you spend perfecting your first draft, your work will come back covered in corrections, and you will go through more drafts before you submit your final version. Send your drafts to your supervisor <a href="http://blogs.nature.com/naturejobs/2018/07/09/done-is-better-than-perfect-overcoming-phd-perfectionism/" target="_blank" rel="noopener">sooner rather than later</a>.</p>
<h4 id="10-对导师诚实"><a href="#10-对导师诚实" class="headerlink" title="10. 对导师诚实"></a>10. 对导师诚实</h4><p>Be honest with your supervisor. Let them know if you don’t understand something, if you’ve messed up an experiment or if they forgot to give you feedback. The more honest you are, the better your relationship will be. Helping your supervisor to help you is key.</p>
<h4 id="11-备份！"><a href="#11-备份！" class="headerlink" title="11. 备份！"></a>11. 备份！</h4><p> Back up your work! You can avoid many tears by doing this at least weekly.</p>
<h4 id="12-和实验室其他成员多交流"><a href="#12-和实验室其他成员多交流" class="headerlink" title="12. 和实验室其他成员多交流"></a>12. 和实验室其他成员多交流</h4><p>Socialize with your lab group and other students. It’s a great way to discuss PhD experiences, get advice and help, improve your research and make friends.</p>
<h4 id="13-参加其他实验室的组会，开阔视野"><a href="#13-参加其他实验室的组会，开阔视野" class="headerlink" title="13. 参加其他实验室的组会，开阔视野"></a>13. 参加其他实验室的组会，开阔视野</h4><p>Attend departmental seminars and lab-group meetings, even (or especially) when the topic is not your area of expertise. What you learn could change the direction of your research and career. Regular attendance will also be noticed.</p>
<h4 id="14-展示个人的工作"><a href="#14-展示个人的工作" class="headerlink" title="14. 展示个人的工作"></a>14. 展示个人的工作</h4><p>Present your research. This can be at lab-group meetings, conferences and so on. Presenting can be scary, but it gets easier as you practise, and it’s a fantastic way to network and get feedback at the same time.</p>
<h4 id="15-尝试发表个人的工作"><a href="#15-尝试发表个人的工作" class="headerlink" title="15. 尝试发表个人的工作"></a>15. 尝试发表个人的工作</h4><p>Aim to publish your research. It might not work out, but drafting articles and submitting them to journals is a great way to learn new skills and enhance your CV.</p>
<h4 id="16-抓住机会离开实验室，-出去运动放松"><a href="#16-抓住机会离开实验室，-出去运动放松" class="headerlink" title="16. 抓住机会离开实验室， 出去运动放松"></a>16. 抓住机会离开实验室， 出去运动放松</h4><p>Have a life outside work. Although your lab group is like your work family, it’s great for your mental health to be able to escape work. This could be through sport, clubs, hobbies, holidays or spending time with friends.</p>
<h4 id="17-不与别人比较"><a href="#17-不与别人比较" class="headerlink" title="17. 不与别人比较"></a>17. 不与别人比较</h4><p>Don’t compare yourself with others. Your PhD is an opportunity to conduct original research that reveals new information. As such, all PhD programmes are different. You just need to do what works for you and your project.</p>
<h4 id="18-研究不是一路顺分顺水的"><a href="#18-研究不是一路顺分顺水的" class="headerlink" title="18. 研究不是一路顺分顺水的"></a>18. 研究不是一路顺分顺水的</h4><p>The nature of research means that things will not always go according to plan. This does not mean you are a bad student. Keep calm, take a break and then carry on. Experiments that fail can still be written up as part of a successful PhD.</p>
<h4 id="19-向导师求助，别自己死磕"><a href="#19-向导师求助，别自己死磕" class="headerlink" title="19. 向导师求助，别自己死磕"></a>19. 向导师求助，别自己死磕</h4><p>Never struggle on your own. Talk to other students and have frank discussions with your supervisor. There’s no shame in asking for help. You are not alone.</p>
<h4 id="20-享受博士生涯"><a href="#20-享受博士生涯" class="headerlink" title="20. 享受博士生涯"></a>20. 享受博士生涯</h4><p>Enjoy your PhD! It can be tough, and there will be days when you wish you had a ‘normal’ job, but PhDs are full of wonderful experiences and give you the opportunity to work on something that fascinates you. Celebrate your successes and enjoy yourself.</p>
<h4 id="21-导师分享三篇重要文章"><a href="#21-导师分享三篇重要文章" class="headerlink" title="21.导师分享三篇重要文章"></a>21.导师分享三篇重要文章</h4><p><a href="https://mp.weixin.qq.com/s/Dd_AIcEGdpOXE8A3U9LNwg" target="_blank" rel="noopener">一个华科研究生导师的肺腑之言</a> [2]</p>
<p><a href="http://www.cs.columbia.edu/~nieh/teaching/e6118_s04/papers/1_22_redell_good-paper.html" target="_blank" rel="noopener">How to write a good system paper</a> [3]</p>
<p><a href="https://www.recg.org/writing.html" target="_blank" rel="noopener">Tips about writeing system papers</a> [4]</p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>[1]  <a href="https://www.nature.com/articles/d41586-018-07332-x" target="_blank" rel="noopener">https://www.nature.com/articles/d41586-018-07332-x</a></p>
<p>[2] <a href="https://mp.weixin.qq.com/s/Dd_AIcEGdpOXE8A3U9LNwg" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/Dd_AIcEGdpOXE8A3U9LNwg</a></p>
<p>[3] <a href="http://www.cs.columbia.edu/~nieh/teaching/e6118_s04/papers/1_22_redell_good-paper.html" target="_blank" rel="noopener">http://www.cs.columbia.edu/~nieh/teaching/e6118_s04/papers/1_22_redell_good-paper.html</a></p>
<p>[4] <a href="https://www.recg.org/writing.html" target="_blank" rel="noopener">https://www.recg.org/writing.html</a></p>
]]></content>
      <tags>
        <tag>essay</tag>
      </tags>
  </entry>
  <entry>
    <title>Amazon Aurora: Design Considerations for High Throughput Cloud-Native Relational Databases</title>
    <url>/2020/05/15/Amazon-Aurora-Design-Considerations-for-High%20Throughput%20Cloud-Native%20Relational%20Databases/</url>
    <content><![CDATA[<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">序号</th>
<th style="text-align:center">属性</th>
<th style="text-align:center">内容</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">原文PDF</td>
<td style="text-align:center"><a href="https://dl.acm.org/doi/epdf/10.1145/3035918.3056101" target="_blank" rel="noopener">Aurora</a></td>
</tr>
<tr>
<td style="text-align:center">2</td>
<td style="text-align:center">作者信息</td>
<td style="text-align:center">Amazon</td>
</tr>
<tr>
<td style="text-align:center">3</td>
<td style="text-align:center">核心内容</td>
<td style="text-align:center">分布式数据库</td>
</tr>
<tr>
<td style="text-align:center">4</td>
<td style="text-align:center">研究领域</td>
<td style="text-align:center">数据库</td>
</tr>
<tr>
<td style="text-align:center">5</td>
<td style="text-align:center">全文总览</td>
<td style="text-align:center">致力于构建一个分布式数据库</td>
</tr>
</tbody>
</table>
</div>
<h3 id="0-研究背景-为什么出现Aurora？"><a href="#0-研究背景-为什么出现Aurora？" class="headerlink" title="0 研究背景 为什么出现Aurora？"></a>0 研究背景 为什么出现Aurora？</h3><p>    Aurora是亚马逊云服务AWS中的关系型数据库服务，主要面向OLTP场景。 <strong>Aurora</strong>基本设计理念是在云上环境下，数据库的最大瓶颈不再是计算或者存储资源，而是网络，因此基于一套存储计算分离架构，将日志处理下推到分布式存储层，通过架构上的优化来解决网络瓶颈。 </p>
<p>    在云上环境下，存储计算分离作为解决系统弹性和伸缩性的方案越来越普遍。广义来说，任何数据库，底下文件系统挂一个分布式存储，即可以认为做到了存储计算分离。通过存储计算分离，可以透明添加存储节点，剔除故障节点，进行故障切换，扩展存储空间等。在这个背景下，IO不再成为数据库的瓶颈，因为IO压力可以打散在多个存储节点上，反而是<strong>网络成为瓶颈</strong>，因为数据库实例与所有存储节点的交互都需要通过网络，尤其是为了提升数据库性能，数据库实例与存储节点可能是并行交互的，这进一步加重了网络压力。</p>
<p>    传统数据库中的IO操作是需要同步执行的，当需要进行IO等待时，这往往会导致线程上下文切换，影响数据库性能。比如IO读操作，当需要访问一个数据页时，如果在缓冲池没有命中，则需要进行磁盘IO，那么读线程需要等待IO完成才能继续其它操作，同时这种动作可能会进一步引发刷脏页等。另外一个我们熟悉场景是事务提交操作(IO写操作)，事务提交成功返回前一定要等待事务对应日志刷盘才能返回，由于事务是串行提交，因此其它事务也必须同步等待这个事务提交。 <strong>传统数据库中的两阶段事务尤其不适合与分布式云环境，因为二阶段提交协议对系统中参与的节点和网络要求很高，自身容错能力有限，这点与大规模分布式云环境中，软件和硬件故障是常态的特征是矛盾的。</strong></p>
<p>    本文介绍的Aurora是一个云上环境全新的数据库服务可以很好的解决上述传统数据库遇到的问题。 <strong>它基于存储计算分离的架构，并将回放日志部分下推到分布式存储层，存储节点与数据库实例(计算节点)松耦合，并包含部分计算功能。</strong> Aurora体系下的数据库实例仍然包含了大部分核心功能，比如查询处理，事务，锁，缓存管理，访问接口和undo日志管理等；但redo日志相关的功能已经下推到存储层，包括日志处理，故障恢复，备份还原等。</p>
<h3 id="1-面临问题"><a href="#1-面临问题" class="headerlink" title="1 面临问题"></a>1 面临问题</h3><p>  在云环境中，将存储和计算分离已经成为解决系统弹性和可伸缩性的方案。实现存储计算分离，可以进行故障切换，扩展存储空间等。因此磁盘IO压力可以打散在多个存储节点上，所以IO不再成为数据库的瓶颈。存储和计算分离之后，数据库实例与所有存储节点的交互都需要通过网络，加重了网络带宽压力，从而网络成为瓶颈。</p>
<h3 id="2-问题带来的挑战"><a href="#2-问题带来的挑战" class="headerlink" title="2 问题带来的挑战"></a>2 问题带来的挑战</h3><p>  在云环境中数据库的瓶颈不再是计算或者是资源存储，而是网络。基于此，Aurora设计了存储和计算分离的架构，与传统数据库相比较，这些问题带来的挑战如下。</p>
<p>  传统数据库中的IO操作是需要同步执行的，当需要进行IO等待时，这往往会导致线程上下文切换，影响数据库性能。如IO读操作，当需要访问一个数据页时，如果在缓冲池没有命中，则需要进行磁盘IO，那么读线程需要等待IO完成才能继续其它操作，同时这种动作可能会进一步引发刷脏页等。云环境中的IO操作与传统数据库中的操作是不同的，这带来了IO操作的挑战。</p>
<p>  事务提交操作，事务提交成功返回前一定要等待事务对应日志刷盘才能返回，由于事务是串行提交，因此其它事务也必须同步等待这个事务提交。传统数据库中的两阶段事务尤其不适合与分布式云环境，因为二阶段提交协议对系统中参与的节点和网络要求很高，自身容错能力有限，这点与大规模分布式云环境中，软件和硬件故障是常态的特征是矛盾的，这又是一大挑战。</p>
<h3 id="3-解决方法"><a href="#3-解决方法" class="headerlink" title="3 解决方法"></a>3 解决方法</h3><p>  Aurora是一个云上环境全新的数据库服务可以很好的解决上述问题带来的挑战。它基于存储计算分离的架构，并将回放日志部分下推到分布式存储层，存储节点与数据库实例(计算节点)松耦合，并包含部分计算功能。Aurora体系下的数据库实例仍然包含了大部分核心功能，但redo日志相关的功能已经下推到存储层，包括日志处理，故障恢复，备份还原等。</p>
<h5 id="3-1-数据存储"><a href="#3-1-数据存储" class="headerlink" title="3.1 数据存储"></a><strong>3.1</strong> <strong>数据存储</strong></h5><p>  Aurora存储层的复制基于Quorum协议，假设复制拓扑中有V个节点，每个节点有一个投票权，读或写必须拿到Vr 或 Vw个投票才能返回。为了满足一致性，需要满足两个条件，首先Vr + Vw &gt; V，这个保证了每次读都能读到拥有最新数据的节点；第二，Vw &gt; V/2，每次写都要保证能获取到上次写的最新数据，避免写冲突。</p>
<p>  结合Quorum模型，V=6 ，Vw=4，Vr=3，Aurora可以容忍任何一个AZ出现故障，不会影响写服务；任何一个AZ出现故障，以及另外一个AZ中的一个节点出现故障，不会影响读服务且不会丢失数据。通过Quorum协议，Aurora可以保证只要AZ级别的故障(火灾，洪水，网络故障)和节点故障(磁盘故障，掉电，机器损坏)不同时发生，就不会破坏协议本身，数据库可用性和正确性就能得到保证。</p>
<h5 id="3-2-日志即数据"><a href="#3-2-日志即数据" class="headerlink" title="3.2 日志即数据"></a><strong>3.2</strong> <strong>日志即数据</strong></h5><p>  以MySQL为例，考虑主备复制，如图1所示，AZ1和AZ2分别部署一个MySQL实例做同步镜像复制，底层存储采用EBS，并且每个EBS还有自己的一份镜像，另外部署S3进行redo日志和binlog日志归档，以支持基于时间点的恢复。每个步骤都需要传递5种类型的数据，包括redo，binlog，data-page，double-write和frm元数据。图中的1，3，5步骤是顺序的，要进行4次网络IO，且其中3次是同步串行的。从存储角度来看，数据在EBS上存了4份，需要4份都写成功才能返回。所以在这种架构下，无论是IO量还是串行化模型都会导致性能损耗。</p>
<p><img src="/2020/05/15/Amazon-Aurora-Design-Considerations-for-High%20Throughput%20Cloud-Native%20Relational%20Databases/1.png" width="300px" height="300px"></p>
<p>                     图1. Mirrored MySQL写操作流程</p>
<p>  在Aurora中，所有的写类型只有一种，那就是redo日志。修改一个数据页，会同步产生对应的redo日志。事务提交时，需要事务对应的redo日志都落盘成功后才能返回。存储节点接收redo日志，基于旧版本数据页回放日志，可以得到新版本的数据页。为了避免每次都从头开始回放数据页变更产生的redo日志，存储节点会定期物化数据页版本。Aurora由跨AZ的一个主实例和多个副本实例组成，主实例与副本实例或者存储节点间只传递redo日志和元信息。主实例并发向6个存储节点和副本实例发送日志，当4/6的存储节点应答后，则认为日志已经持久化。传统数据库宕机重启后，恢复从最近的一个检查点开始，读取检查点后的所有redo日志进行回放，确保已经提交的事务对应的数据页得到更新。</p>
<p>  在Aurora中，redo日志相关的功能下推到存储层，回放日志的工作可以一直在后台做。真正进行故障恢复时，需要做的事情很少，所以故障恢复的速度非常快。Aurora存储服务设计的一个关键原则是减少前台用户写的响应时间，因此将尽可能多的操作移到后台异步执行，并且存储节点会根据前台的请求压力，自适应分配资源做不同的工作。对于Aurora而言，分离的存储服务层使得后台线程推进检查点动作完全不影响数据库实例，并且是推进地越快，越有利于前台的磁盘IO读操作。Aurora写基于Quorum模型，存储分片后，按片达成多数即可返回，由于分布足够离散，少数的磁盘IO压力大也不会影响到整体的写性能。</p>
<p><img src="/2020/05/15/Amazon-Aurora-Design-Considerations-for-High%20Throughput%20Cloud-Native%20Relational%20Databases/2.png" width="400px" height="300px"></p>
<p>如上图所示，图中详细介绍了主要的写流程，</p>
<p>1).存储节点接收数据库实例的日志，并追加到内存队列；</p>
<p>2).将日志在本地持久化成功后，给实例应答；</p>
<p>3).按分片归类日志，并确认丢失了哪些日志；</p>
<p>4).与其它存储节点交互，填充丢失的日志；</p>
<p>5).回放日志生成新的数据页；</p>
<p>6).周期性地备份数据页和日志到S3系统；</p>
<p>7).周期性地回收过期的数据页版本；</p>
<p>8).周期性地对数据页进行CRC校验。</p>
<p>  上述所有写相关的操作，只有第1)和第2)步是串行同步的，会直接影响前台请求的响应时间，其它操作都是异步的。</p>
<h4 id="3-3-事务提交"><a href="#3-3-事务提交" class="headerlink" title="3.3 事务提交"></a><strong>3.3</strong> <strong>事务提交</strong></h4><p>  在Aurora中，数据库实例向存储节点传递redo日志，达成多数派后将事务标记为提交状态，然后推进VDL，使数据库进入一个新的一致状态。每个事务的每条redo日志都会分配一个唯一的LSN，这个LSN一定大于当前最新的VDL。由于底层存储按segment分片，每个分片管理一部分页面，当一个事务涉及的修改跨多个分片时，事务对应的日志被打散，每个分片只能看到这个事务的部分日志。为了确保各个分片日志的完整性，每条日志都记录前一条日志的链接，通过前向链接确保分片拥有了完整的日志。Segment Complete LSN(SCL)表示分片拥有完整日志的位点，存储节点相互间通过gossip协议来弥补本地日志空洞，推进SCL。</p>
<p>  在Aurora中，事务提交是完全异步的。每个事务由若干个日志组成，并包含有一个唯一的“commit LSN”，工作线程处理事务提交请求时，将事务相关的日志提交到持久化队列并将事务挂起，并继续处理其它数据库请求。当VDL的位点大于事务的LSN时，表示这个事务redo日志都已经持久化，可以向客户端回包，通知事务已经成功执行。在Aurora中，有一个独立的线程处理事务成功执行的回包工作，因此，从整个提交流程来看，所有工作线程不会因为事务提交等待日志推进而堵塞，他们会继续处理新的请求，通过这种异步提交方式，大大提高了系统的吞吐。</p>
<h4 id="3-4-故障恢复"><a href="#3-4-故障恢复" class="headerlink" title="3.4 故障恢复"></a><strong>3.4</strong> <strong>故障恢复</strong></h4><p>  大多数数据库系统通常会周期性地做检查点，并将检查点信息计入日志。故障时，数据页中同时可能包含了提交和未提交的数据，因此，在故障恢复时，系统首先需要从上一个检查点开始回放日志，将数据页恢复到故障时的状态，然后根据undo日志回滚未交事务。从故障恢复的过程来看，故障恢复是一个比较耗时的操作，并且与检查点操作频率强相关。通过提高检查点频率，可以减少故障恢复时间，但是这直接会影响系统处理前台请求吞吐，所以需要在检查点频率和故障恢复时间做一个权衡，而在Aurora中不需要做这种权衡。</p>
<p>  Aurora将回放日志逻辑下推到存储节点，并且在数据库在线提供服务时在后台常态运行。因此，当出现故障重启时，存储服务能快速恢复。数据库实例宕机重启后，需要故障恢复来获得运行时的一致状态，实例与仲裁协议确定的N个存储节点通信，这样确保能读到最新的数据，并重新计算新的VDL，超过VDL部分的日志都可以被截断丢弃。在Aurora中，对于新分配的LSN范围做了限制，这个主要是为了避免数据库实例上堆积过多的未提交事务。</p>
<h3 id="4-实验验证"><a href="#4-实验验证" class="headerlink" title="4 实验验证"></a>4 实验验证</h3><p>  本文的实验对Aurora的读写能力，吞吐量大小，以及部署后用户的使用数据对Aurora进行了分析。</p>
<p>  从sysbench测试的数据来看，Aurora是基于镜像MySQL吞吐能力的35倍，每个事务的日志量比基于镜像MySQL日志量要少7.7倍。从用户的使用数据来看，某游戏公司使用后web应用响应时间明显降低，由之前的15ms降低到5.5ms,性能提高了近3倍，而且时间延迟明显降低。</p>
<p>  基于实验验证，Aurora相对于传统数据库的优势如下：</p>
<p>  第一，底层数据库存储是一个分布式存储服务，可以轻松应对故障；</p>
<p>  第二，数据库实例往底层存储层只写redo日志，因此数据库实例与存储节点之间的网络压力大大减小，这为提升数据库性能提供了保障；</p>
<p>  第三，将部分核心功能(故障恢复，备份还原)下推到存储层，这些任务可以在后台不间歇地异步执行，并且不影响前台用户任务。</p>
<h3 id="5-相关工作"><a href="#5-相关工作" class="headerlink" title="5 相关工作"></a>5 相关工作</h3><p>  本文的相关工作主要是在分布式存储的将存储与计算解耦、分布式系统、并发控制、日志结构的存储与数据恢复等几个方面分别进行描述的。在描述的过程中，首先通过对Aurora面临的问题进行逐个层面的分析，并对相关工作进行总结，在分析之后，将已有工作与Aurora相结合，并通过Aurora与先有工作进行比较说明，进一步阐述Aurora的实现原理。</p>
<p>  将存储与计算解耦：在此处本文提出与传统系统通常作为整体不同的数据库系统，介绍了有一些关于将内核分解为不同组件的数据库的研究。Deuteronomy 将提供并发控制和恢复的事务组件（TC）与提供LLAMA访问方法的数据组件（DC）分开，结构化缓存和存储管理器。Sinfonia和Hyder是在横向扩展服务上抽象事务访问方法的系统，并且可以使用这些抽象来实现数据库系统。Yesquel系统实现了多版本分布式平衡树，并将并发控制与查询处理器分离。在Aurora中，将查询处理、事务、并发、缓冲区高速缓存和访问方法与作为横向扩展服务实现的日志记录，存储和恢复分离。</p>
<p>  分布式系统：首先指出已经证明过的Brewer CAP定理，指出高度可用的系统无法在存在网络分区的情况下提供“强”的一致性保证。这个结果激发了作者对一致性目标的追求。并对相关工作进行总结，Bailis等人研究了提供高可用事务（HATs）的问题，该事务既不会在分区期间遭受不可用，也不会导致高网络延迟。他们表明可串行性，快照隔离和可重复读取隔离不符合HAT的要求，而大多数其他隔离级别都可以通过高可用性实现。Aurora通过简化假设，即在任何时候只有一个写入器使用从单个有序域分配的LSN生成日志更新来提供所有这些隔离级别。Google的Spanner提供外部一致的读写操作，并在一个时间戳上跨数据库提供全局一致的读取信息。这些功能使Spanner支持一致的备份，一致的分布式查询处理以及原子模式更新，所有这些都是在全球范围内进行的，甚至在正在进行的事务存在的情况下也是如此。Spanner专门针对Google的繁重工作负载，并依靠两阶段提交和两阶段锁定来进行读/写事务。</p>
<p>  并发控制：本文指出较弱的一致性和隔离模型在分布式数据库中是众所周知的，并导致了乐观的复制技术以及最终的一致性系统。集中式系统中的其他方法包括基于锁定的经典悲观方案，Hekaton中的多方案并发控制之类的乐观方案，VoltDB等分片方法和HyPer中的时间戳排序和Deuteronomy . Aurora的存储服务为数据库引擎提供了持久保留的本地磁盘的抽象，并允许引擎确定隔离和并发控制。</p>
<p>  日志结构存储：先介绍日志结构的起源，日志结构的存储系统由LFS 在1992年引入。并对最近的日志结构存储的相关工作进行总结，Deuteronomy 以及LLAMA 和Bw-Tree 的相关工作在存储引擎堆栈中以多种方式使用日志结构化技术。最后对本文提出的Aurora与Deuteronomy 进行横向比较说明。Aurora，通过编写增量而不是整个页面来减少写放大，Deuteronomy 和Aurora都实现纯重做日志记录，并跟踪最高稳定的LSN以确认提交。</p>
<p>  恢复：尽管传统数据库依赖于基于ARIES 的恢复协议，但是一些最近的系统已经选择了其他途径来提高性能。例如，Hekaton和VoltDB在崩溃后使用某种形式的更新日志来重建其内存状态。像Sinfonia这样的系统通过使用诸如进程对和状态机复制之类的技术来避免恢复。Graefe 描述了一种具有每页日志记录链的系统，该系统可以按需进行逐页重做，从而可以快速恢复。与Aurora一样，Deuteronomy 不需要重做恢复。这是因为Deuteronomy 会延迟事务，因此只有已提交的更新才会发布到持久存储中。结果，与Aurora不同，Deuteronomy 中的交易规模可能受到限制。</p>
<h3 id="6-总结建议"><a href="#6-总结建议" class="headerlink" title="6 总结建议"></a>6 总结建议</h3><p>  在计算与存储分离的云基础设施之上，通过仅传输redo log，大幅减少跨网络的IO数据传输，将产生大量IO的数据页合并和持久化交由本地存储来解决，大幅减缓了网络延迟对数据库性能的影响。即使网络传输的速度不再是分布式数据库的瓶颈，这种“日志即数据“的思想也是有意义的，因为在分布式数据库中的计算，存储，网络中，网络通信的功耗是最大的。</p>
<p>  Aurora诞生的原因是在弹性伸缩的云环境下，传统的高吞吐<strong>OLTP</strong>数据库既不能保证可用性，又不能保证持久性。 <strong>Aurora</strong>的关键点在于将传统数据库中的存储与计算分离，具体而言，将日志部分下推到一个独立的分布式存储服务层。由于这种分离架构下，所有IO操作都是通过网络，网络将成为最大的瓶颈，因此Aurora集中精力优化网络以便提高系统吞吐能力。Aurora依靠Quorum模型，在性能影响可控的前提下，解决云环境下的各种异常错误。在Aurora中，日志处理技术减少了I/O写放大，异步提交协议避免了同步等待，同时分离的存储服务层还避免了离线故障恢复和检查点操作。</p>
<p>   Aurora相对于传统数据库有三大优势，首先，底层数据库存储是一个分布式存储服务，可以轻松应对故障；其次，数据库实例往底层存储层只写redo日志，因此数据库实例与存储节点之间的网络压力大大减小，这为提升数据库性能提供了保障；第三，将部分核心功能(故障恢复，备份还原)下推到存储层，这些任务可以在后台不间歇地异步执行，并且不影响前台用户任务。</p>
<p>  批评性建议：</p>
<p>  1.在存储结构方面，论文中没有给出caching很明确的细节说明，Caching是位于了存储层内还是计算层内？读者只能靠猜测。如果在文中给出了具体的细节说明，可能对读者理解本文具有很大的帮助。</p>
<p>  2.Amazon Aurora是基于开源MySQL的数据库，理论上修改GPL协议的开源软件再开发一个新软件是需要开源的，但它本身没有开放源代码，是一个闭源数据库。</p>
<p>  3.为什么备机节点可以多达15个呢？是为了应对数据库的读负载还是作为故障转移的目标，需要这么多备机做备选？本文在15个备份节点的解释上不是很清楚，读后存有疑惑。</p>
<p>下面引用两位专家对Aurora的评价：</p>
<p>Percona Vadim Tkachenko: Aurora没有解决写拓展和分库分表的问题。（2017）</p>
<p>Bill Karwin：Aurora不适合对具有二级索引的表进行大量写操作的场景。（2017）</p>
]]></content>
      <categories>
        <category>SIGMOD</category>
      </categories>
      <tags>
        <tag>论文解读</tag>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title>Applying TPM to Cloud</title>
    <url>/2020/10/12/Applying-TPM-to-Cloud/</url>
    <content><![CDATA[<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">序号</th>
<th style="text-align:left">属性</th>
<th style="text-align:center">内容</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:left">原文PDF</td>
<td style="text-align:center"><a href="https://sci-hub.se/10.1002/spy2.93" target="_blank" rel="noopener">Survey</a></td>
</tr>
<tr>
<td style="text-align:center">2</td>
<td style="text-align:left">作者信息</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">3</td>
<td style="text-align:left">核心内容</td>
<td style="text-align:center">调研了13年至18年的近120篇文献，且这些论文都利用TPM提高云计算安全。</td>
</tr>
<tr>
<td style="text-align:center">4</td>
<td style="text-align:left">研究领域</td>
<td style="text-align:center">可信计算</td>
</tr>
<tr>
<td style="text-align:center">5</td>
<td style="text-align:left">全文总览</td>
<td style="text-align:center">本文对TPM在云计算安全方面进行的细致的调研，并结合调研结果认为TPM在云计算安全的保护领域具有很大的趋势。</td>
</tr>
</tbody>
</table>
</div>
<h3 id="Paper-Source"><a href="#Paper-Source" class="headerlink" title="Paper Source"></a>Paper Source</h3><p><img src="/2020/10/12/Applying-TPM-to-Cloud/sources.png" width="500"></p>
<p><img src="/2020/10/12/Applying-TPM-to-Cloud/papercountry.png" width="500"></p>
<font color="DodgerBlue"> Paper Structure </font>

<p><img src="/2020/10/12/Applying-TPM-to-Cloud/Summary.png" width="600"></p>
<h3 id="Answering-the-Following-Question"><a href="#Answering-the-Following-Question" class="headerlink" title="Answering the Following Question"></a>Answering the Following Question</h3><h4 id="RQ1-For-what-purposes-is-TPM-used-in-the-cloud"><a href="#RQ1-For-what-purposes-is-TPM-used-in-the-cloud" class="headerlink" title="RQ1: For what purposes is TPM used in the cloud?"></a>RQ1: For what purposes is TPM used in the cloud?</h4><blockquote>
<p><strong>TPM 在云中的作用是什么？为什么要用到TPM？</strong></p>
</blockquote>
<h4 id="RQ2-What-types-of-threats-have-been-reportedly-mitigated-via-the-utilization-of-TPM-in-cloud"><a href="#RQ2-What-types-of-threats-have-been-reportedly-mitigated-via-the-utilization-of-TPM-in-cloud" class="headerlink" title="RQ2: What types of threats have been reportedly mitigated via the utilization of TPM in cloud?"></a>RQ2: What types of threats have been reportedly mitigated via the utilization of TPM in cloud?</h4><blockquote>
<p><strong>TPM的确缓解了的云中的哪些攻击？</strong></p>
</blockquote>
<h4 id="RQ3-What-is-the-exact-component-of-the-assessment？What-interpretations-are-given-for-integrity-in-cloud？"><a href="#RQ3-What-is-the-exact-component-of-the-assessment？What-interpretations-are-given-for-integrity-in-cloud？" class="headerlink" title="RQ3: What is the exact component of the assessment？What interpretations are given for integrity in cloud？"></a>RQ3: What is the exact component of the assessment？What interpretations are given for integrity in cloud？</h4><blockquote>
<p><strong>完整性度量的组件到底是什么？云中完整性度量的解释是什么？</strong></p>
</blockquote>
<h4 id="RQ4-At-what-level-are-TPM-primitives-invoked"><a href="#RQ4-At-what-level-are-TPM-primitives-invoked" class="headerlink" title="RQ4: At what level are TPM primitives invoked?"></a>RQ4: At what level are TPM primitives invoked?</h4><blockquote>
<p><strong>TPM被调用的级别是什么？</strong></p>
</blockquote>
<h4 id="RQ5-At-which-phase-are-the-TPM-features-used"><a href="#RQ5-At-which-phase-are-the-TPM-features-used" class="headerlink" title="RQ5: At which phase are the TPM features used?"></a>RQ5: At which phase are the TPM features used?</h4><blockquote>
<p><strong>在什么阶段用到了TPM？</strong><br><strong>A：boot time, run time and both.</strong></p>
</blockquote>
<p><img src="/2020/10/12/Applying-TPM-to-Cloud/Phase.png"></p>
<h3 id="TPM"><a href="#TPM" class="headerlink" title="TPM"></a>TPM</h3><p>​        可信计算利用硬件信任根以及与之关联的软件构建可信环境，提供信任和隐私保护。TPM这个模块，提供安全启动、远程验证、完整性检测以及机密功能。2011年发布了TPM1.2版本，2016年公布了TPM2.0版本。</p>
<p>​        远程证明是可信计算技术提供的主要功能，它将信任逐步从较低级别扩展到较高级别和应用程序。 这被称为信任链。 在信任链方案中，所有将要加载的组件都被认为是不可信的，因此，在加载之前需要对其进行测量。 TPM包含平台配置寄存器（PCR）受保护的内存位置，该位置存储敏感的安全信息（例如测量信息）。</p>
<p>​        除了强大的隔离存储，TPM还拥有用于加密操作的唯一认可密钥（EK）。该密钥是在TPM制造时生成的，密钥的私有部分永远不会离开TPM。 在远程认证时，为了保护平台身份的私密性，使用了认证身份密钥（AIK）。 当平台（证明者）收到（来自验证者的）远程证明请求时，它会发送一个完整性报告，该报告由PCR值及其数字签名（由AIK计算）组成。 由于AIK的私有部分从未离开过TPM，因此可以保证报告的完整性和真实性。</p>
<p>​        初步理解，TPM有几种存在模式，比如：以芯片方式存在电脑主板上或者以firmware形式存在于BIOS中。</p>
<h4 id="The-Aims-of-TPM"><a href="#The-Aims-of-TPM" class="headerlink" title="The Aims of TPM"></a>The Aims of TPM</h4><p><img src="/2020/10/12/Applying-TPM-to-Cloud/TPMAims.png" width="500" height="280"></p>
<font color="DodgerBlue"> 远程验证（Remote Attestation ）</font>

<blockquote>
<ol>
<li>请求验证者向被验证者发送验证请求，这个请求中包括 <em>nonce</em><sup><a href="#fn_1" id="reffn_1">1</a></sup> ，目的是防止重播攻击（Replay attack）</li>
<li>接收到验证请求的一方向自己的TPM提出验证请求，TPM验证自身需要度量的模块</li>
<li>验证后的结果发送给远端的验证发起者（发起者要验证(a)TPM 的真实性(b) 发送数值的真实性）</li>
</ol>
</blockquote>
<font color="DodgerBlue"> 完整性度量 （Integrity Measurement）</font>

<blockquote>
<p>TPM计算并存储不同组件的哈希值，并将这些哈希值在哈希链中进行转换，并将结果与已经存储的数值相比较。<br>完整性度量分为静态与动态两种类型：<br>        静态：保证在运行之前没有发生篡改<br>        动态：保证在运行过程中没有发生恶意篡改</p>
</blockquote>
<font color="DodgerBlue"> Generation and secure storage ofkeys</font>

<blockquote>
<p>生成随机秘钥的方法：种子、随机数生成器、直接导入TPM中。<br>生成的秘钥保存在TPM中</p>
</blockquote>
<font color="DodgerBlue"> Trusted boot</font>

<blockquote>
<p>在开机时，TPM会检查硬件、软件、固件组件的异同，保证在启动系统之前的环境是可信的。</p>
<p>本文的参考文献 [14] 利用TPM的可信启动构造一个可信的环境，保证在开机过程中没有恶意入侵。<br>[15] 提出一个用于监控整个云平台的框架，可信启动保证被监控环境的完整性，既对云中租户也是针对云供应商。</p>
</blockquote>
<font color="DodgerBlue"> Hardware root of trust</font>

<blockquote>
<p>信任根是可以在密码系统中信任的来源，加密安全依赖于秘钥来进行加密解密与生成或者验证数字签名，因此，在这种系统中包括不易损坏的硬件模块，并且提供了一定程度的信任保障。<br>TPM可以提供硬件信任根、提供开机与运行时的完整性度量并且保护度量结果。</p>
</blockquote>
<h4 id="Security-Threats"><a href="#Security-Threats" class="headerlink" title="Security Threats"></a>Security Threats</h4><p><img src="/2020/10/12/Applying-TPM-to-Cloud/TopThreats.png" width="380" height="500"></p>
<h4 id="The-level-of-TPM-invoking"><a href="#The-level-of-TPM-invoking" class="headerlink" title="The level of TPM invoking"></a>The level of TPM invoking</h4><font color="DodgerBlue"> Hardware </font>

<blockquote>
<p>在IoT和云计算等分布式系统模型中，主机平台的安全性至关重要，因为它托管着存储或处理（大量）数据。 TPM是一种用于平台身份验证以及验证其完整性的强大解决方案。在参考文献90中提出的解决方案中，扩展了HCloud（用于医疗保健数据的私有云），并且TPM嵌入在主机平台上以对客户端进行身份验证，并测量静态和动态完整性。讨论了可信云可以提供外部认证服务并进行内部可信调度。提供给外部的每个服务都有一个唯一的映像/进程在内存中运行。加载到内存时，需要验证此过程。可以使用TPM执行静态测量，以验证存储在物理存储库中的文件和软件包。同样，使用TPM签名保护数据库的完整性，以提供硬件级别的安全性。对于过程的动态完整性测量，TPM PCR用于存储和显示逐步的测量值。 Yang等[86]提出了一种设计，旨在为客户提供有关存储在云中的数据的新鲜度，有效性和完整性的保证。为了实现此目标，他们在不受信任的服务器上使用受信任的硬件设备，使客户端能够验证其数据的新鲜度和完整性。在系统运行之前，需要验证平台是否以受信任的方式启动。参考文献91讨论TPM是衡量启动过程和确定平台启动完整性的关键步骤的信任基础。在虚拟环境中，TPM提供了根植于硬件的信任链，该信任链将扩展到虚拟机管理程序。如果关键组件（例如BIOS，固件和虚拟机管理程序）已证明其完整性，则可以确保平台引导的完整性。为了确保启动组件的完整性，需要执行两个步骤：首先，测量引导过程，其次，进行证明，即保证和已执行的组件是受信任的组件。</p>
</blockquote>
<font color="DodgerBlue"> Hypervisor </font>

<blockquote>
<p>本文参考文献28构造了基于Xen的迁移框架：</p>
<p>Xen虚拟机管理程序的安全迁移框架。该设计使用可信计算和相邻完整性度量来动态监视相邻虚拟机管理程序的完整性。更具体地说，为确保始终监视主机，当主机初始化时，TPM模块会验证虚拟机监控程序并将更新消息发送到完整性验证表（该表包含受信任的虚拟机监控程序列表），并将该虚拟机监控程序标记为受信任的。这意味着，如果未收到此类消息，则认为该特定的管理程序不可信。此外，系统会动态监控虚拟机监控程序的运行状态，如果虚拟机监控程序遭到破坏，则会发送相应的更新消息以报告受到破坏的情况。根据此完整性表的结果，确定源虚拟机管理程序是否受信任以及是否应启动VM迁移过程。</p>
</blockquote>
<h4 id="Phase-of-integrity-measurement"><a href="#Phase-of-integrity-measurement" class="headerlink" title="Phase of integrity measurement"></a>Phase of integrity measurement</h4><font color="DodgerBlue"> Boot time </font>

<blockquote>
<p>可信平台技术追求的原则之一是在关键组件加载和执行之前验证它们的信任和完整性。因此，在运行时完整性检查之前，需要确保正确引导了系统并且正在运行适当的操作系统。受信任的平台通过创建信任链来实现这种信任，该信任链以BIOS引导块中的受信任代码（CRTM）为核心信任根。 CRTM衡量其他实体的完整性价值，并且在平台的整个生命周期内保持不变。 CRTM是普通BIOS的补充，它首先运行以测量BIOS块和硬件，然后将控制权传递给引导加载程序。然后在将控件传递给OS之前测量OS内核映像。在此引导过程的每个步骤中，都会获取测量值，并据此扩展相关的TPM PCR值。该测量过程证明了系统的完整性，并确保引导和操作系统软件是制造商想要的版本，并且未被恶意第三方或恶意软件篡改。100Nanavati等人74指出，在虚拟环境中，可信引导技术允许用户证明基础启动平台的身份，并确保加载的虚拟化平台值得信赖。这为用户提供了有关可以向其提交关键数据的虚拟化平台的具体保证。 TPM通过使用加密原语为虚拟化平台提供此受信任的引导，并为其建立信任根。在ALIBI可信监视框架中，17 TPM用于在服务提供商平台上提供信任根。 TPM PCR记录平台上正在执行的软件的状态，并且由于PCR值仅是附加值，因此仅通过重新启动才能消除以前的记录。 TPM还拥有一个公共-私人密钥对。私钥仅保留在TPM的安全环境中，并用于计算TPM生成的证明值（从经过身份验证的启动累积的度量）的签名。使用TPM的公钥，外部验证程序可以检查签名的有效性，并推断出PCR值表示平台软件的状态。</p>
</blockquote>
<h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h3><p>​        本文所统计并分析了120篇文献后，认为TPM技术在云中应用是一种趋势。在云中TPM技术的主要目标是远程验证以及完整性度量。本文主要分析了TPM的功能，TPM可应对云中的安全威胁，TPM提供完整性度量的阶段以及层次并指出了留有的研究空间，最后指出主要的研究差距。</p>
<blockquote id="fn_1">
<sup>1</sup>. 在加密技术中的初始向量和加密散列函数都发挥着重要作用，在各类验证协议的通信应用中确保验证信息不被重复使用以对抗重放攻击(Replay Attack)<a href="#reffn_1" title="Jump back to footnote [1] in the text."> ↩</a>
</blockquote>
<h3 id="引文延伸阅读"><a href="#引文延伸阅读" class="headerlink" title="引文延伸阅读"></a>引文延伸阅读</h3><p>Here are the papers worth reading further.</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>theme</th>
<th>Reference Number &amp; Summary</th>
<th>Reference Number &amp; Summary</th>
<th>more</th>
</tr>
</thead>
<tbody>
<tr>
<td>远程验证</td>
<td>6：TPM进行远程验证VMs</td>
<td>7：验证用户所在地理位置</td>
<td></td>
</tr>
<tr>
<td>完整性度量</td>
<td>10：多用户环境中数据拥有完整性</td>
<td>11：动态的完成性度量的模型（Xen）</td>
<td>8、9</td>
</tr>
<tr>
<td>生成秘钥安全存储</td>
<td>12</td>
<td>13</td>
<td></td>
</tr>
<tr>
<td>安全启动</td>
<td><a href="https://ink.library.smu.edu.sg/cgi/viewcontent.cgi?article=2969&amp;context=sis_research" target="_blank" rel="noopener">14</a>：protect the hypervisor</td>
<td>15 ：monitoring the cloud platform</td>
<td></td>
</tr>
<tr>
<td>硬件信任根</td>
<td>17 25 33 34 35</td>
<td></td>
</tr>
</tbody>
</table>
</div>
<h3 id="References"><a href="#References" class="headerlink" title="References"></a>References</h3><p>[1] <a href="https://www.zhihu.com/question/19790488/answer/19290308" target="_blank" rel="noopener">什么是彩虹表？</a> </p>
]]></content>
      <categories>
        <category>Security and Privacy</category>
      </categories>
      <tags>
        <tag>TPM</tag>
        <tag>Security</tag>
        <tag>Cloud Computing</tag>
        <tag>可信计算</tag>
      </tags>
  </entry>
  <entry>
    <title>C 语言字符串函数总结</title>
    <url>/2021/06/16/C-%E8%AF%AD%E8%A8%80%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%87%BD%E6%95%B0%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<h2 id="strtok"><a href="#strtok" class="headerlink" title="strtok"></a>strtok</h2><hr>
<h3 id="功能"><a href="#功能" class="headerlink" title="功能"></a>功能</h3><hr>
<p>C 库函数 <code>char \*strtok(char \*str, const char \*delim)</code>分解字符串 <code>str</code> 为一组字符串，<code>delim</code> 为分隔符。</p>
<h3 id="用法"><a href="#用法" class="headerlink" title="用法"></a>用法</h3><hr>
<pre><code class="lang-c">#include &lt;string.h&gt;
#include &lt;stdio.h&gt;

int main () {
   char str[80] = "This is - www.runoob.com - website";
   const char s[2] = "-";
   char *token;

   /* 获取第一个子字符串 */
   token = strtok(str, s);

   /* 继续获取其他的子字符串 */
   while( token != NULL ) {
      printf( "%s\n", token );

      token = strtok(NULL, s);
   }

   return(0);
}
</code></pre>
<p><strong>输出结果：</strong></p>
<pre><code class="lang-bash">This is 
 www.runoob.com 
 website
</code></pre>
<p><strong>分别保存ip每个字段信息：</strong></p>
<pre><code class="lang-c">void separateStr(char ip[20], char *ip_each_str[5])
{
    char *temp = NULL;
    int num = 0;
    char delims[] = "."; // 按照.拆分

    temp = strtok(ip, delims);
    ip_each_str[num] = temp;

    while (temp != NULL)
    {
        temp = strtok(NULL, delims);
        ip_each_str[++num] = temp;
    }

    return;
}
</code></pre>
<h3 id="源码"><a href="#源码" class="headerlink" title="源码"></a>源码</h3><hr>
<h3 id="深究"><a href="#深究" class="headerlink" title="深究"></a>深究</h3><hr>
<p><strong>strtok函数有两个小问题：</strong></p>
<blockquote>
<p>1.在输入时，char *ip 与 char ip[] 两种方式会有极大不同，在调用strtok函数时，前者会报错 segment fault；</p>
<p>2.<code>char buffer[] = "***";</code>类型的输入可以进行正确切分，而<code>char *buffer = "***";</code>类型的输入在切分时会出现<code>segmentation fault</code>的错误。</p>
</blockquote>
<p>[1] 针对问题一中得出结论如下：</p>
<p><code>strtok</code>函数进行字符串分割时，会破坏被分解字符串的完整，调用前和调用后的s已经不一样了。第一次分割之后，原字符串str是分割完成之后的第一个字符串，剩余的字符串存储在一个静态变量中。</p>
<p>strtok函数在提取字符串时使用了静态缓冲区，因此，它是线程不安全的，多线程同时访问该静态变量时，则会出现错误。</p>
<p>其实在第一次循环中，strtok函数将第一个人信息后的这个逗号，改为了’\0，这时strtok内部的this指针指向的是逗号的后一个字符。</p>
<p>而在第一个循环结束后，函数第一个参数被设定为NULL，strtok将以this指针指向的位置作为分解起始位置，此时this指针指向的是’\0’，strtok对一个空串无法切分，返回NULL，所以得到上面的结果。</p>
<h2 id="strcat"><a href="#strcat" class="headerlink" title="strcat"></a>strcat</h2><hr>
<h2 id="strcpy"><a href="#strcpy" class="headerlink" title="strcpy"></a>strcpy</h2><hr>
<h2 id="区别-char-str-与-char-str"><a href="#区别-char-str-与-char-str" class="headerlink" title="区别 char * str 与 char str[];"></a>区别 char * str 与 char str[];</h2><hr>
<p><strong>程序示例 test-string_V1.0：</strong></p>
<pre><code class="lang-c">#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;string.h&gt;

int main(void)
{
    char ip[] ="192.168.0.2";
    char *ips = "192.168.0.2";

    printf("before modify ip =&gt;%s&lt;\n",ip);
    ip[2] = '&amp;';
    printf("after  modify ip =&gt;%s&lt;\n",ip);

    printf("before modify ips =&gt;%s&lt;\n",ips);
    ips[0] = '&amp;';
    printf("after  modify ips =&gt;%s&lt;\n",ips);

    return 0;
}
</code></pre>
<p><strong>输出结果：</strong></p>
<pre><code class="lang-bash">before modify ip =&gt;192.168.0.2&lt;
after  modify ip =&gt;19&amp;.168.0.2&lt;
before modify ips =&gt;192.168.0.2&lt;
Segmentation fault
</code></pre>
<p><strong>结论：</strong></p>
<blockquote>
<p>以字符数组方式进行赋值的字符串可以被修改，以char *ips方式赋值的字符串无法被修改，默认为const 类型。</p>
</blockquote>
<p><strong>程序示例 test-string_V1.1：</strong></p>
<pre><code class="lang-c">#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;string.h&gt;

int main(void)
{
    char ip[] ="192.168.0.2";
//    char *ips = "192.168.0.2";
    char *ip_const = "192.168.0.2";
    char *ips = NULL;

    // 这种方式也不会被修改,strcpy底层实现是直接将指针指向还是按照字符数组赋值？
    ips = (char *)malloc(sizeof(char)*20);
    strcpy(ips, ip_const);

    printf("before modify ip =&gt;%s&lt;\n",ip);
    ip[2] = '&amp;';
    printf("after  modify ip =&gt;%s&lt;\n",ip);

    printf("before modify ips =&gt;%s&lt;\n",ips);
    ips[2] = '&amp;';
    printf("after  modify ips =&gt;%s&lt;\n",ips);

    return 0;
}
</code></pre>
<p><strong>输出结果：</strong></p>
<pre><code class="lang-bash">before modify ip =&gt;192.168.0.2&lt;
after  modify ip =&gt;19&amp;.168.0.2&lt;
before modify ips =&gt;192.168.0.2&lt;
after  modify ips =&gt;19&amp;.168.0.2&lt;
</code></pre>
<p><strong>结论：</strong></p>
<blockquote>
<p>以char * ip定义的字符串，在strcpy方式之后以赋值方式可以修改。</p>
</blockquote>
<p><strong>程序示例 test-string_V1.2：</strong></p>
<pre><code class="lang-c">#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;string.h&gt;

int main(void)
{
    char ip[] ="192.168.0.2";
//    char *ips = "192.168.0.2";
    char *ip_const = "192.168.0.2";
    char *ips = NULL;

    // 这种方式初始化时候使用strcat会更改原始字符串
    ips = (char *)malloc(sizeof(char)*20);
    strcpy(ips, ip_const);

    printf("before modify ip =&gt;%s&lt;\n",ip);
    ip[2] = '&amp;';
    printf("after  modify ip =&gt;%s&lt;\n",ip);

    printf("before modify ips =&gt;%s&lt;\n",ips);
    strcat(ips, ip);
    printf("after  modify ips =&gt;%s&lt;\n",ips);

    return 0;
}
</code></pre>
<p><strong>输出结果：</strong></p>
<pre><code class="lang-bash">before modify ip =&gt;192.168.0.2&lt;
after  modify ip =&gt;19&amp;.168.0.2&lt;
before modify ips =&gt;192.168.0.2&lt;
after  modify ips =&gt;192.168.0.219&amp;.168.0.2&lt;
</code></pre>
<p><strong>结论：</strong></p>
<blockquote>
<p>以char * ip定义的字符串，使用strcat会更改原始字符串。</p>
</blockquote>
<p><strong>程序示例 test-string_V1.3：</strong></p>
<pre><code class="lang-c">#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;string.h&gt;

int main(void)
{
    char ip[] ="192.168.0.2";
//    char *ips = "192.168.0.2";
    char *ip_const = "192.168.0.2";
    char *ips = NULL;

    // 这种方式初始化, 会更改原始字符串
    ips = (char *)malloc(sizeof(char)*20);
    for (int i = 0; i &lt; strlen(ip_const); ++i) {
        ips[i] = ip_const[i];
    }

    printf("before modify ip =&gt;%s&lt;\n",ip);
    ip[2] = '&amp;';
    printf("after  modify ip =&gt;%s&lt;\n",ip);

    printf("before modify ips =&gt;%s&lt;\n",ips);
    ips[2] = '&amp;';
    printf("after  modify ips =&gt;%s&lt;\n",ips);

    return 0;
}
</code></pre>
<p><strong>输出结果：</strong></p>
<pre><code class="lang-bash">before modify ip =&gt;192.168.0.2&lt;
after  modify ip =&gt;19&amp;.168.0.2&lt;
before modify ips =&gt;192.168.0.2&lt;
after  modify ips =&gt;19&amp;.168.0.2&lt;
</code></pre>
<p><strong>结论：</strong></p>
<blockquote>
<p>以char * ip定义的字符串，动态分配内存后使用字符赋值会被修改。</p>
</blockquote>
<p><strong>综上：</strong></p>
<blockquote>
<p>以字符数组方式进行赋值的字符串可以被修改，以char *ips方式赋值的字符串无法被修改，默认为const 类型。</p>
<p>以char * ip定义的字符串，使用strcpy/strcat会更改原始字符串。</p>
<p>以动态分配内存方式字符赋值会修改原始字符串。</p>
</blockquote>
<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><p>[1] <a href="https://cloud.tencent.com/developer/article/1678308" target="_blank" rel="noopener">https://cloud.tencent.com/developer/article/1678308</a></p>
]]></content>
      <tags>
        <tag>TODO</tag>
        <tag>C语言</tag>
        <tag>字符串</tag>
      </tags>
  </entry>
  <entry>
    <title>BatchCrypt</title>
    <url>/2020/09/13/BatchCrypt/</url>
    <content><![CDATA[<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">序号</th>
<th style="text-align:center">属性</th>
<th style="text-align:center">内容</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">原文PDF</td>
<td style="text-align:center"><a href="https://marcoszh.github.io/batchcrypt_atc20.pdf" target="_blank" rel="noopener">Batchcrypt</a></td>
</tr>
<tr>
<td style="text-align:center">2</td>
<td style="text-align:center">作者信息</td>
<td style="text-align:center"><a href="https://marcoszh.github.io/" target="_blank" rel="noopener">Chengliang Zhang</a></td>
</tr>
<tr>
<td style="text-align:center">3</td>
<td style="text-align:center">核心内容</td>
<td style="text-align:center">利用同态加密技术实现FL的安全数据传输，通过改进系统模型，降低同态加密带来的加密与通讯代价。</td>
</tr>
<tr>
<td style="text-align:center">4</td>
<td style="text-align:center">研究领域</td>
<td style="text-align:center">Federal Learning; HE</td>
</tr>
<tr>
<td style="text-align:center">5</td>
<td style="text-align:center">全文总览</td>
<td style="text-align:center">利用同态加密构造一个适合联邦学习的模型，通过优化降低同态加密带来的加密计算与通讯的时间代价。</td>
</tr>
</tbody>
</table>
</div>
<h3 id="BatchCrypt"><a href="#BatchCrypt" class="headerlink" title="BatchCrypt"></a>BatchCrypt</h3><p>  这篇论文的目的是利用同态加密构造一个适合联邦学习的模型，能够利用同态加密的安全特性满足联邦学习对安全的需求，并在此基础上对同态加密进行改进，从而获得一个更加高效的处理系统。通过引入批处理，缓解同态加密的加密代价，这样就可以在满足安全性的同时保证性能。</p>
<h3 id="联邦学习"><a href="#联邦学习" class="headerlink" title="联邦学习"></a>联邦学习</h3><h4 id="联邦学习系统架构"><a href="#联邦学习系统架构" class="headerlink" title="联邦学习系统架构"></a><font color="Blue"><strong>联邦学习系统架构</strong></font></h4><blockquote>
<p>假设企业A、B想要联合训练一个机器学习模型，两者业务系统分别拥有各自用户的相关数据，企业B拥有模型需要预测的便签数据，出于安全考虑，A与B无法直接进行数据交换，下图是利用联邦学习模型架构的组成。</p>
<p>第一部分： 加密样本对齐。由于两个公司的用户群体并非完全重合，系统利用基于加密的用户样本对齐，在A与B不公开各自数据的前提下确认双方的共有用户，便于联合这些用户特征进行建模。</p>
<p>第二部分： 加密模型训练。在确定共有用户群体之后，利用这些数据训练机器学习模型，为了保证训练过程中数据的保密性，需要借助第三方协作者C进行加密训练，以线性回归模型为例，训练过程如下：</p>
<blockquote>
<ol>
<li><p>协作者C把公钥分发给A与B，对训练过程中需要交换的数据进行加密；</p>
</li>
<li><p>A、B之间以加密形式交互用于计算梯度的中间结果；</p>
</li>
<li><p>A、B分别基于加密的梯度值进行计算，同时B根据便签数据计算损失，并把这些结果汇总给C，C通过汇总结果计算总梯度并将其解密；</p>
</li>
<li><p>C将解密后的梯度分别回传给A和B，并根据梯度更新各自模型的参数。</p>
</li>
</ol>
</blockquote>
<p>对上述过程进行迭代，直至损失函数收敛，这样就完成了整个训练过程，在样本对齐以及模型训练过程中， A、B各自的数据均留在本地，且训练中的数据交互也不会导致数据隐私泄露，因此，双方在联邦学习的帮助下可以实现合作训练模型的目的。</p>
<p>第三部分： 效果激励。联邦学习的特点是解决了为什么不同机构要加入联邦共同建模的问题。提供数据多的机构获得的模型效果会更好，模型效果取决于数据提供方对自己和他人的贡献，这些模型的效果在联邦机制上会分发给各个机构反馈，并继续激励更多机构加入这一数据联邦。</p>
</blockquote>
<p><img src="/2020/09/13/BatchCrypt/FL_Architecture.png" width="600px" height="300px"></p>
<p>​                                                                   图1. 联邦学习架构图</p>
<h4 id="联邦学习优势"><a href="#联邦学习优势" class="headerlink" title="联邦学习优势 "></a><font color="RoyalBlue"><strong>联邦学习优势</strong> </font></h4><blockquote>
<p>数据隔离，满足用户隐私保护和数据安全的需求；</p>
<p>保证模型质量无损，不会出现负迁移，保证联邦模型比割裂的独立模型效果好；</p>
<p>参与者地位对等，能够实现公平合作；</p>
<p>能够保证参与方在保持独立的情况下，进行信息与模型参数的加密交换，并同时获得成长。</p>
</blockquote>
<h4 id="联邦学习方式"><a href="#联邦学习方式" class="headerlink" title="联邦学习方式 "></a><font color="RoyalBlue"><strong>联邦学习方式</strong> </font></h4><div class="table-container">
<table>
<thead>
<tr>
<th>Method</th>
<th>Differential Privacy</th>
<th>Secure Multi Party Comput.</th>
<th>Secure Aggregation</th>
<th>Homomorphic Encryption</th>
</tr>
</thead>
<tbody>
<tr>
<td>Efficiency</td>
<td>√</td>
<td>×</td>
<td>×</td>
<td>×</td>
</tr>
<tr>
<td>Strong Privacy</td>
<td>×</td>
<td>√</td>
<td>×</td>
<td>√</td>
</tr>
<tr>
<td>No accuracy loss</td>
<td>×</td>
<td>√</td>
<td>√</td>
<td>√-</td>
</tr>
</tbody>
</table>
</div>
<ul>
<li><p><font color="green"> <strong>DP</strong></font>  通过注入噪声增加对数据的保护(安全性较差)</p>
</li>
<li><p><font color="green"> <strong>MPC</strong></font> 多方合作，利用达成一致的同种方式计算。多方客户端通过一种特定受保护的同步协议进行同步，但是不适合于跨孤岛的联邦学习，对隐私或者计算性能都有很大的影响。</p>
</li>
<li><p><font color="green"> <strong>Secure Aggregation</strong></font> 易被其他实体获取</p>
</li>
<li><font color="green"> **HE**</font> 

<blockquote>
<p>1.对训练模型的保护</p>
<p>2.没有学习精度的缺失，没有噪声的引入</p>
<p>3.应用的话对系统无需额外的更改，仅仅是加密解密上的更新,但是，这增加了很多的系统负载（计算以及交互代价过高）</p>
</blockquote>
</li>
</ul>
<h3 id="HE应用于FL"><a href="#HE应用于FL" class="headerlink" title="HE应用于FL"></a><font color="b"><strong>HE应用于FL</strong></font></h3><p>​        上传数据到中心服务器的过程中，密钥对是通过加密信道在客户端之间传输的，客户上传加密过的数据到服务器，服务器聚集所有客户上传的密文，并将结果返回给客户为了保证在上传数据的时候不发生数据泄露，采用的方式包括同态加密，这种方式在保证加密的同时不降低学习的准确率。客户端通过已获取的密钥对解密返回的密文。这样无论客户端是否可信，读取的数据都是密文，即对数据进行了保护。</p>
<h4 id="HE性能瓶颈"><a href="#HE性能瓶颈" class="headerlink" title="HE性能瓶颈"></a><font color="blue"><strong>HE性能瓶颈</strong></font></h4><p>​        通过测试三个联邦学习的深度学习模型实例得出了性能瓶颈，主要是同态加密过程与通讯过程成为了主要性能瓶颈。</p>
<font color="green">**实验测试**</font>

<p>​    模拟不同的地理位置的客户，在EC2上开9个客户端，分布在5个不同的地理位置，利用FATE (Federated AI Technology Enabler)进行训练。</p>
<font color="green">**加密与通讯代价**</font>

<p>​        2.1 在三个数据集上的训练时间增加量分别为 96、135、154倍，提高了两个数量级，加密后的数据量分别带来了161、156、163倍的额外数据量。</p>
<p>​        2.2 客户端数据加密及解密时间占据8成；在聚合端（服务端），7成以上的时间用来等待数据的传输，聚合数据的时间只有10%</p>
<p><img src="/2020/09/13/BatchCrypt/Iterationtime.png" width="500px" height="300px"></p>
<p>​        其余时间用来从不同客户端收集数据、分发数据。（因为不同 客户端在不同的地理位置，因此不是同步传输）</p>
<font color="green">**为什么同态的代价如此高昂**</font>

<p>​        随着秘钥长度的增加，安全性会随之增加，但是带来的加密代价也是随之增加的。由于pailier只能处理整形的数据，在遇到浮点数的时候需要事先进行转化，因此这些数据加密时间并不是严格按照线性关系增加的。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Keysize</th>
<th>Plaintext</th>
<th>Ciphertext</th>
<th>Encryption</th>
<th>Decryption</th>
</tr>
</thead>
<tbody>
<tr>
<td>1024</td>
<td>6.87MB</td>
<td>287.64MB</td>
<td>216.87S</td>
<td>68.63S</td>
</tr>
<tr>
<td>2048</td>
<td>6.87MB</td>
<td>527.17MB</td>
<td>1152.98S</td>
<td>357.17S</td>
</tr>
<tr>
<td>3072</td>
<td>6.87MB</td>
<td>754.62MB</td>
<td>3111.14S</td>
<td>993.80S</td>
</tr>
</tbody>
</table>
</div>
<font color="green">**总结**</font>

<p>​        4.1 由于同态加密在此过程中占据主导地位，如果利用硬件加速模型计算，例如GPU、TPU，获得的意义不大；</p>
<p>​        4.2 不同的数据孤岛在不同的地理位置，因此大量的数据传输会带来额外的网络通讯费用。</p>
<font color="green">**解决方法**</font>

<ol>
<li>加速HE的操作时间：FPGA仅提高三倍的处理时间，但是通讯上未改进；</li>
<li>减少加密的操作（减少密文的长度），或者利用批处理方式对目标值进行处理。</li>
</ol>
<h4 id="FATE改进"><a href="#FATE改进" class="headerlink" title="FATE改进"></a><font color="blue"><strong>FATE改进</strong></font></h4><p>==目标==  想要获得高效的处理时间并且不会引入精度上的缺失。</p>
<p>==FATE局限性==</p>
<blockquote>
<ol>
<li>仅可以处理整数，无法处理浮点数，而梯度值不仅是浮点数而且是有符号的浮点数；</li>
<li>处理的数都是正整数，处理负数时要转化为正数，无法判断数字是正溢出还是负溢出。</li>
</ol>
</blockquote>
<p>==对梯度值进行量化==</p>
<p><img src="/2020/09/13/BatchCrypt/sign.png" width="500px" height="100px"></p>
<p>由于对浮点数进行加减需要对齐指数（阶码）后才能操作，因此对于仅可以处理整数的系统来说是不太现实的，需要对浮点数进行转化。</p>
<p>1.将浮点数转化为整数，利用转化后的整数进行计算；</p>
<p>2.采用两个符号位对浮点数进行正负标识，可以推断出数字的正负溢出。</p>
<p><img src="/2020/09/13/BatchCrypt/doublesign.png" width="500px" height="200px"></p>
<p>通过以上的处理，可以使用FATE系统对量化后的梯度值进行HE处理。</p>
<p>3.利用机器学习的方式，对数据进行剪枝处理，减少处理的数据量（去噪声），并且模型是动态变化的。（在线模型）</p>
<p>==架构图==</p>
<p><img src="/2020/09/13/BatchCrypt/batcharchitecture.png" width="500px" height="300px"></p>
<h4 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a><font color="blue"><strong>实验结果</strong></font></h4><p>==实验环境==</p>
<p>AWS </p>
<p>Cluster of 10, spanning 5 locations （部署在五大洲）</p>
<p>C5.4xlarge instances (16 vCPUs, 32 GB memory) </p>
<p>==处理时间==</p>
<p><img src="/2020/09/13/BatchCrypt/lab-1.png" width="500px" height="200px"></p>
<p>==通讯时间==</p>
<p><img src="/2020/09/13/BatchCrypt/lab-2.png" width="500px" height="200px"></p>
<p>==总计时间==</p>
<p><img src="/2020/09/13/BatchCrypt/lab-3.png" width="500px" height="300px"></p>
<h3 id="References"><a href="#References" class="headerlink" title="References"></a>References</h3><p>[1] <a href="https://blog.csdn.net/cao812755156/article/details/89598410?utm_medium=distribute.pc_relevant.none-task-blog-title-1&amp;spm=1001.2101.3001.4242" target="_blank" rel="noopener">联邦学习</a></p>
<p>[2] <a href="https://ai.googleblog.com/2017/04/federated-learning-collaborative.html" target="_blank" rel="noopener">https://ai.googleblog.com/2017/04/federated-learning-collaborative.html</a></p>
]]></content>
      <categories>
        <category>ATC</category>
      </categories>
      <tags>
        <tag>论文解读</tag>
        <tag>Federal Learning</tag>
        <tag>Homomorphic</tag>
      </tags>
  </entry>
  <entry>
    <title>CloudMon</title>
    <url>/2020/09/14/CloudMon/</url>
    <content><![CDATA[<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">序号</th>
<th style="text-align:center">属性</th>
<th style="text-align:center">内容</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">原文PDF</td>
<td style="text-align:center"><a href="">CloudMon</a></td>
</tr>
<tr>
<td style="text-align:center">2</td>
<td style="text-align:center">作者信息</td>
<td style="text-align:center"><a href="https://chuliangweng.github.io/" target="_blank" rel="noopener">Cl.W</a></td>
</tr>
<tr>
<td style="text-align:center">3</td>
<td style="text-align:center">核心内容</td>
<td style="text-align:center">这篇文章信任hypervisor并在此基础上对guestVM进行保护，主要是从内存角度出发，针对rootkit攻击进行运行时检测。</td>
</tr>
<tr>
<td style="text-align:center">4</td>
<td style="text-align:center">研究领域</td>
<td style="text-align:center">System Security; Virtual Machine</td>
</tr>
<tr>
<td style="text-align:center">5</td>
<td style="text-align:center">全文总览</td>
<td style="text-align:center">本文构造一个动态的监控架构，并在此基础上保证guest VM 运行时的安全性，主要功能是在客户虚拟机中检测出rootkits攻击。</td>
</tr>
</tbody>
</table>
</div>
<p>​        本文构建了一个动态的监控架构，运行在特权级别，通过对guestVM内存的扫描，检测客户机是否受到rootkit攻击，从而保证guestVM的运行时安全性。利用虚拟化技术对客户机内存进行实时监控，且这些监控对于客户机是透明的，为了实现检测的有效与高效，本系统在性能和安全之间权衡。</p>
<h4 id="Rootkit-攻击"><a href="#Rootkit-攻击" class="headerlink" title="Rootkit 攻击 "></a><font color="blue"><strong>Rootkit 攻击</strong> </font></h4><p>​        rootkit 能够以特权级指令访问 host，并且可以通过对系统进行更改隐藏自己的存在。</p>
<p>​        检测rootkit，最好是对客户机透明，不更改客户机系统的前提下对其进行检测。</p>
<h3 id="威胁模型"><a href="#威胁模型" class="headerlink" title="威胁模型"></a>威胁模型</h3><p>​        假设VMM（hypervisor）与priviliged VM  是可信的，guest VM 会受到攻击，在开机阶段的安全性受到VMM的保护，并且对guest VM的攻击不会对privileged VM 的安全性造成影响。</p>
<p>（有些保护是针对VMM的，但是这不在本文的考虑范围内，本文聚焦在对客户机的保护上）</p>
<h3 id="CloudMon-系统设计"><a href="#CloudMon-系统设计" class="headerlink" title="CloudMon 系统设计"></a>CloudMon 系统设计</h3><p>​        目的是实现一个可以访问较低权限级别内存信息、检测潜在的攻击并且可以保证检测的实时性与系统性能。访问内存的操作实现是基于 Xen的xenctrl 库，这个库能够读取较低权限的内存（如guest VM的内存信息）。</p>
<p>​        构建一个guest VM 内存的监控器，目标是对VM透明、高效且是瞬时性的，这种方式可行性是因为攻击者对VM内存任何的更改都是可见的。CloudMon扫描内核memory与寄存器，从而可以实时的检测内存状态变化。这是一个特权级别的VM，能够通过VMM访问其他VMs的内存信息，而不是单纯的一个安全的guest VM。</p>
<p><img src="/2020/09/14/CloudMon/CloudMonArchitecture.png" width="400px" height="240px"></p>
<p>​        从云中大量的攻击实例中提取rootkit攻击特征，并将该特征记录在Feature Lib中，通过比较RT Value 与 SV Table 中数值的差异情况，可以检测出系统调用表中的攻击情况，设置较小的检测时间间隔，可以近似实时的检测嵌入内核的 rootkit ，通过设置检测的时间间隔，可以控制性能开销。并且CloudMon会直接检索其内存，因此，包括DKSM 和Shadow Walker 在内的任何来宾内核rootkit都不会欺骗CloudMon。 </p>
<font color="green">**获取开始地址信息**</font>

<p>​        KV Searcher查找 guest VM 系统调用的起始地址，SV generator 通过扫描，比对通过大量OS攻击实例中获取到的攻击特征，从而可以判断出被攻击者。</p>
<h4 id="实验环境"><a href="#实验环境" class="headerlink" title="实验环境"></a><font color="blue"><strong>实验环境</strong></font></h4><div class="table-container">
<table>
<thead>
<tr>
<th>Xen</th>
<th>priviliged VM</th>
<th>guest VM</th>
</tr>
</thead>
<tbody>
<tr>
<td>Xen-3.4.2</td>
<td>Ubuntu 9.04</td>
<td>Ubuntu 8.04</td>
</tr>
</tbody>
</table>
</div>
<p>已经存在的检测方式：</p>
<ol>
<li><p>获取guest OS的system.map信息</p>
</li>
<li><p>one-on-one 运行在guest VM上</p>
</li>
</ol>
<h3 id="相关工作介绍"><a href="#相关工作介绍" class="headerlink" title="相关工作介绍"></a>相关工作介绍</h3><p>本文将对VM的保护机制分为了 out-of-VM  与 in-VM两种</p>
<p>A类：out-of-VM</p>
<ol>
<li><p>利用受信任的VM充当监控器。OSck,是一种one-on-one的监控模式</p>
</li>
<li><p>XenKIMONO 在VM中聚集信息时会暂停OS的执行</p>
</li>
<li><p>vIPS 通过预先设置，这种检测规则需要有固定的检测时间间隔</p>
</li>
</ol>
<p>B类：in-VM</p>
<ol>
<li><p>硬件虚拟化技术</p>
</li>
<li><p>Lares 在guest VM 中内置hooks（钩子函数）实时的检测虚拟机的安全（事件检测）</p>
</li>
</ol>
]]></content>
      <categories>
        <category>TC</category>
      </categories>
      <tags>
        <tag>论文解读</tag>
        <tag>Virtual Machine</tag>
        <tag>System Security</tag>
      </tags>
  </entry>
  <entry>
    <title>CITM attacks</title>
    <url>/2021/03/23/CITM-attacks/</url>
    <content><![CDATA[<h2 id="导读"><a href="#导读" class="headerlink" title="导读"></a>导读</h2><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">序号</th>
<th style="text-align:left">属性</th>
<th style="text-align:center">内容</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:left">原文PDF</td>
<td style="text-align:center"><a href="https://dl.acm.org/doi/pdf/10.1145/3372297.3417886" target="_blank" rel="noopener">cache-in-the-middle</a> <a href="https://ykma.gitee.io/files/docs/CITM-slides.pdf" target="_blank" rel="noopener">CITM-slides</a></td>
</tr>
<tr>
<td style="text-align:center">2</td>
<td style="text-align:left">作者信息</td>
<td style="text-align:center">中科院，乔治梅森大学 <a href="https://csis.gmu.edu/ksun/" target="_blank" rel="noopener">home-page</a></td>
</tr>
<tr>
<td style="text-align:center">3</td>
<td style="text-align:left">核心内容</td>
<td style="text-align:center">基于ARM的CITM攻击原因分析</td>
</tr>
<tr>
<td style="text-align:center">4</td>
<td style="text-align:left">研究领域</td>
<td style="text-align:center">TEE 可信计算环境</td>
</tr>
<tr>
<td style="text-align:center">5</td>
<td style="text-align:left">全文总览</td>
<td style="text-align:center">本文发现了三种基于缓存的攻击（CITM），针对IEE数据保护模型和ARM缓存属性，分析了CITM的攻击原因并给出对策。</td>
</tr>
</tbody>
</table>
</div>
<h2 id="研究动机"><a href="#研究动机" class="headerlink" title="研究动机"></a>研究动机</h2><p>本文聚焦在ARM TrustZone中的一个冲突矛盾点：</p>
<p>在开发者眼中，想要通过在可信执行环境中约束第三方软件的安装起到最小化可信计算基的目的，而第三方软想要将其安装在可信环境中。</p>
<p>已有的解决方案： IEE </p>
<p>为了解决上述的矛盾点，研究者们在普通的执行环境中创建了一个隔离的执行环境，这样可以为安全敏感型应用提供保护。</p>
<p>现有的IEE系统更多地关注于保护IEE敏感数据的主存，而在IEE系统中缓存的安全性还没有很好的研究。</p>
<p>本文系统的研究了 IEE 的数据保护模型和 ARM cache的特征，发现了三种可以成为CITM的攻击能够泄露在IEE中保护的敏感数据。</p>
<p>作者在三种IEE系统中测试了CITM攻击，最后分析了CITM攻击的根本原因，并提出了防御机制。</p>
<h2 id="背景知识"><a href="#背景知识" class="headerlink" title="背景知识"></a>背景知识</h2><p>TrustZone作为一种硬件辅助技术，将平台划分为两个执行环境： <strong>正常世界</strong> (非安全世界)和 <strong>安全世界</strong> ，其中</p>
<ul>
<li><strong>正常世界</strong> (NW)负责在rich Os上运行正常的应用程序</li>
<li><strong>安全世界</strong> (SW)保护安全敏感的代码和数据</li>
</ul>
<p>对于支持TrustZone的ARM处理器，所有级别的缓存都扩展了一个额外的标记位(NS位)来记录它们的安全状态</p>
<ul>
<li><p>当从正常世界访问内存时，相应的cache line将设置为非安全的</p>
</li>
<li><p>当从安全世界访问内存时，相应的cache line将被设置为安全的</p>
</li>
<li><p>另外，cache line的NS位是由硬件自动设置的，软件不能修改</p>
</li>
<li><p>TZASC 硬件可以区分memory为 Secure 与 Non-secure</p>
</li>
<li><p>ARM 处理器配置了两级缓存</p>
<p><img src="/2021/03/23/CITM-attacks/image-20210330093949863.png" width="400"></p>
</li>
</ul>
<p>TrustZone的传统用法是在安全的环境中运行安全敏感的应用程序并存储它们的敏感数据，(也就是把这些敏感操作都放到安全世界中)，</p>
<p><img src="/2021/03/23/CITM-attacks/image-20210330091547211.png" width="400"></p>
<ul>
<li><p>这便是可信执行环境 ( TEE )系统，其中安全敏感的应用程序在这里被实现为 可信应用程序 ( TA )，运行在安全世界(SW)中。</p>
<ul>
<li>(例：三星KNOX、OP-TEE、高通QSEE、华为安全操作系统)</li>
</ul>
</li>
<li><p>TEE解决方案依赖于内置的硬件支持 来实施安全隔离，并防范来自不可信的rich Os的攻击。</p>
<ul>
<li>问题：设备制造商和第三方安全敏感的应用程序开发人员存在需求冲突 （制造商不想打开SW让你安第三方APP，他们更信任自己的应用，但第三方APP想进入SW以求安全可信）</li>
</ul>
</li>
<li><p>为此，研究人员建议在正常世界中创建 <strong>孤立的执行环境</strong> (称为 <strong>IEE</strong> )</p>
</li>
</ul>
<p><img src="/2021/03/23/CITM-attacks/image-20210330091804383.png" width="400"></p>
<ul>
<li><p>关键点：在安全的世界中使用可信参考监视器(例： <strong>IEE监视器</strong> )，确保只有经过授权的运行在IEE中的安全敏感应用程序才能访问相关的IEE敏感资源，从而保护一个IEE中的安全敏感应用程序不受其他IEEs和rich OS的影响。</p>
<ul>
<li>TrustICE 依赖于IEE监视器，通过动态控制IEE内存的安全属性来保护IEE内存。</li>
<li>Ginseng 构建了IEEs来保护正常世界中的第三方应用程序的秘密，而不需要在安全世界中部署任何特定于应用程序的逻辑。</li>
<li>SANCTUARY 将其IEE分配为per-core环境，以确保在正常世界中，为IEE指定的内存(以下简称IEE内存)不被任何其他非安全的内核访问。</li>
</ul>
</li>
<li><p>IEE 优缺点：</p>
<ul>
<li><p>用“ <strong>switch out</strong> ”来表示一个内核的上下文从IEE切换到不可信的rich OS的进程；用“ <strong>switch in</strong> ”来表示每个内核上的逆向进程。</p>
</li>
<li><p>IEE系统能够最大限度地 <strong>减小SW的TCB</strong> ：仅在SW中安装IEE监视器即可将安全敏感应用程序转移到NW中。</p>
</li>
<li><p>IEE系统具有<strong>可移植性</strong> ，表现在：安全敏感的应用程序是在NW中安装和执行的。</p>
</li>
<li><p>但安全敏感的应用程序是由<strong>软件</strong>组件(例：IEE监视器)隔离和保护的，故IEE系统可能<strong>无法达到</strong>与TEE系统相同的安全保护级别。</p>
</li>
</ul>
</li>
</ul>
<h2 id="现存系统及CITM攻击"><a href="#现存系统及CITM攻击" class="headerlink" title="现存系统及CITM攻击"></a>现存系统及CITM攻击</h2><ul>
<li>CITM可以操纵IEE保护的敏感数据：<ul>
<li>在并发执行时，通过 <strong>跨核缓存</strong> [4] [5] 操作来操纵IEE数据<ul>
<li>在多核平台上，防范并发运行的不可信的rich OS，仅确保在IEE内存上进行core-wise isolation是不安全的，因为缓存可能仍然对跨核访问开放，从而受到攻击者的操纵</li>
<li><strong>SANCTUARY</strong> ：在并发执行过程中，攻击者通过跨核L1缓存操作成功窃取和修改SANCTUARY系统的IEE数据</li>
</ul>
</li>
<li>操纵IEE内存的 <strong>非安全缓存映射</strong> 绕过其安全保护措施<ul>
<li>当一个安全敏感的应用程序被挂起或完成时(即在“switch out”过程中)，IEE系统必须采取一些安全措施来保护IEE数据，防止以后被rich OS访问，攻击者可以通过操纵到用于安全措施的IEE内存的非安全缓存映射来绕过这些安全措施</li>
<li><strong>Ginseng</strong> ：绕过“switch out”过程中强制执行的安全措施，窃取Ginseng系统的IEE数据</li>
</ul>
</li>
<li>在“ <strong>switch out</strong> ”过程中 <strong>窃取</strong> IEE敏感数据，并在“ <strong>switch in</strong> ”过程中 <strong>篡改</strong> IEE数据<ul>
<li>当IEE内存保护是通过动态地控制内存的安全属性(例如，配置它在“switch in”前不安全，而在“switch out”前安全)，缓存存在不完整的安全保护</li>
<li><strong>TrustICE</strong> ：利用在环境交换过程中没有得到很好保护的环境交换内存的非安全缓存，窃取和篡改TrustICE系统的环境交换数据</li>
</ul>
</li>
</ul>
</li>
<li>CITM存在的根本原因：缓存和内存之间的安全相关属性不一致，缓存和内存之间的读写操作不同步。</li>
<li>解决方案：安全配置IEE内存的缓存属性；在环境切换期间，清除到IEE内存的缓存映射</li>
</ul>
<p><strong>IEE的保护措施：</strong></p>
<p>Model1: 非可信程序与敏感型应用并存的方式</p>
<blockquote>
<p>1.为每个安全敏感型应用分配内核隔离存储，处理在并发期间的敏感数据；</p>
<p>2.当安全敏感应用程序的执行被暂停或完成时，在“切出”过程中清理内核隔离的存储，可以保护所有敏感数据免受不信任程序的侵害；</p>
<p>3.在恢复或启动对安全敏感的应用程序的执行时，IEE监视器负责在“切入”过程中还原核心隔离的存储或分配空白的核心隔离的存储。</p>
</blockquote>
<p>Model2：不允许非可信程序与敏感型应用并存：</p>
<blockquote>
<p>单核情况下，运行敏感型应用，直接挂起非可信程序；</p>
<p>多核情况下，即使有空闲核，也将非可信程序挂起。</p>
</blockquote>
<p><strong>本文发现的攻击方式：</strong></p>
<p>可以通过在normal-world OS中操纵cache实现对IEE环境的威胁。以攻击者的视角出发，可以通过一下两种方式入侵IEE:</p>
<blockquote>
<p>1、并发执行期间操纵隔离的内存；</p>
<p>2、篡改IEE中上下文的切换<sup><a href="#fn_switching" id="reffn_switching">switching</a></sup>。</p>
</blockquote>
<h2 id="攻击方法与防御方法"><a href="#攻击方法与防御方法" class="headerlink" title="攻击方法与防御方法"></a>攻击方法与防御方法</h2><h3 id="1-Type-I-并发执行时操纵核间隔离的内存"><a href="#1-Type-I-并发执行时操纵核间隔离的内存" class="headerlink" title="1. Type I 并发执行时操纵核间隔离的内存"></a>1. Type I 并发执行时操纵核间隔离的内存</h3><p><strong>攻击原理：</strong></p>
<p>多核系统中，当主存用作安全敏感型应用程序的核心隔离存储时，并发运行的恶意程序会通过在正常情况下操纵缓存窃取或者修改核心隔离内存中IEE数据。</p>
<p>具体过程：当核心隔离出的内存设置为cacheable时，IEE在内存中的数据将会映射到cache中，因为是在normal-world中的安全敏感型应用访问，所以该cache标记为不安全，并且可能由不受信任的OS操纵。TZC-400 可以用来对主存进行隔离，但是这个硬件不会对cache进行隔离。所以存在被攻击的可能。</p>
<p><strong>SANCTUARY[6] 系统保护机制</strong></p>
<p><code>该系统的核心隔离存储默认禁用L2 cache.</code></p>
<p>IEE 结束后，需要switch out，这时在IEE 中运行的微内核会将属于IEE的内存中数据全置为0，通过这种方式清除敏感数据，同时会设置L1 cache为无效。</p>
<p>IEE启动前，需要switch in，在secure world中的监控器会在IEE中构造一个纯净的执行环境，并且在敏感型应用加载之前设置L1 cache为无效。</p>
<p><strong>SANCTUARY 面临的Type I 攻击</strong></p>
<p><strong>攻击流程：</strong></p>
<p><img src="/2021/03/23/CITM-attacks/image-20210325141138970.png" width="400"></p>
<h3 id="2-Type-II-在换出过程中绕过安全措施"><a href="#2-Type-II-在换出过程中绕过安全措施" class="headerlink" title="2. Type II 在换出过程中绕过安全措施"></a>2. Type II 在换出过程中绕过安全措施</h3><p><strong>攻击原理：</strong></p>
<p>攻击者目标是绕过在IEE上下文切换时的安全保护措施。</p>
<p>因为运行在normal world 中的OS是非信任的，因此切入时的安全措施始终由安全环境中的IEE监视器启动和完成。这些相应的cache line被标记为secure，因此在normal world中无法对其进行更改。攻击者可以利用<strong>cache锁定技术</strong>阻止cache的替换，则IEE 内存中的数据将不会在安全敏感型应用挂起或结束后被清除。从而会被攻击者利用，实现攻击。</p>
<p>【这里指出的切出程序，主要是在两种world间的切换】</p>
<p>为了解决此问题，某些IEE系统选择通过有意从安全敏感的应用程序访问安全内存来引发安全环境中的外部异常中止，从而触发上下文切换。在这过程中，接入到normal world且映射到secure memory的cache lines不是安全的，恶意的OS将可能会操作相应的cache line绕过安全保护措施。(Ginseng [7] )</p>
<p><strong>攻击示意图：</strong></p>
<p><img src="/2021/03/23/CITM-attacks/image-20210326155423911.png" width="400"></p>
<h3 id="3-Type-III-在上下文切换时误用安全性不完整的措施"><a href="#3-Type-III-在上下文切换时误用安全性不完整的措施" class="headerlink" title="3. Type III 在上下文切换时误用安全性不完整的措施"></a>3. Type III 在上下文切换时误用安全性不完整的措施</h3><p><strong>攻击原理：</strong></p>
<p>IEE动态标记Switching程序的安全属性，换出（secure）换入（non-secure）</p>
<p>这是针对的不完整的安全措施，那么就有可能存在切出泄露，切入覆盖原数据的情况。</p>
<p><strong>攻击示意图：</strong></p>
<p><img src="/2021/03/23/CITM-attacks/image-20210326155450688.png" width="400"></p>
<h2 id="Cache-操作—-补充背景知识"><a href="#Cache-操作—-补充背景知识" class="headerlink" title="Cache 操作—- 补充背景知识"></a>Cache 操作—- 补充背景知识</h2><p><img src="/2021/03/23/CITM-attacks/image-20210303110802982.png" width="600"></p>
<p><strong>non-cacheability</strong></p>
<p>[1] 中详细介绍了cacheability与non-cacheability两者的区别</p>
<p>Cache，就是一种缓存机制，它位于CPU和DDR之间，为CPU和DDR之间的读写提供一段内存缓冲区。cache一般是SRAM，它采用了和制作CPU相同的半导体工艺，它的价格比DDR要高，但读写速度要比DDR快不少。例如CPU要执行DDR里的指令，可以一次性的读一块区域的指令到cache里，下次就可以直接从cache里获取指令，而不用反复的去访问速度较慢的DDR。又例如，CPU要写一块数据到DDR里，它可以将数据快速地写到cache里，然后手动执行一条刷新cache的指令就可以将这片数据都更新到DDR里，或者干脆就不刷新，待cache到合适的时候，自己再将内容flush到DDR里。总之一句话，cache的存在意义就是拉近CPU和DDR直接的性能差异，提高整个系统性能。</p>
<p>对于单CPU，不操作外设，只对DDR的读写，可以放心的使用cache。对于其它情况，有两种办法：<br>1 手动更新cache，这需要对外设的机制较为了解，且要找到合适的时机刷新(将cache里的数据flush到内存里)或无效(Invalidate，将cache里的内容清掉，下次再读取的时候需要去DDR里读最新的内容)<br>2 将内存设置为non-cache的，更准确的说是non-cacheable的</p>
<p>在ARM处理器中，一般是采用编译链接时预设的方法来区分cache区域和non-cache区域，在链接脚本或者scatter file里定义不同的section，将需要设为non-cacheable的内存块放置到特定的section里。CPU在启动时会读取这些配置文件，在启动代码里对不同的section配置MMU或MPU，对non-cache的section映射到CPU认识的特拟地址。此后，CPU再访问内存的时候，经过MMU或者MPU，就会知道这块内存是cacheable还是non-cacheable的了。</p>
<p><strong>write-back</strong></p>
<p>CPU更新cache时，只是把更新的cache区标记一下，并不同步更新memory，在被替换时才写回下一级存储层次（memory）中。</p>
<p>[2] 对比了write-through 和 write-back</p>
<p><strong>write-through</strong></p>
<p>CPU向cache写入数据时，同时向memory也写一份，使cache和memory的数据保持一致。</p>
<p><strong>write-allocate</strong></p>
<p>先把要写的数据载入到Cache中，写Cache，然后再通过flush方式写入到内存中。</p>
<p>ARM缓存的状态还会受到其他维护操作的影响，比如 <strong>invalidation</strong> 和 <strong>cleaning</strong> 指令。</p>
<ul>
<li>当执行 <strong>invalidation</strong> 指令时，它直接使保存在缓存中的数据无效。</li>
<li><strong>cleaning</strong> 指令将目标缓存的内容转发到下一级缓存或主存。</li>
</ul>
<h3 id="References"><a href="#References" class="headerlink" title="References"></a>References</h3><p>[1] <a href="https://blog.csdn.net/wbwwf8685/article/details/52091900" target="_blank" rel="noopener">https://blog.csdn.net/wbwwf8685/article/details/52091900</a></p>
<p>[2] <a href="http://witmax.cn/cache-writing-policies.html" target="_blank" rel="noopener">http://witmax.cn/cache-writing-policies.html</a></p>
<p>[3] <a href="https://azeria-labs.com/trusted-execution-environments-tee-and-trustzone/" target="_blank" rel="noopener">https://azeria-labs.com/trusted-execution-environments-tee-and-trustzone/</a></p>
<p>[4] <a href="https://segmentfault.com/a/1190000000387993" target="_blank" rel="noopener">https://segmentfault.com/a/1190000000387993</a></p>
<p>[5] <a href="https://segmentfault.com/a/1190000000387968?utm_source=sf-similar-article" target="_blank" rel="noopener">https://segmentfault.com/a/1190000000387968?utm_source=sf-similar-article</a></p>
<p>[6] Ferdinand Brasser, David Gens, Patrick Jauernig, Ahmad-Reza Sadeghi, and Emmanuel Stapf. 2019. SANCTUARY: ARMing TrustZone with User-space Enclaves.. In NDSS.</p>
<p>[7] Min Hong Yun and Lin Zhong. 2019. Ginseng: Keeping Secrets in Registers When You Distrust the Operating System.. In NDSS.</p>
<blockquote id="fn_switching">
<sup>switching</sup>. 本文指出的换入换出指的是从IEE内部视角看，换出：上下文的切换由IEE到普通OS，换入：上下文切换从OS到IEE.<a href="#reffn_switching" title="Jump back to footnote [switching] in the text."> ↩</a>
</blockquote>
]]></content>
      <categories>
        <category>CCS</category>
      </categories>
      <tags>
        <tag>论文解读</tag>
        <tag>TEE</tag>
      </tags>
  </entry>
  <entry>
    <title>CubicleOS</title>
    <url>/2021/06/16/CubicleOS/</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>DORY</title>
    <url>/2021/01/08/DORY/</url>
    <content><![CDATA[<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">序号</th>
<th style="text-align:center">属性</th>
<th style="text-align:center">内容</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">原文PDF</td>
<td style="text-align:center"><a href="https://www.usenix.org/system/files/osdi20-dauterman_dory.pdf" target="_blank" rel="noopener">DORY</a></td>
</tr>
<tr>
<td style="text-align:center">2</td>
<td style="text-align:center">作者信息</td>
<td style="text-align:center">加州大学伯克利分校 <a href="https://people.eecs.berkeley.edu/~edauterman/" target="_blank" rel="noopener">emma</a> <a href="https://people.eecs.berkeley.edu/~raluca/#Awards" target="_blank" rel="noopener">Raluca</a></td>
</tr>
<tr>
<td style="text-align:center">3</td>
<td style="text-align:center">核心内容</td>
<td style="text-align:center">保证在对加密数据查询时没有信息泄露</td>
</tr>
<tr>
<td style="text-align:center">4</td>
<td style="text-align:center">研究领域</td>
<td style="text-align:center">隐私防护</td>
</tr>
<tr>
<td style="text-align:center">5</td>
<td style="text-align:center">全文总览</td>
<td style="text-align:center">构造一个对加密数据进行高效的，无泄露的系统</td>
</tr>
</tbody>
</table>
</div>
<h3 id="全文总览"><a href="#全文总览" class="headerlink" title="全文总览"></a>全文总览</h3><p>$DORY:$ <strong>D</strong>ecentralized <strong>O</strong>blivious <strong>R</strong>etrieval s<strong>Y</strong>stem (分布式无记忆性检索系统)</p>
<p>  该系统实现加密查找并且能在服务端分散信任，它保证攻击者不会同时攻击全部的主机，并且无法从攻击的服务端学习到搜索访问模式。</p>
<p>  对加密数据进行高效，无泄漏的搜索仍然是过去二十年中一个尚未解决的问题。作者调研了5家提供端到端加密文件共享的公司，了解了他们对显示世界的需求并保护搜索访问模式<sup><a href="#fn_搜索访问模式" id="reffn_搜索访问模式">搜索访问模式</a></sup>。</p>
<ol>
<li>作者设计并实现了DORY系统，可以保护搜索访问模式；</li>
<li>并且DORY在多个服务器之间分配信任，以防止控制其中除一台以外的全部主机；</li>
<li>作者开发新的密码和系统技术，以满足查询的效率和信任模型需求。</li>
</ol>
<p>  DORY的性能比 <a href="https://en.wikipedia.org/wiki/Oblivious_RAM" target="_blank" rel="noopener">Oblivious RAM</a> 好几个数量级。在8台服务器（每个服务器有16个CPU）上并行运行时，DORY花费116ms来搜索大约5万个文档，花费862ms来搜索100万个文档。</p>
<h3 id="研究问题"><a href="#研究问题" class="headerlink" title="研究问题"></a>研究问题</h3><p>单词级别的泄露</p>
<p><img src="/2021/01/08/DORY/attack.png" width="500px"></p>
<h4 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h4><p>加密数据搜索目前存在两种</p>
<ol>
<li><p>泄漏搜索访问</p>
<p>攻击者可以不断的向服务器发送单词级别的搜索，通过服务器的响应来判断该文本是否存在于，最终通过搜索全部单词，找到目标文本所包含的内容，重构出文本，实现攻击。</p>
</li>
<li><p>非泄露访问，但是十分昂贵</p>
<p>ORAM 在服务器运行的时间代价是$2^{O(\sqrt{\log n \log \log n})}$，访问开销为 $O\left(\log ^{2} n\right)$ </p>
<p>设计系统目标</p>
<p><img src="/2021/01/08/DORY/dory.png" width="500px"></p>
</li>
</ol>
<h3 id="调研结果"><a href="#调研结果" class="headerlink" title="调研结果"></a>调研结果</h3><p><strong>第一个调研文件共享中加密查询需求</strong></p>
<p>亮点：切实的应用驱动创新</p>
<p>  这篇文章是第一个对实际的文件共享加密查询需求的调研，对目前主流的5家公司(Keybase, PreVeil, SpiderOak, Sync, and Tresorit)进行了实实在在的分析，并根据自己统计的信息总结出优化的方案，正是这项调研结果激发了DORY的设计动机。(Section 2)</p>
<h4 id="系统需求"><a href="#系统需求" class="headerlink" title="系统需求"></a>系统需求</h4><p>  在调研的过程中发现几家公司的共同点是都有对数据进行加密的需求，并且目前都有在服务端对加密数据进行查询的需求。那么在构建这样一个服务端的加密查询系统时要满足一下的要求：</p>
<p><strong>搜索响应</strong>： 百万文档数量的搜索延迟在500ms到4s之间</p>
<p><strong>用户花费</strong>： 用户每月的费用在 $0.7 左右</p>
<p><strong>分布式一致性</strong>：多个用户（单用户多客户端）可以访问一个文件，因此搜索时要保证用户之间的一致性</p>
<p><strong>撤销用户访问要廉价</strong>：公司目前采用的是懒惰撤销<sup><a href="#fn_懒惰撤销" id="reffn_懒惰撤销">懒惰撤销</a></sup>用户的访问权限，即为其他的用户创建新的秘钥，当其他用户访问文档时才使用新秘钥进行更新，而不是在撤销访问权限后，立马对全部文档进行更新，所以被撤销的用户依然可以使用原始秘钥访问从未更新过的文档内容。这些公司希望采用类似的搜索方法。</p>
<p><strong>系统松弛性</strong>：这些公司不要求搜索结果是最新的（它们可能会持续几分钟的时间），并且他们也愿意接受少量的误报。</p>
<p><strong>隐藏搜索访问模式</strong>：这些公司希望保证至少一个信任域是真诚的时候，攻击者将无法学习搜索访问模式。</p>
<p><strong>搜索访问模式的分布式信任</strong>：公司希望通过确保将n个搜索索引放在一起不会轻易为攻击者提供纯文本搜索索引，来限制攻击者破坏所有n个信任域所造成的损害。例如，如果公司被传唤，并且每个信任域都必须从那时起移交其搜索索引和搜索访问模式，则公司可以选择暂停搜索服务以通过减少搜索访问模式泄漏来保护用户的隐私。</p>
<h4 id="分布式信任"><a href="#分布式信任" class="headerlink" title="分布式信任"></a>分布式信任</h4><p><strong>跨云分裂</strong>：通过将不同的云视为不同的信任域，恶意云提供者（或可以利用一个云基础架构中的漏洞的攻击者）无法访问两个信任域。</p>
<p><strong>跨机构拆分</strong>：通过在竞争性组织或公众普遍信任的非营利组织（例如，电子前沿基金会）中使用信任域，用户可以更有力地保证组织不太可能合谋。</p>
<p><strong>跨地区划分</strong>：通过将司法管辖区（即不同的国家）分开来划分信任域，单个法律机构就无法访问整个系统。</p>
<p>如果将信任域部署在云中，则我们可以利用以下事实：从金钱上激励云提供商以提供可用性。故障停止仍然可以自然发生，但是云提供商可以轻松检测故障并启动新服务器。客户可以报告缺乏信任域可用性的统计信息，部署系统的组织可以将其业务转移到其他地方。</p>
<h3 id="DORY-设计"><a href="#DORY-设计" class="headerlink" title="DORY 设计"></a>DORY 设计</h3><h4 id="优化查询"><a href="#优化查询" class="headerlink" title="优化查询"></a>优化查询</h4><p>ORAM更新为DPFs <a href="https://en.wikipedia.org/wiki/Distributed_point_function" target="_blank" rel="noopener">分布点函数</a></p>
<h4 id="设计并优化索引"><a href="#设计并优化索引" class="headerlink" title="设计并优化索引"></a>设计并优化索引</h4><p>构建位图索引并使用布隆过滤器优化 (Section 4.1)</p>
<p><img src="/2021/01/08/DORY/update.png" width="500px"></p>
<p><img src="/2021/01/08/DORY/search.png" width="500px"></p>
<p><img src="/2021/01/08/DORY/bloom.png" width="500px"></p>
<h4 id="加密并优化索引"><a href="#加密并优化索引" class="headerlink" title="加密并优化索引"></a>加密并优化索引</h4><p>采用随机一次填充优化加密方案 (Section 4.1)</p>
<h4 id="阻止恶意攻击并减少代价"><a href="#阻止恶意攻击并减少代价" class="headerlink" title="阻止恶意攻击并减少代价"></a>阻止恶意攻击并减少代价</h4><p>采用聚合MAC <a href="">3</a> <a href="https://ieeexplore.ieee.org/document/4594983">Aggregate MAC</a> 减少防御代价 (Section 4.3)</p>
<h4 id="提供容错机制并减少代价"><a href="#提供容错机制并减少代价" class="headerlink" title="提供容错机制并减少代价"></a>提供容错机制并减少代价</h4><p>采用比拜占庭容错更加优异的容错算法 (Section 5)</p>
<p>map 大小设置 [5]</p>
<pre><code class="lang-go">var numBlocksMap = map[int]int{
    1024: 16479,
    2048: 18187,
    4096: 20220,
    8192: 25782,
    16384: 37739,
    32768: 69029,
    65536: 104213,
    131072: 179095,
    262144: 344721,
}
</code></pre>
<p>源码设置的bloomfilter大小 [4]</p>
<pre><code class="lang-go">func main() {
    /* Set up config */
    filename := flag.String("config", "src/config/server1.config", "server config file")
    maxDocs := flag.Int("max_docs", 256, "max number of documents")
    bloomFilterSz := flag.Int("bf_sz", 128, "bloom filter size in bits")
    flag.Parse()

    var err error
    config, err = setupConfig(*filename)
    if err != nil {
        log.Fatalln("Error retrieving config file: ", err)
    }

    /* Initialize server */
    log.Println("Starting initialization...")
    C.setSystemParams(C.int(*bloomFilterSz), C.int(*maxDocs));
    sOld = &amp;C.server{}
    sNew = &amp;C.server{}
    C.initializeServer((*C.server)(sOld), C.int(kNumThreads))
    C.initializeServer((*C.server)(sNew), C.int(kNumThreads))
    oldVersionNum = 0
    newVersionNum = 0

    /* Start listening */
    log.Println("Listening...")
    err = common.ListenLoop(config.Port, config.CertFile, config.KeyFile, handleConnection)
    if err != nil {
        log.Fatalln(err)
    }
}
</code></pre>
<blockquote id="fn_MAC">
<sup>MAC</sup>.  <a href="https://sci-hub.se/10.1109/ISIT.2008.4594983" target="_blank" rel="noopener">[2]</a>  MAC讲解[3]<a href="#reffn_MAC" title="Jump back to footnote [MAC] in the text."> ↩</a>
</blockquote>
<blockquote id="fn_DPFs">
<sup>DPFs</sup>.  在密码学中，分布式点函数是一种加密原语，它允许两个分布式进程共享一条信息，并计算它们共享信息的功能，而不会向任何一个进程透露信息本身。<a href="#reffn_DPFs" title="Jump back to footnote [DPFs] in the text."> ↩</a>
</blockquote>
<blockquote id="fn_懒惰撤销">
<sup>懒惰撤销</sup>.  为了降低撤销的成本，可以将重新加密延迟到文件更新之前。懒惰撤销的概念最早是在Cepheus中提出的。这个想法是，如果被撤消的读者仍然可以读取未更改的文件，则不会在安全方面造成重大损失。仅当创建新数据时，才会进行昂贵的重新加密。仍然需要立即更改元数据，以防止被撤消的编写者进一步写入。<a href="#reffn_懒惰撤销" title="Jump back to footnote [懒惰撤销] in the text."> ↩</a>
</blockquote>
<blockquote id="fn_搜索访问模式">
<sup>搜索访问模式</sup>.  在加密的搜索系统中，当用户在文件夹内的文件上搜索关键字时，服务器仅获悉用户在该文件夹中进行了搜索，而没有获悉与该搜索相匹配的文档，与之匹配的文档数量或有关该文档的其他信息或者关键词。<a href="#reffn_搜索访问模式" title="Jump back to footnote [搜索访问模式] in the text."> ↩</a>
</blockquote>
<h3 id="References"><a href="#References" class="headerlink" title="References"></a>References</h3><p>[1] <a href="https://en.wikipedia.org/wiki/Oblivious_RAM" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Oblivious_RAM</a></p>
<p>[2] Chan A C F, Castelluccia C. On the (im) possibility of aggregate message authentication codes[C]//2008 IEEE International Symposium on Information Theory. IEEE, 2008: 235-239.</p>
<p>[3] <a href="https://blog.csdn.net/qq_30505673/article/details/82432454" target="_blank" rel="noopener">https://blog.csdn.net/qq_30505673/article/details/82432454</a></p>
<p>[4] <a href="https://github.com/ucbrise/dory/blob/2617c2bbdfbdf4cd453c798fb6c7560dde59aaa4/src/server/server.go" target="_blank" rel="noopener">https://github.com/ucbrise/dory/blob/2617c2bbdfbdf4cd453c798fb6c7560dde59aaa4/src/server/server.go</a></p>
<p>[5] <a href="https://github.com/ucbrise/dory/blob/2617c2bbdfbdf4cd453c798fb6c7560dde59aaa4/baseline/src/server/run_server.go" target="_blank" rel="noopener">https://github.com/ucbrise/dory/blob/2617c2bbdfbdf4cd453c798fb6c7560dde59aaa4/baseline/src/server/run_server.go</a></p>
]]></content>
      <categories>
        <category>OSDI</category>
      </categories>
      <tags>
        <tag>论文解读</tag>
      </tags>
  </entry>
  <entry>
    <title>Attacks Directories, Not Caches</title>
    <url>/2020/07/17/Attacks-Directories-Not-Caches/</url>
    <content><![CDATA[<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">序号</th>
<th style="text-align:center">属性</th>
<th style="text-align:center">内容</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">原文PDF</td>
<td style="text-align:center"><a href="">Attack Directories, Not Caches: Side-Channel Attacks in a Non-Inclusive World</a></td>
</tr>
<tr>
<td style="text-align:center">2</td>
<td style="text-align:center">作者信息</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">3</td>
<td style="text-align:center">核心内容</td>
<td style="text-align:center">Side Channel Attack</td>
</tr>
<tr>
<td style="text-align:center">4</td>
<td style="text-align:center">研究领域</td>
<td style="text-align:center">Attack, Cache</td>
</tr>
<tr>
<td style="text-align:center">5</td>
<td style="text-align:center">全文总览</td>
<td style="text-align:center">基于缓存的侧信道攻击在新型缓存的攻击实践</td>
</tr>
</tbody>
</table>
</div>
<h3 id="0-Main-idea"><a href="#0-Main-idea" class="headerlink" title="0. Main idea"></a>0. Main idea</h3>]]></content>
      <categories>
        <category>Security and Privacy</category>
      </categories>
      <tags>
        <tag>TODO</tag>
        <tag>论文解读</tag>
        <tag>side channel attack</tag>
      </tags>
  </entry>
  <entry>
    <title>Dancing with Wolves</title>
    <url>/2020/06/27/Dancing-with-Wolves/</url>
    <content><![CDATA[<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">序号</th>
<th style="text-align:center">属性</th>
<th style="text-align:center">内容</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">原文PDF</td>
<td style="text-align:center"><a href="https://dl.acm.org/doi/pdf/10.1145/3050748.3050750" target="_blank" rel="noopener">Dancing with wolves</a></td>
</tr>
<tr>
<td style="text-align:center">2</td>
<td style="text-align:center">作者信息</td>
<td style="text-align:center">Liang Deng,Nanjing University</td>
</tr>
<tr>
<td style="text-align:center">3</td>
<td style="text-align:center">核心内容</td>
<td style="text-align:center">对非可信的VMM进行事件监测</td>
</tr>
<tr>
<td style="text-align:center">4</td>
<td style="text-align:center">研究领域</td>
<td style="text-align:center">检测</td>
</tr>
<tr>
<td style="text-align:center">5</td>
<td style="text-align:center">全文总览</td>
<td style="text-align:center">通过ASR与IPR技术，ED-monitor可以及时、频繁地对VMM的监测</td>
</tr>
</tbody>
</table>
</div>
<h3 id="Main-idea"><a href="#Main-idea" class="headerlink" title="Main idea"></a>Main idea</h3><p>  VMM的执行权限最高，一旦VMM受到威胁，那么其所处的整个云环境都会受到威胁。因此本文目标是对云计算中非可信的VMM实时攻击进行事件驱动监控。为了保证VMM事件监控的可靠性，需要保证monitor自身的可靠。在具体实现过程中，将VMM的特权级指令清空，并转移到monitor执行。通过IPR实现对VMM特权级指令的拦截，通过ASR技术防止VMM篡改hook函数位置和VMM自身的代码。</p>
<p>  Q: 为什么要提供事件监测？</p>
<p>  A: 因为对于瞬时攻击而言，仅通过轮询的方式对VMM进行完整性监测，很难捕捉到攻击的踪迹，但是基于事件的方式则可以对攻击所触发的事件进行拦截。</p>
<p>本文是国家自然基金项目支持，代码并未开源。</p>
<h3 id="ED-monitor"><a href="#ED-monitor" class="headerlink" title="ED-monitor"></a>ED-monitor</h3><p>  实现事件监控对monitor的要求：monitor与VMM具有相同的执行权限（避免了不同权限之间转换带来的性能损失），monitor需要及时频繁地被调用。</p>
<p>  读到这里，感觉再往下深入就是解决几个问题：</p>
<ol>
<li><p>如何实现ASR？</p>
</li>
<li><p>如何实现IPR？</p>
</li>
<li><p>如何触发monitor？</p>
<p>当需要在VMM中调用特权级指令的时候，会对monitor进行调用。</p>
</li>
<li><p>如何保证monitor的完整性？</p>
<p>分为monitor memory完整性、控制流完整性和定制VMM调用monitor接口实现。</p>
</li>
<li><p>如何保证VMM不对自身hook函数的篡改？对hypervisor所有事件添加hook？</p>
<p>采用W+X mapping policy对code hook的保护；</p>
<p>使用SPT保护data hook.</p>
</li>
<li><p>安全性分析？</p>
<p>几种保护机制可以满足安全的需求。可以实现对特权级指令的拦截、对其验证、防止对monitor的篡改，从而保证了monitor的完整性。IPR与ASR可以实现对原型的保护。</p>
</li>
<li><p>原型实现？</p>
</li>
</ol>
<h3 id="0-Abstract"><a href="#0-Abstract" class="headerlink" title="0 Abstract"></a>0 Abstract</h3><p>高风险漏洞可能会使VMMS完全受损</p>
<p>（这里提出的目的是说明在非信任环境中进行检测是十分必要的）</p>
<p>VMM拥有最高执行权限，如果它被攻击的话，将会威胁整个环境，因此对VMM进行检测是必要的。</p>
<p>main idea: 对云计算中非可信的VMM进行事件监控，不需要比VMM更高的特权级别也不需要特殊硬件的支持。</p>
<h3 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1 Introduction"></a>1 Introduction</h3><p>监控器应与VMM 处于相同的特权级别，并且在之间的转换上不能产生大量的时间代价</p>
<p>且为了实现通过监控器就能捕获VMM的事件，需要保证监控器本身的完整性以及能够获取到VMM的事件，此时认为VMM是处于非可信状态的。</p>
<p>Q: SMM不能读取MMU的配置，所以不适格作为事件驱动器的实现，也就是事件驱动监控器必须要获得MMU的配置？</p>
<p>Q：这种基于事件驱动的监控，与时间依赖的关系？</p>
<p>瞬时攻击能不能进行？</p>
<p>本意：如果及时并且频繁的调用该监控器，那么就可以阻止瞬时攻击？</p>
<p>当事件被触发就可以调用monitor，从而对VMM进行保护？</p>
<p>当VMM访问监控器数据的时候，将会及时地调用监控程序进行完整性评估</p>
<h3 id="2-Overview"><a href="#2-Overview" class="headerlink" title="2 Overview"></a>2 Overview</h3><h4 id="2-1-Threat-model"><a href="#2-1-Threat-model" class="headerlink" title="2.1 Threat model"></a>2.1 Threat model</h4><p>  认为威胁来自于VMM，VMM拥有最高的执行权限，而且能够获取到内存或者磁盘中任意数据。如果VMM受到攻击的话，则攻击者具备VMM的权限，威胁整个机器。不考虑硬件威胁，开机过程也受信任。</p>
<h4 id="2-2-Eventdriven-VMM-Monitoring"><a href="#2-2-Eventdriven-VMM-Monitoring" class="headerlink" title="2.2 Eventdriven VMM Monitoring"></a>2.2 Eventdriven VMM Monitoring</h4><p>hook 函数</p>
<p>做什么的？</p>
<p>钩子函数是置于VMM中的触发函数，目的是捕获指定的VMM事件行为，当产生这些行为的时候，VMM会运行钩子函数，从而激发对VMM完整性的检测。</p>
<p>钩子函数通常如何设置？</p>
<p>这些钩子函数可以是插入VMM代码中任意位置的代码挂钩（跳转指令），调用表内的数据挂钩或任何其他可以传输控制流的技术。</p>
<h4 id="2-3-Placing-the-Monitor-in-the-Same-World"><a href="#2-3-Placing-the-Monitor-in-the-Same-World" class="headerlink" title="2.3 Placing the Monitor in the Same World"></a>2.3 Placing the Monitor in the Same World</h4><h4 id="2-4-Requirements-and-Challenges"><a href="#2-4-Requirements-and-Challenges" class="headerlink" title="2.4 Requirements and Challenges"></a>2.4 Requirements and Challenges</h4><p>保证ED-monitor 是受信任的，即保证monitor自身的完整性，该monitor不能被VMM篡改</p>
<ol>
<li><p>内存、控制流、入口</p>
</li>
<li><p>hook 函数的位置不应该别VMM篡改（这个如何实现？）【因为VMM有 最高执行权限】</p>
</li>
</ol>
<h4 id="2-5-Our-Approach-Multual-Protection"><a href="#2-5-Our-Approach-Multual-Protection" class="headerlink" title="2.5 Our Approach: Multual-Protection"></a>2.5 Our Approach: Multual-Protection</h4><p>Q:这里写的比较简略，地址空间随机化如何能保证code和data？但VMM具备了最高执行权限，会有效果吗？（应用级别攻击）</p>
<p>下文提到，VMM的权限可以获取到随机化后的monitor的remap，因此目前的ASR对事件的监控可能是无效的。本文的想法是限制VMM的特权指令，并让monitor代替执行最高权限。（这样VMM中进行最高权限的操作将会被monitor捕获）</p>
<p>本文的解决方法是：同时使用ASR和本文提出的IPR（基于工具的指令限制）方法，IPR通过ASR保证对VMM最高权限操作的拦截与验证，同时ASR基于IPR减轻部分威胁（来自于谁的威胁？）</p>
<p>ASR：这种技术主要是对进程的表、堆、主程序代码、静态数据段、共享库等所在的地址进行随机化。如果某些代码的位置固定，那么一份攻击成功的话，就可以应用到其他机器继续进行攻击。因此ASR技术可以降低攻击成功的概率，并且使得攻击难以移植。</p>
<p>另：一种技术叫做ALSR，Address space layout randomization，地址空间布局随机化</p>
]]></content>
      <categories>
        <category>VEE</category>
      </categories>
      <tags>
        <tag>论文解读</tag>
        <tag>System Security</tag>
        <tag>Detection</tag>
        <tag>Event-driven</tag>
      </tags>
  </entry>
  <entry>
    <title>EFI UEFI BIOS</title>
    <url>/2021/07/23/EFI-UEFI-BIOS/</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>GiantVM</title>
    <url>/2021/04/26/GiantVM/</url>
    <content><![CDATA[]]></content>
      <tags>
        <tag>TODO</tag>
      </tags>
  </entry>
  <entry>
    <title>CloudVisor-D</title>
    <url>/2020/10/18/CloudVisor-D/</url>
    <content><![CDATA[<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">序号</th>
<th style="text-align:center">属性</th>
<th style="text-align:center">内容</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">原文PDF</td>
<td style="text-align:center"><a href="https://www.usenix.org/system/files/sec20summer_mi_prepub.pdf" target="_blank" rel="noopener">CloudViso-D</a></td>
</tr>
<tr>
<td style="text-align:center">2</td>
<td style="text-align:center">作者信息</td>
<td style="text-align:center">IPADS，Shanghai Jiao Tong University</td>
</tr>
<tr>
<td style="text-align:center">3</td>
<td style="text-align:center">核心内容</td>
<td style="text-align:center">Untrusted Hypervisor，解耦是嵌套虚拟化技术，非可信平台保护VMs</td>
</tr>
<tr>
<td style="text-align:center">4</td>
<td style="text-align:center">研究领域</td>
<td style="text-align:center">Virtualization， Cloud Platform</td>
</tr>
<tr>
<td style="text-align:center">5</td>
<td style="text-align:center">全文总览</td>
<td style="text-align:center">CloudVisor-D将传统嵌套虚拟化的架构分解为两个模块，能在无需引起虚拟机下陷的情况下将大多数虚拟机操作转交给可信的守卫模块处理，大幅度提升嵌套虚拟化技术的性能。</td>
</tr>
</tbody>
</table>
</div>
<h3 id="全文概览"><a href="#全文概览" class="headerlink" title="全文概览"></a>全文概览</h3><p>​        本文首次提出解耦式嵌套虚拟化技术，可以在恶意虚拟机监控器环境下实现虚拟机隐私的高效保护，并基于此开发了 CloudVisor-D 系统。该技术将传统嵌套虚拟化的架构分解为两个模块，能在无需引起虚拟机下陷的情况下将大多数虚拟机操作转交给可信的守卫模块处理，大幅度提升嵌套虚拟化技术的性能。通过利用最新硬件的功能，使得VM多数的特权级别操作不需要触发<code>VM Exit</code>， 即无需退出到嵌套的<code>Hypervisor</code>中，这是先前<code>CloudVisor</code>设计中性能下降的主要原因。</p>
<p>​        该工作是<code>IPADS</code>实验室<code>CloudVisor[SOSP' 11]</code>系统的后续之作，也是继 CHAOS [ISTR’07]、HyperCoffer [HPCA’13]、TxIntro [HPCA’14]、CrossOver [ISCA’15]、SeCage [CCS’15]、Nexen [NDSS’17] 、EPTI [ATC’18]、SkyBridge [EuroSys’19]等系列工作之后，在虚拟化隔离与安全方面的延续工作。</p>
<p><img src="/2020/10/18/CloudVisor-D/summary.png"></p>
<h3 id="CloudVisor-D"><a href="#CloudVisor-D" class="headerlink" title="CloudVisor-D"></a>CloudVisor-D</h3><p>​        云中多租户的前提是云平台能够提供给用户隐私与完整性保护，然而提供这个前提的hypervisor 被其存在的漏洞严重的威胁。事实上，随着hypervisor代码量的不断增加，在Xen中发现的代码漏洞正在不断的增加。现有的方法是在软件以及硬件方面都有瑕疵，会导致性能的下降。</p>
<p>​        本文利用嵌套虚拟化技术,目的是保护部署在同一个物理机上的客户虚拟机安全。CloudVisor-D解决了嵌套虚拟化的不足，并设计了一个分解的嵌套虚拟化管理器。通过分解，hypervisor分解为小型的管理程序，在非特权模式下，分解为一组guardian-VM（不是完整的VM，仅包含一些服务处理程序，对于商业虚拟机管理器是透明的），并为每一个客户虚拟机提供一个，因此消耗的资源很少。基于新硬件的特征，Guardian-VM能够在不退出VM的情况下执行卸载VM的操作，通过这种G-VM的帮助，客户VM可以直接调用超级调用命令，而且不需要陷入RootVisor中。常规EPT违规将在来宾模式下转换为异常，然后由Guardian-VM重定向到SubVisor进行处理。</p>
<p>​        但是在客户模式下，VM或SubVisor可能会恶意切换EPT以绕过甚至攻击Guardian-VM。有一些工作在假设不能够修改CR3寄存器数值的前提的下解决上述问题，但本文并不基于此种假设。本文在CloudVisor-D中提供了一系列的技术来保护：</p>
<ol>
<li><p>RootVisor创建出一个隔离的环境使得Guardian-VM不会被篡改；</p>
</li>
<li><p>每个Guardian-VM都会强制其在客户VM和SubVisor之间以客户模式插入所有通信路径。</p>
<p><img src="/2020/10/18/CloudVisor-D/comparison.jpg"></p>
</li>
</ol>
<p>​        CloudVisor-D通过解耦合的设计来解决嵌套虚拟化(<strong>CloudVisor工作</strong> )的不足，方法是在特权模式下将嵌套的管理程序功能分解为微小的嵌套管理程序（RootVisor），在非特权模式下将其分解为一组Guardian-VM。这种分解的设计为每个来宾VM提供一个Guardian-VM，并将大多数保护逻辑卸载到每个Guardian-VM，而小型RootVisor负责将所有Guardian-VM与商业虚拟机管理程序（SubVisor）和来宾VM隔离。 Guardian-VM不是完整的VM，而仅包含一些服务处理程序，并且对于SubVisor是不可见的。 </p>
<p>​        Guardian-VM可以处理VM操作，而无需信任来宾VM和SubVisor。 具体来说，Guardian-VM要求相应的VM只能调用跳转表中列出的有限范围内的功能。 此外，它为每个来宾VM向SubVisor提供了一个影子EPT，并在将其复制回真实EPT之前仔细检查了SubVisor对影子EPT所做的更新。 最后，Guardian-VM还可以保护其来宾VM的I / O数据的隐私和完整性。</p>
<h3 id="虚拟机退出"><a href="#虚拟机退出" class="headerlink" title="虚拟机退出"></a>虚拟机退出</h3><p>VM响应某些指令而退出，并且事件（例如页面错误）是虚拟化系统中性能下降的关键来源。但是您是否想过为什么？无论如何，VM退出过程中到底会发生什么？</p>
<p>VM出口标志着在当前运行的VM和必须出于特定原因而必须执行系统控制的VMM（管理程序）之间进行转换的点。通常，处理器必须在退出时保存VM运行时的状态快照。对于英特尔架构，以下是这些步骤的近似值：</p>
<p>1.在VM退出信息字段中记录有关VM退出原因的信息（退出原因，来宾地址），并更新VM进入控制字段。</p>
<p>2.将处理器状态保存在来宾状态区域中。其中包括控制寄存器，调试寄存器，MSR（请参见下一项），段寄存器，描述符表寄存器，RIP，RSP和RFLAGS，以及未注册状态（如未决的调试异常）。</p>
<p>3.将MSR保存在VM退出MSR存储区中。如果您不熟悉，MSR代表机器专用寄存器。它们用于控制和报告处理器性能。</p>
<p>4.根据主机状态区域和某些VM退出控件加载处理器状态。这包括主机控制寄存器，调试寄存器，MSR，主机表和描述符表寄存器，RIP，RSP和RFLAGS，页目录指针表条目以及非寄存器状态。</p>
<p>5.从VM退出MSR加载区域加载MSR。</p>
<p>在VMM执行其系统管理功能之后，将执行相应的VM条目，该条目将处理器控制从VMM过渡到VM！</p>
<h3 id="嵌套虚拟化？"><a href="#嵌套虚拟化？" class="headerlink" title="嵌套虚拟化？"></a>嵌套虚拟化？</h3><h3 id="阅读时的问题："><a href="#阅读时的问题：" class="headerlink" title="阅读时的问题："></a>阅读时的问题：</h3><ol>
<li><p>本文提到的硬件（SGX）与即将用到的硬件（TPM）分别都是什么，有什么区别、联系？</p>
<p>TPM与SGX都是安全芯片，Intel SGX最关键的优势在于将程序以外的software stack如OS和BIOS都排除在了TCB（Trusted Computing Base）以外，在enclave里的code只信任自己和intel的CPU。TPM在开机过程中需要构建信任链，逐步确立信任。但是SGX仅仅在用户权限下使用，TPM则在特权级别下使用。</p>
</li>
<li><p>嵌套虚拟化需要VM退出？CloudVisor-D版本的嵌套虚拟化怎么就解决了前者的问题？</p>
<p>嵌套虚拟化是指将原来的hypervisor转移到非特权模式下，命名为SubVisor，在特权模式下构建一个受信任的虚拟机管理器（RootVisor），VM与SubVisor的任何通讯都要经过RootVisor进行检查，从而避免漏洞注入到SubVisor中。</p>
<p><a href="https://www.cnblogs.com/kelamoyujuzhen/p/10115167.html" target="_blank" rel="noopener">https://www.cnblogs.com/kelamoyujuzhen/p/10115167.html</a></p>
</li>
<li><p>文中出现的RootVisor、SubVisor是什么关系？</p>
<p>RootVisor是新构建的一个特权级别的虚拟机管理，类似于修改前的hypervisor，对费特权级别的VM以及SubVisor进行管理。</p>
<p>SubVisor是将原始的hypervisor移动到非特权级别下的名称，在非特权模式下，仍然保留了创建虚拟机的功能。</p>
</li>
<li><p>详细指出半虚拟化与全虚拟化的关系？<br>后者效率比较低下。</p>
</li>
<li><p>2.2节中为什么EPT有4层违规？介绍下EPT？</p>
<p>Intel EPT应该有5级分页，经历4次地址拼接，所以在寻址的时候，最差情况下要经历4次地址miss，导致4次VM exit.</p>
</li>
<li><p>虚拟化异常是什么？</p>
</li>
<li><p>谈论虚拟化安全一般会从几个方面入手，分别都是什么？（性能？可靠性？）</p>
</li>
<li><p>Ring0与特权模式的关系、区别？</p>
<p><a href="https://www.cnblogs.com/xusongwei/archive/2012/07/30/2615592.html" target="_blank" rel="noopener">https://www.cnblogs.com/xusongwei/archive/2012/07/30/2615592.html</a></p>
</li>
<li><p>本文用到的技术？</p>
<ol>
<li>TPM</li>
<li>SSL</li>
</ol>
</li>
<li><p>本文提到的加密是怎么回事？</p>
<p>涉及到IO传输，对传输的数据进行加密，防止被恶意窃取。</p>
</li>
<li><p>以文中提到的虚拟机退出次数为例，本文只在Xen与CloudVisor间做了比较，说明后者产生更多的VM Exit，而CloudVisor-D是利用新硬件特性进行的部署，是所以VM Exit的次数明显减少，但是如果直接在CloudVisor上进行改进呢？</p>
<p>​        本文所利用的指令，VMFUNC，是可以在非特权级别下进行操作并寻得EPTP表的，本文并未提到在特权模式下的转换会不会涉及到VM Exit（是会触发VM Exit的），这样的话，仅仅在CloudVisor架构基础上利用新硬件，并不能达到其最佳的效果。简言之，<code>利用VMFUNC指令在非特权模式下进行EPT Switching操作不会引发VM Exit 的特性</code>，进行优化，很大程度上减少了VM Exit的次数。又要保证这种更改之后的可靠性，所以加入了Guardian-VM.</p>
</li>
<li><p>虚拟化异常不会触发VM Exit吗?</p>
</li>
<li><p>文中指出的EPT存在哪里？</p>
<p>指的是适配硬件虚拟化的 intel 扩展页表。</p>
</li>
</ol>
<h3 id="References"><a href="#References" class="headerlink" title="References"></a>References</h3><p>[1] <a href="https://www.cnblogs.com/ck1020/p/6043054.html" target="_blank" rel="noopener">intel EPT 机制详解</a></p>
<p>[2] <a href="https://www.facebook.com/notes/intel/virtualization-and-performance-understanding-vm-exits/97103992067/" target="_blank" rel="noopener">Understanding VM Exits</a></p>
]]></content>
      <categories>
        <category>Security</category>
      </categories>
      <tags>
        <tag>论文解读</tag>
        <tag>Untrusted Hypervisor</tag>
        <tag>Virtualization</tag>
      </tags>
  </entry>
  <entry>
    <title>Google Technology</title>
    <url>/2020/11/23/Google-Technology/</url>
    <content><![CDATA[<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">序号</th>
<th style="text-align:center">属性</th>
<th style="text-align:center">内容</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">原文PDF</td>
<td style="text-align:center"><a href="https://static.googleusercontent.com/media/research.google.com/zh-CN//archive/gfs-sosp2003.pdf" target="_blank" rel="noopener">GFS</a> <a href="https://static.googleusercontent.com/media/research.google.com/zh-CN//archive/mapreduce-osdi04.pdf" target="_blank" rel="noopener">MapReduce</a> <a href="https://storage.googleapis.com/pub-tools-public-publication-data/pdf/68a74a85e1662fe02ff3967497f31fda7f32225c.pdf" target="_blank" rel="noopener">Bigtable</a> <a href="https://static.googleusercontent.com/media/research.google.com/zh-CN//archive/spanner-osdi2012.pdf" target="_blank" rel="noopener">Spanner</a></td>
</tr>
<tr>
<td style="text-align:center">2</td>
<td style="text-align:center">作者信息</td>
<td style="text-align:center">google</td>
</tr>
<tr>
<td style="text-align:center">3</td>
<td style="text-align:center">核心内容</td>
<td style="text-align:center">分布式文件系统、数据存储系统等技术</td>
</tr>
<tr>
<td style="text-align:center">4</td>
<td style="text-align:center">研究领域</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">5</td>
<td style="text-align:center">全文总览</td>
</tr>
</tbody>
</table>
</div>
<p>分4个文章说一下</p>
]]></content>
      <categories>
        <category>google</category>
      </categories>
      <tags>
        <tag>TODO</tag>
        <tag>论文解读</tag>
      </tags>
  </entry>
  <entry>
    <title>Information theoretic framework</title>
    <url>/2021/03/15/Information-theoretic-framework/</url>
    <content><![CDATA[<h2 id="四条公理"><a href="#四条公理" class="headerlink" title="四条公理"></a>四条公理</h2><h2 id="两种模型"><a href="#两种模型" class="headerlink" title="两种模型"></a>两种模型</h2>]]></content>
      <categories>
        <category>JSAC</category>
      </categories>
      <tags>
        <tag>TODO</tag>
        <tag>论文解读</tag>
        <tag>Protocol</tag>
      </tags>
  </entry>
  <entry>
    <title>HIMA</title>
    <url>/2020/12/02/HIMA/</url>
    <content><![CDATA[<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">序号</th>
<th style="text-align:center">属性</th>
<th style="text-align:center">内容</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">原文PDF</td>
<td style="text-align:center"><a href="https://www.researchgate.net/publication/221046631_HIMA_A_Hypervisor-Based_Integrity_Measurement_Agent" target="_blank" rel="noopener">HIMA</a></td>
</tr>
<tr>
<td style="text-align:center">2</td>
<td style="text-align:center">作者信息</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">3</td>
<td style="text-align:center">核心内容</td>
<td style="text-align:center">本文提出的HIMA用于度量在Hypervisor上部署虚拟机之间的完整性。</td>
</tr>
<tr>
<td style="text-align:center">4</td>
<td style="text-align:center">研究领域</td>
<td style="text-align:center">分布式系统构建信任</td>
</tr>
<tr>
<td style="text-align:center">5</td>
<td style="text-align:center">全文总览</td>
<td style="text-align:center">完整性度量</td>
</tr>
</tbody>
</table>
</div>
<h3 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h3><p>​        完整性度量是在分布式系统间构建信任的关键问题。本文提出观点认为：完整性度量需要在度量代理和度量目标之间构建强大的隔离，并在使用时间检查之间实现良好的隔离。</p>
<p>​        一个好的完整性度量解决方案必须要在度量代理以及目标之间提供良好的隔离性以及使用时间检查一致性实现良好的一致性。但是目前没有同时提供两种隔离的技术，本文致力于同时提供两种隔离性。</p>
<p>​        本文提出的<code>HIMA</code>是一种基于<code>Hypervisor</code>的代理，可以测量在<code>Hypervisor</code>上运行虚拟机的完整性。</p>
<p>主要采用的两种技术：</p>
<ol>
<li><p>主动监视关键客户机事件</p>
<p>通过监视所有更改客户机程序布局的事件，确保相应地执行度量程序是最新状态。</p>
</li>
<li><p>客户机内存保护 </p>
<p>保证能够捕获任何试图修改测量程序或者绕过测量程序的企图。HIMA通过主动监视客户机获得的信息来促进完整性度量。即<strong>保证执行的程序是已度量过的程序</strong>，通过强制执行度量过的内存页面策略来保证TOCTOU的一致性。</p>
</li>
</ol>
<p>从而保证对客户机的检测能够提供 <code>TOCTTOU</code>的一致性，从而能够检测出<code>TOCTTOU</code>攻击。</p>
<h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><p><strong>验证中存在的问题</strong></p>
<p>​        IMA以及PRIMA 基于一个monitor 度量相同系统内核组件的执行，但是这样设计的缺陷是容易受到针对内核运行时的攻击，这种攻击可能利用常见的操作系统漏洞来操纵内核的完整性度量代码或者关键性数据。已知的内核代码保护方法不能轻易的检测到针对度量数据的攻击。（例如，在发送到TPM之前存储在存储器中的hash值）这种攻击得以实时的重要原因是在测量程序和测量目标之间缺乏隔离性。</p>
<h3 id="整体架构"><a href="#整体架构" class="headerlink" title="整体架构"></a>整体架构</h3><p><img src="/2020/12/02/HIMA/architecture.png" height="360"></p>
<h3 id="Threat-Model"><a href="#Threat-Model" class="headerlink" title="Threat Model"></a>Threat Model</h3><p><strong>整体假设</strong></p>
<p>​        在本文中假设虚拟化平台能够使用现有的静态检测技术检测到到自身的完整性([1]中提到了这项检测技术，这项技术提到了TPM)，尽管客户机的内核在加载的时候已经被检测过了，但是由于运行时可能遭受攻击，所以整体上是不信任客户机内核的。即便内核代码是完整的，内核数据的泄露也可能会导致内核行为异常。同样假定硬件配备了<code>Non-eXecutable</code>. 客户虚拟机能够分离用户程序代码和数据页。</p>
<p><strong>威胁模型</strong></p>
<p>​        本文考虑的所有攻击是针对运行时程序的代码注入及更改。攻击者完全掌控客户机，攻击者可能会控制客户机内核并且尝试误导完整性监测，在攻击之后隐藏其踪迹，这在客户VM的生存周期内都是很大的威胁。在本文，着重对客户机的静态部分进行度量，实现客户VM的 <code>TOCTOU</code>一致性，而不是动态代码。</p>
<h3 id="Contribution"><a href="#Contribution" class="headerlink" title="Contribution"></a>Contribution</h3><h4 id="动态监控客户机重要事件"><a href="#动态监控客户机重要事件" class="headerlink" title="动态监控客户机重要事件"></a>动态监控客户机重要事件</h4><p><img src="/2020/12/02/HIMA/systemcall.png" height="200"></p>
<blockquote>
<ol>
<li>进程A触发系统调用，HIMA保存需要的数据和寄存器；</li>
<li>内核停止进程A调用进程B；</li>
<li>进程B调用系统调用；</li>
<li>完成B的系统调用；</li>
<li>恢复进程A的系统调用；</li>
<li>系统调用结束，HIMA度量一段内存区域并返回度量结果，同时，HIMA基于系统调用的返回值计算可执行程序内存的结果；</li>
</ol>
</blockquote>
<p>​        HIMA 会在截获适当的事件之后度量要加载到客户虚拟机中的程序。当测量一个程序时，HIMA收集丰富的语义信息来产生有意义的度量，这些度量可以用于进一步的证明。</p>
<blockquote>
<p>Identifying program’s memory map.</p>
<p>Handling on-demand loading.</p>
<p>Coupling measured programs with their IDs.</p>
</blockquote>
<h4 id="客户机内存保护"><a href="#客户机内存保护" class="headerlink" title="客户机内存保护"></a>客户机内存保护</h4><p>​        作者指出，主动监视不足以确保<strong>用户程序的一致性</strong>。来宾内核或用户程序中的运行时漏洞可用于绕过监视的事件并跳过测量过程，或在执行之前修改测量的程序。因此，HIMA必须进一步保证：（1）来宾虚拟机只能执行测量的用户程序；（2）在HIMA不知情的情况下，不能修改测量的用户程序。</p>
<p>​        HIMA进一步指出对客户内存的保护。具体地说，HIMA利用hypervisor对MMU的控制来基于内存页的访问权限来实施其保证。因此，HIMA在完全隔离来宾vm的情况下强制用户程序的<code>toctotu</code>一致性。但是，我们必须解决一些技术问题以及解决方法，包括</p>
<p>（1）识别受监视页的内存映射 ：</p>
<p>（2）处理测量的可执行页的重新映射（例如，由于fork或clone系统调用）,</p>
<p>（3）确认我们的保护扩展到实际的物理内存。</p>
<p>提出方法：</p>
<p> <strong>Protecting Guest Memory Using Page Access Permissions</strong></p>
<p><strong>Identifying Mapping of Monitored Pages</strong></p>
<p><strong>Handling Remapping of Measured Executable Pages</strong></p>
<p><strong>Extending Memory Protection to Physical Frames</strong></p>
<p><strong>Writable-eXecutable (WX) Memory Regions</strong></p>
<p><img src="/2020/12/02/HIMA/memoryProtection.png" height="360"></p>
<h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h3><p>​        基于hypervisor的代理，用于测量在hypervisor之上运行的来宾vm的完整性。HIMA位于hypervisor中，对来宾vm执行全面的“开箱即用”度量，包括来宾操作系统内核及其应用程序。HIMA提供了两种完整的机制：主动监视重要的来宾事件和保护来宾内存。前者保证在客户机虚拟机中的程序布局发生变化时（例如，进程的创建或终止）刷新完整性度量，而后者确保在没有HIMA的知识的情况下无法绕过用户程序的完整性度量。通过这两种机制，HIMA保证了用户程序完整性度量的一致性。</p>
<h3 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h3><p><strong>远程验证</strong>是计算机系统可以验证远端程序完整性的过程。完整性信息验证了（被验证）系统的配置和当前状态，从而检测结果可以反映其可信度。</p>
]]></content>
      <categories>
        <category>ACSAC</category>
      </categories>
      <tags>
        <tag>论文解读</tag>
        <tag>Detection</tag>
        <tag>Hypervisor</tag>
      </tags>
  </entry>
  <entry>
    <title>FHEW</title>
    <url>/2020/08/13/FHEW/</url>
    <content><![CDATA[<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">序号</th>
<th style="text-align:center">属性</th>
<th style="text-align:center">内容</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">原文PDF</td>
<td style="text-align:center"><a href="https://eprint.iacr.org/2014/816.pdf" target="_blank" rel="noopener">FHEW</a></td>
</tr>
<tr>
<td style="text-align:center">2</td>
<td style="text-align:center">作者信息</td>
<td style="text-align:center">Centrum Wiskunde &amp; Informatica, Amsterdam</td>
</tr>
<tr>
<td style="text-align:center">3</td>
<td style="text-align:center">核心内容</td>
<td style="text-align:center">对全同态加密中 bootstraping 进行优化</td>
</tr>
<tr>
<td style="text-align:center">4</td>
<td style="text-align:center">研究领域</td>
<td style="text-align:center">同态加密</td>
</tr>
<tr>
<td style="text-align:center">5</td>
<td style="text-align:center">全文总览</td>
<td style="text-align:center">优化影响同态加密效率的主要瓶颈——Gentry 的引导程序</td>
</tr>
</tbody>
</table>
</div>
<h3 id=""><a href="#" class="headerlink" title=" "></a> </h3>]]></content>
      <categories>
        <category>Cryptographic Techniques</category>
      </categories>
      <tags>
        <tag>TODO</tag>
        <tag>论文解读</tag>
        <tag>Homomorphic</tag>
      </tags>
  </entry>
  <entry>
    <title>HyperLock</title>
    <url>/2020/12/01/HyperLock/</url>
    <content><![CDATA[<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">序号</th>
<th style="text-align:center">属性</th>
<th style="text-align:center">内容</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">原文PDF</td>
<td style="text-align:center"><a href="https://www.cs.fsu.edu/~zwang/files/EuroSys12.pdf" target="_blank" rel="noopener">HyperLock</a></td>
</tr>
<tr>
<td style="text-align:center">2</td>
<td style="text-align:center">作者信息</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">3</td>
<td style="text-align:center">核心内容</td>
<td style="text-align:center">保护Hypervisor</td>
</tr>
<tr>
<td style="text-align:center">4</td>
<td style="text-align:center">研究领域</td>
<td style="text-align:center">保护虚拟机安全</td>
</tr>
<tr>
<td style="text-align:center">5</td>
<td style="text-align:center">全文总览</td>
<td style="text-align:center">1. 提出HyperLock保护Hypervisor和客户虚拟机；2. 提出Hypervisor 影子技术，为每个客户机分配一个Hypervisor，提高隔离性。</td>
</tr>
</tbody>
</table>
</div>
<h3 id="概览"><a href="#概览" class="headerlink" title="概览"></a>概览</h3><p>​        本文主要指出是对Hypervisor的保护，实验的平台是KVM。<br>​        即便是部署虚拟机之后会带来很大的便利，但是Hypervisor软件bug是有可能被利用并发起攻击的。本文认为，因为客户机与主机的联系如此紧密，如果一个Hypervisor被攻击了，那么部署在其上面的许多客户机很有可能受到威胁。<br>​        为了隔离Hypervisor与各个客户机，本文提出了HyperLock来提供严格的隔离保证。具体来说，Hypervisor在运行时被隔离，他有自己独立的地址空间和受限制的指令集；另一种技术是Hypervisor shadow，有效的为每个客户机创建单独的Hypervisor，从而将可能受到的影响降到最小。</p>
<h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><p>​        现有对Hypervisor的攻击表明攻击者可以从客户机逃脱并直接攻击主机OS，并且受攻击的Hypervisor能够轻松的读取其他客户机的内容或者窃取敏感信息。</p>
<p>（为了说明xen的不安全性，需要介绍几个对xen的攻击实例）</p>
]]></content>
      <categories>
        <category>EuroSys</category>
      </categories>
      <tags>
        <tag>TODO</tag>
        <tag>论文解读</tag>
        <tag>Detection</tag>
        <tag>Isolation</tag>
      </tags>
  </entry>
  <entry>
    <title>LinnOS</title>
    <url>/2021/06/11/LinnOS/</url>
    <content><![CDATA[<h2 id="导读"><a href="#导读" class="headerlink" title="导读"></a>导读</h2><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">序号</th>
<th style="text-align:left">属性</th>
<th style="text-align:center">内容</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:left">原文PDF</td>
<td style="text-align:center"><a href="https://www.usenix.org/system/files/osdi20-hao.pdf" target="_blank" rel="noopener">paper</a> <a href="https://www.usenix.org/sites/default/files/conference/protected-files/osdi20_slides_hao.pdf" target="_blank" rel="noopener">slides</a></td>
</tr>
<tr>
<td style="text-align:center">2</td>
<td style="text-align:left">作者信息</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">3</td>
<td style="text-align:left">核心内容</td>
<td style="text-align:center">LinnOS 实现一种轻量级神经网络细粒度推断SSD性能，实现性能可预测性。</td>
</tr>
<tr>
<td style="text-align:center">4</td>
<td style="text-align:left">研究领域</td>
<td style="text-align:center">Storage</td>
</tr>
<tr>
<td style="text-align:center">5</td>
<td style="text-align:left">全文总览</td>
</tr>
</tbody>
</table>
</div>
<h2 id="总览"><a href="#总览" class="headerlink" title="总览"></a>总览</h2><p>本文介绍了 LinnOS，这是一种操作系统，它利用轻量级神经网络以非常精细的每 IO 粒度推断 SSD 性能，并帮助并行存储应用程序实现性能可预测性。 LinnOS 支持黑盒设备和实际生产跟踪，无需用户的任何额外输入，同时优于工业机制和其他方法。 我们的评估表明，与对冲和基于启发式的方法相比，LinnOS 将平均 I/O 延迟提高了 9.6-79.6%，推理准确度为 87-97%，每个 I/O 的推理开销为 4-6μs，证明它是 可以将机器学习整合到操作系统中以进行实时决策。</p>
<h2 id="SSD推断条件"><a href="#SSD推断条件" class="headerlink" title="SSD推断条件"></a>SSD推断条件</h2><p>SSD的写延迟具有不可预测，本文根据SSD的历史数据和相应时间选择第一个适合自己的</p>
<h2 id="思想借鉴"><a href="#思想借鉴" class="headerlink" title="思想借鉴"></a>思想借鉴</h2><p>主要借助其推断方式构建个人网络通讯模型。</p>
<p><img src="https://cdn.jsdelivr.net/gh/LavaBeastMurfitt/cdn/images/LinnOS_division.png" alt=""></p>
<p>简单神经网络</p>
<p><img src="https://cdn.jsdelivr.net/gh/LavaBeastMurfitt/cdn/images/LinnOS-design-challenge.png" alt=""></p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2>]]></content>
      <categories>
        <category>OSDI</category>
      </categories>
      <tags>
        <tag>TODO</tag>
        <tag>论文解读</tag>
        <tag>Storage</tag>
      </tags>
  </entry>
  <entry>
    <title>MIT-6.S081-0-deployment</title>
    <url>/2021/06/22/MIT-6-S081-0-deployment/</url>
    <content><![CDATA[<h2 id="课程简介"><a href="#课程简介" class="headerlink" title="课程简介"></a>课程简介</h2><p>MIT6.S081这门课程的标题是Operating System Engineering，主要讲的就是操作系统。授课教授是Robert Morris和Frans Kaashoek.</p>
<p>课程是基于一个类似于Unix但是简单的多的教学操作系统XV6来讲解，虽然不是原汁原味的Linux，但是对于理解Linux的工作方式和结构是足够了。</p>
<h2 id="工具准备"><a href="#工具准备" class="headerlink" title="工具准备"></a>工具准备</h2><p><strong>需要的工具</strong></p>
<blockquote>
<ol>
<li>qemu for riscv</li>
<li>gdb for riscv</li>
<li>gcc for riscv</li>
<li>binutils for riscv</li>
</ol>
</blockquote>
<h2 id="部署实验环境"><a href="#部署实验环境" class="headerlink" title="部署实验环境"></a>部署实验环境</h2><p>使用的系统是 ubuntu 20.04.2</p>
<p><strong>更换国内源</strong></p>
<p><a href="https://mirror.tuna.tsinghua.edu.cn/help/ubuntu/" target="_blank" rel="noopener">清华源-ubuntu-20.04</a></p>
<p><strong>更新软件包</strong></p>
<pre><code class="lang-bash">apt update 
apt upgrade
</code></pre>
<p><strong>安装依赖</strong></p>
<pre><code class="lang-bash">apt-get install git build-essential gdb-multiarch qemu-system-misc gcc-riscv64-linux-gnu binutils-riscv64-linux-gnu
</code></pre>
<p><strong>课程代码</strong></p>
<pre><code class="lang-bash">git clone git://g.csail.mit.edu/xv6-labs-2020
</code></pre>
<p><strong>查看分支内容</strong></p>
<pre><code class="lang-bash">cd xv6-labs-2020
git branch --all
</code></pre>
<p><strong>进入第一个实验分支</strong></p>
<p><code>git checkout util</code></p>
<pre><code class="lang-bash">  master
* util
  remotes/origin/HEAD -&gt; origin/master
  remotes/origin/cow
  remotes/origin/fs
  remotes/origin/lazy
  remotes/origin/lock
  remotes/origin/master
  remotes/origin/mmap
  remotes/origin/net
  remotes/origin/pgtbl
  remotes/origin/riscv
  remotes/origin/syscall
  remotes/origin/thread
  remotes/origin/traps
  remotes/origin/util
</code></pre>
<p><strong>编译xv6开启模拟器</strong></p>
<pre><code class="lang-bash">make qemu
</code></pre>
<p><strong>结果如下</strong></p>
<p><img src="https://cdn.jsdelivr.net/gh/LavaBeastMurfitt/cdn/images/MIT-6.S081-make-qemu.png" alt=""></p>
<p>退出命令：<code>Ctrl+a</code>之后按<code>x</code>退出qemu</p>
<p><strong>验证调试器</strong></p>
<p><strong>一个窗口运行qemu </strong>  <code>make qemu-gdb</code></p>
<p><strong>另一个窗口运行gdb </strong> <code>gdb-multiarch -q kernel/kernel</code></p>
<p><strong>第一次运行，根据提示设置好 .gdbinit</strong></p>
<p><img src="https://cdn.jsdelivr.net/gh/LavaBeastMurfitt/cdn/images/MIT-6.S081-gdb.png" alt=""></p>
<p>如果输入<code>gdb-multiarch -q kernel/kernel</code>出现上图结果，则说明环境ok.</p>
<h2 id="连接远端仓库"><a href="#连接远端仓库" class="headerlink" title="连接远端仓库"></a>连接远端仓库</h2><p>查看远程仓库 <code>git remote -v</code></p>
<p>添加MIT远程仓库 <code>git remote add labs git://g.csail.mit.edu/xv6-labs-2020</code></p>
<p>拉取分支 <code>git fetch labs</code></p>
<p>查看分支 <code>git branch -a</code></p>
<p>切换分支 <code>git checkout util</code></p>
<p>提交代码到个人仓库 <code>git push https://github.com/Mykrobin/MIT-6.S081.git</code> 或者 <code>git push git@github.com:Mykrobin/MIT-6.S081.git</code></p>
<p>第二种提交方式需要配置密钥到GitHub  配置方法见<a href="https://www.cnblogs.com/zwdeblog/p/9708503.html" target="_blank" rel="noopener">6</a></p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1] <a href="https://pdos.csail.mit.edu/6.828/2020/schedule.html" target="_blank" rel="noopener">课程主页</a></p>
<p>[2] <a href="https://mit-public-courses-cn-translatio.gitbook.io/mit6-s081/" target="_blank" rel="noopener">课程翻译</a></p>
<p>[3] <a href="https://github.com/Mykrobin/MIT-6.S081/blob/main/references/book-riscv-rev1.pdf" target="_blank" rel="noopener">xv6 原版</a></p>
<p>[4] <a href="https://github.com/Mykrobin/MIT-6.S081/blob/main/references/XV6-Chinese-2020.pdf" target="_blank" rel="noopener">xv6 中文版</a></p>
<p>[5] <a href="https://zhuanlan.zhihu.com/p/377466759" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/377466759</a></p>
<p>[6] <a href="https://www.cnblogs.com/zwdeblog/p/9708503.html" target="_blank" rel="noopener">https://www.cnblogs.com/zwdeblog/p/9708503.html</a></p>
]]></content>
      <tags>
        <tag>MIT6.S081</tag>
        <tag>OS</tag>
      </tags>
  </entry>
  <entry>
    <title>MIT-6.S081-1-util</title>
    <url>/2021/06/22/MIT-6-S081-1-util/</url>
    <content><![CDATA[<h2 id="1-Sleep"><a href="#1-Sleep" class="headerlink" title="1. Sleep"></a>1. Sleep</h2><h3 id="Problem"><a href="#Problem" class="headerlink" title="Problem"></a>Problem</h3><hr>
<p>Implement the UNIX program <code>sleep</code> for xv6; your <code>sleep</code> should pause for a user-specified number of ticks. A tick is a notion of time defined by the xv6 kernel, namely the time between two interrupts from the timer chip. Your solution should be in the file <code>user/sleep.c</code>.</p>
<p><strong>Some hints:</strong></p>
<ul>
<li>Before you start coding, read Chapter 1 of the <a href="https://pdos.csail.mit.edu/6.S081/2020/xv6/book-riscv-rev1.pdf" target="_blank" rel="noopener">xv6 book</a>.</li>
<li>Look at some of the other programs in <code>user/</code> (e.g., <code>user/echo.c</code>, <code>user/grep.c</code>, and <code>user/rm.c</code>) to see how you can obtain the command-line arguments passed to a program.</li>
<li>If the user forgets to pass an argument, sleep should print an error message.</li>
<li>The command-line argument is passed as a string; you can convert it to an integer using <code>atoi</code> (see user/ulib.c).</li>
<li>Use the system call <code>sleep</code>.</li>
<li>See <code>kernel/sysproc.c</code> for the xv6 kernel code that implements the <code>sleep</code> system call (look for <code>sys_sleep</code>), <code>user/user.h</code> for the C definition of <code>sleep</code> callable from a user program, and <code>user/usys.S</code> for the assembler code that jumps from user code into the kernel for <code>sleep</code>.</li>
<li>Make sure <code>main</code> calls <code>exit()</code> in order to exit your program.</li>
<li>Add your <code>sleep</code> program to <code>UPROGS</code> in Makefile; once you’ve done that, <code>make qemu</code> will compile your program and you’ll be able to run it from the xv6 shell.</li>
<li>Look at Kernighan and Ritchie’s book <em>The C programming language (second edition)</em> (K&amp;R) to learn about C.</li>
</ul>
<p><strong>Run the program from the xv6 shell:</strong></p>
<pre><code>      $ make qemu
      ...
      init: starting sh
      $ sleep 10
      (nothing happens for a little while)
      $
</code></pre><p>Your solution is correct if your program pauses when run as shown above. Run make grade to see if you indeed pass the sleep tests.</p>
<p>Note that make grade runs all tests, including the ones for the assignments below. If you want to run the grade tests for one assignment, type:</p>
<pre><code>     $ ./grade-lab-util sleep
</code></pre><p>This will run the grade tests that match “sleep”. Or, you can type:</p>
<pre><code>     $ make GRADEFLAGS=sleep grade
</code></pre><p>which does the same.</p>
<h3 id="Sleep题解"><a href="#Sleep题解" class="headerlink" title="Sleep题解"></a>Sleep题解</h3><hr>
<p>仿照 <code>rm.c</code> 即可完成sleep系统调用</p>
<h3 id="问题记录"><a href="#问题记录" class="headerlink" title="问题记录"></a>问题记录</h3><hr>
<p>注意在源码中<code>int sleep(int n)</code> 的参数是如何传递到<code>kernel</code>层的</p>
<h2 id="2-pingpong"><a href="#2-pingpong" class="headerlink" title="2. pingpong"></a>2. pingpong</h2><h3 id="Problem-1"><a href="#Problem-1" class="headerlink" title="Problem"></a>Problem</h3><hr>
<p>Write a program that uses UNIX system calls to ‘’ping-pong’’ a byte between two processes over a pair of pipes, one for each direction. The parent should send a byte to the child; the child should print “<pid>: received ping”, where <pid> is its process ID, write the byte on the pipe to the parent, and exit; the parent should read the byte from the child, print “<pid>: received pong”, and exit. Your solution should be in the file <code>user/pingpong.c</code>.</pid></pid></pid></p>
<p>Some hints:</p>
<ul>
<li>Use <code>pipe</code> to create a pipe.</li>
<li>Use <code>fork</code> to create a child.</li>
<li>Use <code>read</code> to read from the pipe, and <code>write</code> to write to the pipe.</li>
<li>Use <code>getpid</code> to find the process ID of the calling process.</li>
<li>Add the program to <code>UPROGS</code> in Makefile.</li>
<li>User programs on xv6 have a limited set of library functions available to them. You can see the list in <code>user/user.h</code>; the source (other than for system calls) is in <code>user/ulib.c</code>, <code>user/printf.c</code>, and <code>user/umalloc.c</code>.</li>
</ul>
<p>Run the program from the xv6 shell and it should produce the following output:</p>
<pre><code>    $ make qemu
    ...
    init: starting sh
    $ pingpong
    4: received ping
    3: received pong
    $
</code></pre><p>Your solution is correct if your program exchanges a byte between two processes and produces output as shown above.</p>
<h3 id="pingpong题解"><a href="#pingpong题解" class="headerlink" title="pingpong题解"></a>pingpong题解</h3><hr>
<p>涉及到父进程传入子进程，之后子进程传入到父进程，可以使用双向管道，控制数据的输出</p>
<h3 id="问题记录-1"><a href="#问题记录-1" class="headerlink" title="问题记录"></a>问题记录</h3><hr>
<h2 id="3-primes"><a href="#3-primes" class="headerlink" title="3. primes"></a>3. primes</h2><h3 id="Problem-2"><a href="#Problem-2" class="headerlink" title="Problem"></a>Problem</h3><hr>
<p>Write a concurrent version of prime sieve using pipes. This idea is due to Doug McIlroy, inventor of Unix pipes. The picture halfway down <a href="http://swtch.com/~rsc/thread/" target="_blank" rel="noopener">this page</a> and the surrounding text explain how to do it. Your solution should be in the file <code>user/primes.c</code>.</p>
<p>Your goal is to use <code>pipe</code> and <code>fork</code> to set up the pipeline. The first process feeds the numbers 2 through 35 into the pipeline. For each prime number, you will arrange to create one process that reads from its left neighbor over a pipe and writes to its right neighbor over another pipe. Since xv6 has limited number of file descriptors and processes, the first process can stop at 35.</p>
<p>Some hints:</p>
<ul>
<li>Be careful to close file descriptors that a process doesn’t need, because otherwise your program will run xv6 out of resources before the first process reaches 35.</li>
<li>Once the first process reaches 35, it should wait until the entire pipeline terminates, including all children, grandchildren, &amp;c. Thus the main primes process should only exit after all the output has been printed, and after all the other primes processes have exited.</li>
<li>Hint: <code>read</code> returns zero when the write-side of a pipe is closed.</li>
<li>It’s simplest to directly write 32-bit (4-byte) <code>int</code>s to the pipes, rather than using formatted ASCII I/O.</li>
<li>You should create the processes in the pipeline only as they are needed.</li>
<li>Add the program to <code>UPROGS</code> in Makefile.</li>
</ul>
<p>Your solution is correct if it implements a pipe-based sieve and produces the following output:</p>
<pre><code>    $ make qemu
    ...
    init: starting sh
    $ primes
    prime 2
    prime 3
    prime 5
    prime 7
    prime 11
    prime 13
    prime 17
    prime 19
    prime 23
    prime 29
    prime 31
    $2
</code></pre><h3 id="primes题解"><a href="#primes题解" class="headerlink" title="primes题解"></a>primes题解</h3><hr>
<p>此图为该问题的简单表述</p>
<p><img src="https://cdn.jsdelivr.net/gh/LavaBeastMurfitt/cdn/images/MIT-6.S081-utiles-prime-thread.png" alt=""></p>
<p>父进程不断的传入全部数据，在子进程中进行筛选，满足条件的记录下来，不符合条件的则踢除。</p>
<h3 id="问题记录-2"><a href="#问题记录-2" class="headerlink" title="问题记录"></a>问题记录</h3><hr>
<p>注意每次fork 与 pipe 的顺序问题</p>
<h2 id="4-find"><a href="#4-find" class="headerlink" title="4. find"></a>4. find</h2><h3 id="Problem-3"><a href="#Problem-3" class="headerlink" title="Problem"></a>Problem</h3><hr>
<p>Write a simple version of the UNIX find program: find all the files in a directory tree with a specific name. Your solution should be in the file <code>user/find.c</code>.</p>
<p>Some hints:</p>
<ul>
<li>Look at user/ls.c to see how to read directories.</li>
<li>Use recursion to allow find to descend into sub-directories.</li>
<li>Don’t recurse into “.” and “..”.</li>
<li>Changes to the file system persist across runs of qemu; to get a clean file system run make clean and then make qemu.</li>
<li>You’ll need to use C strings. Have a look at K&amp;R (the C book), for example Section 5.5.</li>
<li>Note that == does not compare strings like in Python. Use strcmp() instead.</li>
<li>Add the program to <code>UPROGS</code> in Makefile.</li>
</ul>
<p>Your solution is correct if produces the following output (when the file system contains the files <code>b</code> and <code>a/b</code>):</p>
<pre><code>    $ make qemu
    ...
    init: starting sh
    $ echo &gt; b
    $ mkdir a
    $ echo &gt; a/b
    $ find . b
    ./b
    ./a/b
    $
</code></pre><h3 id="fin题解"><a href="#fin题解" class="headerlink" title="fin题解"></a>fin题解</h3><hr>
<p>参照ls.c文件，搞清楚每个参数的输出内容，如何进行文件地址的拼接；</p>
<p>识别文件的类型是文件or目录，如果是目录，则进行递归遍历，否则判断是否为目标文件。</p>
<h3 id="问题记录-3"><a href="#问题记录-3" class="headerlink" title="问题记录"></a>问题记录</h3><hr>
<h2 id="5-xargs"><a href="#5-xargs" class="headerlink" title="5. xargs"></a>5. xargs</h2><h3 id="Problem-4"><a href="#Problem-4" class="headerlink" title="Problem"></a>Problem</h3><hr>
<p>Write a simple version of the UNIX xargs program: read lines from the standard input and run a command for each line, supplying the line as arguments to the command. Your solution should be in the file <code>user/xargs.c</code>.</p>
<p>The following example illustrates xarg’s behavior:</p>
<pre><code>    $ echo hello too | xargs echo bye
    bye hello too
    $
</code></pre><p>Note that the command here is “echo bye” and the additional arguments are “hello too”, making the command “echo bye hello too”, which outputs “bye hello too”.</p>
<p>Please note that xargs on UNIX makes an optimization where it will feed more than argument to the command at a time. We don’t expect you to make this optimization. To make xargs on UNIX behave the way we want it to for this lab, please run it with the -n option set to 1. For instance</p>
<pre><code>    $ echo "1\n2" | xargs -n 1 echo line
    line 1
    line 2
    $
</code></pre><p>Some hints:</p>
<ul>
<li>Use <code>fork</code> and <code>exec</code> to invoke the command on each line of input. Use <code>wait</code> in the parent to wait for the child to complete the command.</li>
<li>To read individual lines of input, read a character at a time until a newline (‘\n’) appears.</li>
<li>kernel/param.h declares MAXARG, which may be useful if you need to declare an argv array.</li>
<li>Add the program to <code>UPROGS</code> in Makefile.</li>
<li>Changes to the file system persist across runs of qemu; to get a clean file system run make clean and then make qemu.</li>
</ul>
<p>xargs, find, and grep combine well:</p>
<pre><code>  $ find . b | xargs grep hello
</code></pre><p>will run “grep hello” on each file named b in the directories below “.”.</p>
<p>To test your solution for xargs, run the shell script xargstest.sh. Your solution is correct if it produces the following output:</p>
<pre><code>  $ make qemu
  ...
  init: starting sh
  $ sh &lt; xargstest.sh
  $ $ $ $ $ $ hello
  hello
  hello
  $ $
</code></pre><p>You may have to go back and fix bugs in your find program. The output has many <script type="math/tex">` because the xv6 shell doesn't realize it is processing commands from a file instead of from the console, and prints a `</script> for each command in the file.</p>
<h3 id="xargs题解"><a href="#xargs题解" class="headerlink" title="xargs题解"></a>xargs题解</h3><hr>
<h3 id="问题记录-4"><a href="#问题记录-4" class="headerlink" title="问题记录"></a>问题记录</h3><hr>
<p><img src="https://cdn.jsdelivr.net/gh/LavaBeastMurfitt/cdn/images/MIT-6.S081-utils-grade.png" alt=""></p>
<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><p>[1] <a href="https://pdos.csail.mit.edu/6.S081/2020/labs/util.html" target="_blank" rel="noopener">Lab: utils</a> </p>
<p>[2] <a href="https://swtch.com/~rsc/thread/" target="_blank" rel="noopener">https://swtch.com/~rsc/thread/</a></p>
<p>[3] <a href="http://www.ruanyifeng.com/blog/2019/08/xargs-tutorial.html" target="_blank" rel="noopener">xargs 命令教程</a></p>
]]></content>
      <tags>
        <tag>MIT6.S081</tag>
        <tag>OS</tag>
      </tags>
  </entry>
  <entry>
    <title>Lares:An Architecture for Secure Active Monitoring Using Virtualization</title>
    <url>/2020/05/03/Lares-An-Architecture-for-Secure-Active-Monitoring-Using-Virtualization/</url>
    <content><![CDATA[<h3 id="Prevention-VS-Detection"><a href="#Prevention-VS-Detection" class="headerlink" title="Prevention VS Detection"></a>Prevention VS Detection</h3><p>Prevention侧重于阻止，即在攻击前拦截攻击，如阻止一个恶意驱动的加载。Detection侧重于检测，即在攻击成功后，检测是否发生过攻击。Prevention类的虚拟机监控又称Active Monitoring（主动监控），典型的有Lares。Detection类的虚拟机监控又称Passive Monitoring（被动监控），典型的有VICTOR。</p>
<ul>
<li><strong>Active Monitoring（Synchronous）</strong></li>
</ul>
<p>主动监控一般采用同步机制，即事件发生时进行拦截。所以主动监控适合于监控发生频率较低的事件，如进程的创建。对发生频率较高的事件进行拦截，如拦截线程的切换，则会带来较大的性能损耗，尤其是当这类事件会引起陷入hypervisor的时候。</p>
<ul>
<li><strong>Passive Monitoring （Asynchronous）</strong></li>
</ul>
<p>被动监控一般采用异步机制，即事件发生后进行检测，如周期性的扫描内存。发生频率较高的事件可通过这种方式进行检测。然而这种方法需要权衡性能和风险，确定一个合适的检测周期。过于频繁的检测会带来较大的性能损耗，而周期间隔较大又可能遗漏攻击行为（攻击行为发生在两次检测之间）。</p>
]]></content>
      <categories>
        <category>Security and Privacy</category>
        <category>TODO</category>
      </categories>
      <tags>
        <tag>论文解读</tag>
        <tag>虚拟化安全</tag>
      </tags>
  </entry>
  <entry>
    <title>MIT log 0 内存管理实验环境</title>
    <url>/2020/11/09/MIT-log-0-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E5%AE%9E%E9%AA%8C%E7%8E%AF%E5%A2%83/</url>
    <content><![CDATA[<h3 id="内存实验环境搭建"><a href="#内存实验环境搭建" class="headerlink" title="内存实验环境搭建"></a>内存实验环境搭建</h3><p><strong>操作系统</strong>是计算机科学中十分重要的一门基础学科，是一名计算机专业毕业生必须要具备的基础知识。但是在学习这门课时，如果仅仅把目光停留在课本上一些关于操作系统概念上的叙述，并不能对操作系统有着深层次的理解。必须要结合动手实践，才能真正掌握核心的知识。<br>MIT的操作系统课程6.828是一门被广泛好评的入门课程。它最重要的特点就是它实践第一的教学原则。在这门课程中会涉及到非常丰富的实验，也会有非常多的动手机会。而且授课者更是亲自构建了一个简化的基于Unix内核的操作系统xv6。所有的实验都是在这个操作系统上完成。虽然它功能很简单，但是它能够帮助我们真正的了解操作系统在做什么[3]。<br>因此，以博客的形式记录自己学习6.828的过程，本系列博文尽量包括以下几个内容：</p>
<ul>
<li>所有实验的实验报告(Lab)</li>
<li>所有实验中的练习(Exercise)</li>
</ul>
<p>下面开始实验环境的搭建：</p>
<h4 id="实验环境"><a href="#实验环境" class="headerlink" title="实验环境"></a>实验环境</h4><p>本次实验在ubuntu18系统上进行，所有的操作步骤都在Linux 操作系统上进行。</p>
<h3 id="准备阶段"><a href="#准备阶段" class="headerlink" title="准备阶段"></a>准备阶段</h3><p>因为本实验的  操作系统是比较新的 Ubuntu18，其自带的软件版本可能比较新，对于此lab可能不太适配，所以需要对需要的软件进行一些配置。</p>
<h4 id="gcc版本降级"><a href="#gcc版本降级" class="headerlink" title="gcc版本降级"></a>gcc版本降级</h4><p>目的： 将gcc 版本降级到 4.8 版本</p>
<p>(1). 下载 <code>gcc/g++ 4.8</code></p>
<pre><code class="lang-shell">apt-get install -y gcc-4.8
apt-get install -y g++-4.8
</code></pre>
<p>(2). 链接gcc/g++实现降级</p>
<pre><code class="lang-shell">cd /usr/bin
sudo rm gcc
sudo ln -s gcc-4.8 gcc
sudo rm g++
sudo ln -s g++-4.8 g++
</code></pre>
<h4 id="编译qemu"><a href="#编译qemu" class="headerlink" title="编译qemu"></a>编译qemu</h4><p><strong>安装依赖</strong> [4]</p>
<pre><code class="lang-shell">apt-get install git build-essential binutils g++-multilib libgtk2.0-dev libtool-bin libsdl-dev -y
</code></pre>
<p><strong>下载qemu源码</strong></p>
<pre><code class="lang-shell">git clone https://github.com/mit-pdos/6.828-qemu.git qemu
</code></pre>
<p><strong>下载 lab 源码</strong></p>
<pre><code class="lang-shell">git clone https://pdos.csail.mit.edu/6.828/2018/jos.git lab # 只有第一实验的检查脚本
</code></pre>
<p><strong>安装步骤</strong></p>
<p>进入<code>qemu</code>目录下</p>
<pre><code class="lang-shell">./configure --disable-kvm --target-list="i386-softmmu x86_64-softmmu"
sudo make &amp;&amp; make install
</code></pre>
<p><img src="/2020/11/09/MIT-log-0-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E5%AE%9E%E9%AA%8C%E7%8E%AF%E5%A2%83/qemu.png" height="260xp"></p>
<p>它生成的最后一个信息 <code>mk obj/kern/kernel.img</code>，这个<code>kernel.img</code>就是内核映像文件，另外obj目录在make之前是没有的，它是make指令生成的，它里面将会有许多的文件我们之后会重点观察。编译完内核源码，我们就可以把它运行在<code>QEMU</code>上啦！[3]</p>
<p><strong>安装结果测试</strong></p>
<p>输入<code>/usr/local/bin/qemu-system-i386</code> 出现以下窗口则安装ok</p>
<p><img src="/2020/11/09/MIT-log-0-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E5%AE%9E%E9%AA%8C%E7%8E%AF%E5%A2%83/qemu-test.png" height="300xp"></p>
<p>在<code>lab</code>目录下输入  <code>make qemu</code> 出现如下结果</p>
<p><img src="/2020/11/09/MIT-log-0-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E5%AE%9E%E9%AA%8C%E7%8E%AF%E5%A2%83/make-qemu.png" height="300xp"></p>
<p>至此，实验环境搭建完成！</p>
<h3 id="References"><a href="#References" class="headerlink" title="References"></a>References</h3><p>[1] <a href="https://os.vampire.rip/" target="_blank" rel="noopener">https://os.vampire.rip/</a></p>
<p>[2] <a href="https://zhuanlan.zhihu.com/p/74028717" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/74028717</a></p>
<p>[3] <a href="https://www.cnblogs.com/fatsheep9146/p/5060292.html" target="_blank" rel="noopener">https://www.cnblogs.com/fatsheep9146/p/5060292.html</a></p>
<p>[4] <a href="https://www.cnblogs.com/gatsby123/p/9746193.html" target="_blank" rel="noopener">https://www.cnblogs.com/gatsby123/p/9746193.html</a></p>
]]></content>
      <tags>
        <tag>lab</tag>
        <tag>OS Memory</tag>
      </tags>
  </entry>
  <entry>
    <title>MIT-log-1-启动PC</title>
    <url>/2020/12/11/MIT-log-1-%E5%90%AF%E5%8A%A8PC/</url>
    <content><![CDATA[<h3 id="Part-1-PC-BootStrap"><a href="#Part-1-PC-BootStrap" class="headerlink" title="Part 1: PC BootStrap"></a>Part 1: PC BootStrap</h3><p><strong>PC物理地址空间</strong></p>
<pre><code class="lang-shell">+------------------+  &lt;- 0xFFFFFFFF (4GB)
|      32-bit      |
|  memory mapped   |
|     devices      |
|                  |
/\/\/\/\/\/\/\/\/\/\

/\/\/\/\/\/\/\/\/\/\
|                  |
|      Unused      |
|                  |
+------------------+  &lt;- depends on amount of RAM
|                  |
|                  |
| Extended Memory  |
|                  |
|                  |
+------------------+  &lt;- 0x00100000 (1MB)
|     BIOS ROM     |
+------------------+  &lt;- 0x000F0000 (960KB)
|  16-bit devices, |
|  expansion ROMs  |
+------------------+  &lt;- 0x000C0000 (768KB)
|   VGA Display    |
+------------------+  &lt;- 0x000A0000 (640KB)
|                  |
|    Low Memory    |
|                  |
+------------------+  &lt;- 0x00000000
</code></pre>
<h4 id="利用Qemu和gdb实现对OS的debug"><a href="#利用Qemu和gdb实现对OS的debug" class="headerlink" title="利用Qemu和gdb实现对OS的debug"></a>利用Qemu和gdb实现对OS的debug</h4><h5 id="操作步骤"><a href="#操作步骤" class="headerlink" title="操作步骤"></a>操作步骤</h5><ol>
<li><p>打开一个终端，在lab目录下输入 <code>make qemu-gdb</code></p>
<p><img src="/2020/12/11/MIT-log-1-%E5%90%AF%E5%8A%A8PC/gdb-1.png" height="100"></p>
</li>
<li><p>在另一个终端中进入lab目录下，输入<code>gdb</code>即可</p>
<p><img src="/2020/12/11/MIT-log-1-%E5%90%AF%E5%8A%A8PC/gdb-2.png" height="400"></p>
</li>
</ol>
<p>此时，便可以进行调试了。</p>
<p>   在OS启动时，第一段加载的第一段程序是BIOS，BIOS的操作就是在控制、初始化、检测各种底层的设备，如：时钟，GDTR寄存器、设置中断向量表等，最重要的功能就是<strong>把操作系统从此磁盘中导入内存，然后把控制权交给操作系统。</strong>所以BIOS在运行的最后会去检测可以从当前系统的哪个设备中找到操作系统，通常来说是我们的磁盘。当BIOS确定操作系统位于磁盘中，那么它就会把这个磁盘的第一个扇区，通常把它叫做启动区（boot sector）先加载到内存中，这个启动区中包括一个非常重要的程序—<strong>boot loader，</strong>它会负责完成整个操作系统从磁盘导入内存的工作，以及一些其他的非常重要的配置工作。最后操作系统才会开始运行。</p>
<p>可见PC启动后的运行顺序为<code>BIOS --&gt; boot loader--&gt; OS内核</code></p>
<h5 id="Exercise-2"><a href="#Exercise-2" class="headerlink" title="Exercise 2:"></a>Exercise 2:</h5><p>在gdb窗口中显示出PC机启动后运行BIOS的第一条命令为</p>
<pre><code class="lang-shell">1. [f000:fff0]    0xffff0: ljmp   $0xf000,$0xe05b
</code></pre>
<p>    这是运行的第一条指令，为跳转指令，目标是<code>0xfe05b</code>. 当PC机启动后，CPU运行在实模式(real mode)<sup><a href="#fn_实模式" id="reffn_实模式">实模式</a></sup>下，而当进入操作系统内核后，将会运行在保护模式(protected mode)下[2]。其中实模式是早期CPU（如8088处理器）的工作模式，这类处理器只有20根地址线，所以只能访问<code>1MB</code>的内存空间。但是，CPU不断的发展，之后的<code>80286/80386</code>已经具备32根地址线，能够访问<code>4GB</code>的内存空间，为了能够很好的管理内存空间，提出了保护模式。所以现在的处理器都是工作在保护模式下的，但为了向后兼容，即原来的8088处理器的软件仍能够运行在现代处理器上，现代处理器的CPU在启动过程中都处于实模式，启动完成后进入保护模式。<code>BIOS</code>就是PC刚启动时运行的软件，所以工作在实模式下。</p>
<p>    实模式下的地址：<code>段基址：段内偏移</code>，其中这两个字段的值都存放在寄存器中，段基地址必须存放在段寄存器中，如CS(代码段), DS(数据段), SS(堆栈段), ES(扩展段)。</p>
<p>     由于8088CPU 寄存器中都是16位，而CPU总线是20位，则需要通过16位的寄存器拼接得到20位的地址：把段寄存器中值左移4位，形成20位段基址，然后和16位段内偏移地址相加，得到20位的真实地址，如：<code>0xf000&lt;&lt;4+0xe05b=0xfe05b</code></p>
<p>使用gdb进行调试：<code>si</code> 查看下一条指令</p>
<pre><code class="lang-shell">2. [f000:e05b]    0xfe05b: cmpl   $0x0,%cs:0x6ac8
</code></pre>
<p>   把<code>0x0</code> 这个立即数 与 <code>%cs:0x6ac8</code>代表的内存地址处的值进行比较。其中<code>% cs</code>代表CS段寄存器中的值。</p>
<pre><code class="lang-shell">3. [f000:e062]    0xfe062: jne    0xfd2e1
</code></pre>
<p>   <code>jne</code>指令：如果ZF标志位为0的时候跳转，即上一条指令 <code>cmpl</code> 的结果不是0 的时候跳转，即 <code>%cs:0x6ac8</code> 地址处的值不是 <code>0x0</code>的时候跳转。</p>
<blockquote>
<p><code>cmpl</code>指令是将两个操作数相减，但计算结果不保存，只是更具计算结果改变<code>eflags</code>的标志位，如果两个操作数相同，则计算结果为0，ZF标志位为1 。</p>
<p><code>gdb</code>查看寄存器中数值：</p>
<pre><code class="lang-shell">(gdb) info registers
eax            0x0      0
ecx            0x0      0
edx            0x663    1635
ebx            0x0      0
esp            0x0      0x0
ebp            0x0      0x0
esi            0x0      0
edi            0x0      0
eip            0xe062   0xe062
eflags         0x46     [ PF ZF ]
cs             0xf000   61440
ss             0x0      0
ds             0x0      0
es             0x0      0
fs             0x0      0
gs             0x0      0
</code></pre>
<p><code>gdb</code>查看内存信息：</p>
<pre><code class="lang-shell">(gdb) x 0xfe05b
   0xfe05b:     cmpl   $0x0,%cs:0x6ac8
(gdb) x 0xfe062
   0xfe062:     jne    0xfd2e1
</code></pre>
</blockquote>
<pre><code class="lang-shell">4. [f000:e066]    0xfe066: xor    %dx,%dx
</code></pre>
<p>   下一条指令的地址为<code>0xfe066</code>，可见并没有发生指令跳转，该指令功能是把dx寄存器内容清零。</p>
<pre><code class="lang-shell">5. [f000:e068]    0xfe068: mov    %dx,%ss
6. [f000:e06a]    0xfe06a: mov    $0x7000,%esp
7. [f000:e070]    0xfe070: mov    $0xf34c2,%edx
8. [f000:e076]    0xfe076: jmp    0xfd15c  # 跳转到绝对地址
9. [f000:d15c]    0xfd15c: mov    %eax,%ecx
</code></pre>
<p>    设置寄存器中的数值。</p>
<pre><code class="lang-shell">10. [f000:d15f]    0xfd15f: cli
</code></pre>
<p>   关闭中断指令。PC启动时的操作是比较关键的，关中断指令用于关闭那些可以屏蔽的中断。</p>
<pre><code class="lang-shell">11. [f000:d160]    0xfd160: cld
</code></pre>
<p>    设置方向标识位为0，表示后续的串操作 [3] 比如MOVS操作，内存地址的变化方向，如果为0代表从低地址值变为高地址。</p>
<pre><code class="lang-shell">12. [f000:d161]    0xfd161: mov    $0x8f,%eax
# (gdb) info register eax
# eax            0x0      0
13. [f000:d167]    0xfd167: out    %al,$0x70
# (gdb) info register eax
# eax            0x8f     143
14. [f000:d169]    0xfd169: in     $0x71,%al
# (gdb) info register al
# al             0x8f     -113
</code></pre>
<p>    CPU与外部设备通讯时，通常是通过访问、修改设备控制器中的寄存器来实现的。那么这些位于设备控制器当中的寄存器也叫做<strong>IO端口</strong>。为了方便管理，80x86CPU采用IO端口单独编址的方式，即所有设备的端口都被命名到一个IO端口地址空间中。这个空间是独立于内存地址空间的。所以必须采用和访问内存的指令不一样的指令来访问端口。</p>
<blockquote>
<p>在向0x70端口写入值后，必须对0x71端口有操作(这里正好选用了in操作)，否则RTC就会处于an unknown state之中.</p>
</blockquote>
<pre><code class="lang-shell">out %al,PortAddress #把al寄存器中值写到端口PortAddress
in PortAddress,%al  #把端口地址为PortAddress的端口值读到al寄存器
# 标准规定，端口操作必须用到al/ax寄存器作为缓冲
</code></pre>
<p>    三条命令就是要操作端口0x70，0x71，根据清单[4] 中内容，可以知道0x70端口和0x71端口是用于控制系统中一个叫做CMOS的设备，这个设备是一个低功耗的存储设备，它可以用于在计算机关闭时存储一些信息，它是由独立的电池供电的[5]。 这个CMOS中可以控制跟PC相关的多个功能，其中最重要的就是<strong>时钟设备（Real Time Clock）</strong>的 ，它还可以控制是否<strong>响应不可屏蔽中断NMI(Non-Maskable Interrupt)</strong>。操作CMOS存储器中的内容需要两个端口，一个是0x70另一个就是0x71。其中0x70可以叫做索引寄存器，<strong>这个8位寄存器的最高位是不可屏蔽中断(NMI)使能位。如果你把这个位置1，则NMI不会被响应。低7位用于指定CMOS存储器中的存储单元地址</strong>，所以如果你想访问第1号存储单元，并且在访问时，我要使能NMI，那么你就应该向端口0x70里面送入0b10000001 = 0x81。</p>
<p>    这三条指令可以看出，它首先关闭了NMI中断，并且要访问存储单元0xF的值，并且把值读到al中，但是在后面我们发现这个值并没有被利用，所以可以认为<strong>这三条指令是用来关闭NMI中断的。</strong></p>
<pre><code class="lang-shell">15. [f000:d16b]    0xfd16b: in     $0x92,%al 
# (gdb) info register al
# al             0x0      0
16. [f000:d16d]    0xfd16d: or     $0x2,%al
17. [f000:d16f]    0xfd16f: out    %al,$0x92
# (gdb) info register al
# al             0x2      2
</code></pre>
<p>    它控制的是 PS/2系统控制端口A，而第16，17步的操作是在把这个端口的1号bit置为1。这个端口的bit1的功能是<code>bit 1= 1 indicates A20 active</code>,即A20位，即第21个地址线被使能，如果A20地址线被激活，那么系统工作在保护模式下。但是在之后的boot loader程序中，计算机首先要工作在实模式下啊。所以这里的这个操作，根据[6]应该是去测试可用内存空间。在boot loader之前，它肯定还会转换回实模式。</p>
<pre><code class="lang-shell">or # 只要有一个输入位是 1，则输出位就是 1
</code></pre>
<pre><code class="lang-shell">18. [f000:d171]    0xfd171: lidtw  %cs:0x6ab8
</code></pre>
<p>    加载中断向量表寄存器(IDTR)。这个指令会把从地址0xf6ab8起始的后面6个字节的数据读入到中断向量表寄存器(IDTR)中。中断是操作系统中非常重要的一部分，有了中断操作系统才能真正实现进程。每一种中断都有自己对应的中断处理程序，那么这个中断的处理程序的首地址就叫做这个中断的中断向量。中断向量表[7]是存放所有中断向量的表。</p>
<pre><code class="lang-shell">19. [f000:d177]    0xfd177: lgdtw  %cs:0x6a74
</code></pre>
<p>    把从<code>0xf6a74</code>为起始地址处的6个字节的值加载到全局描述符表格寄存器中GDTR中.</p>
<pre><code class="lang-shell">20. [f000:d17d]    0xfd17d: mov    %cr0,%eax
21. [f000:d180]    0xfd180: or     $0x1,%eax
22. [f000:d184]    0xfd184: mov    %eax,%cr0
</code></pre>
<p>    计算机中包含CR0-CR3四个控制寄存器，用来控制和确定处理器的操作模式。其中这三个语句的操作是要把CR0寄存器的最低位(0bit)置1。CR0寄存器的0bit是PE位，启动保护位，当该位被置1，代表开启了保护模式。但是这里出现了问题，我们刚刚说过BIOS是工作在实模式之下，后面的boot loader开始的时候也是工作在实模式下，所以这里把它切换为保护模式，显然是自相矛盾。所以只能推测它在检测机器是否能工作在保护模式下。</p>
<pre><code class="lang-shell">23. [f000:d187]    0xfd187: ljmpl  $0x8,$0xfd18f
# The target architecture is assumed to be i386
24. =&gt; 0xfd18f:     mov    $0x10,%eax
25. =&gt; 0xfd194:     mov    %eax,%ds
26. =&gt; 0xfd196:     mov    %eax,%es
27. =&gt; 0xfd198:     mov    %eax,%ss
28. =&gt; 0xfd19a:     mov    %eax,%fs
29. =&gt; 0xfd19c:     mov    %eax,%gs
</code></pre>
<p>    这里的23~29步之所以这么做是按照规定来的，[8]中指出，如果刚刚加载完GDTR寄存器我们必须要重新加载所有的段寄存器的值，而其中CS段寄存器必须通过长跳转指令，即23号指令来进行加载。所以这些步骤是在第19步完成后必须要做的。这样才能是GDTR的值生效。</p>
<h3 id="Part-2-引导加载程序"><a href="#Part-2-引导加载程序" class="headerlink" title="Part 2: 引导加载程序"></a>Part 2: 引导加载程序</h3><h3 id="Part-3-内核"><a href="#Part-3-内核" class="headerlink" title="Part 3: 内核"></a>Part 3: 内核</h3><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>[1] <a href="https://github.com/shishujuan/mit6.828-2017.git" target="_blank" rel="noopener">https://github.com/shishujuan/mit6.828-2017.git</a></p>
<p>[2] <a href="https://blog.csdn.net/zdwzzu2006/article/details/4030948" target="_blank" rel="noopener">https://blog.csdn.net/zdwzzu2006/article/details/4030948</a></p>
<p>[3] <a href="https://www.cnblogs.com/cykun/archive/2010/10/27/1862940.html" target="_blank" rel="noopener">https://www.cnblogs.com/cykun/archive/2010/10/27/1862940.html</a></p>
<p>[4] <a href="http://bochs.sourceforge.net/techspec/PORTS.LST" target="_blank" rel="noopener">http://bochs.sourceforge.net/techspec/PORTS.LST</a></p>
<p>[5] <a href="http://wiki.osdev.org/CMOS" target="_blank" rel="noopener">http://wiki.osdev.org/CMOS</a></p>
<p>[6] <a href="http://kernelx.weebly.com/a20-address-line.html" target="_blank" rel="noopener">http://kernelx.weebly.com/a20-address-line.html</a></p>
<p>[7] <a href="http://wiki.osdev.org/Interrupt_Descriptor_Table" target="_blank" rel="noopener">http://wiki.osdev.org/Interrupt_Descriptor_Table</a> </p>
<p>[8] <a href="https://en.wikibooks.org/wiki/X86_Assembly/Global_Descriptor_Table" target="_blank" rel="noopener">https://en.wikibooks.org/wiki/X86_Assembly/Global_Descriptor_Table</a></p>
<p>[9] <a href="https://blog.csdn.net/a747979985/article/details/94334901" target="_blank" rel="noopener">https://blog.csdn.net/a747979985/article/details/94334901</a></p>
<p>[10] <a href="https://wenku.baidu.com/view/fe595521bb68a98271fefad4?pcf=2&amp;fromShare=1&amp;fr=copy&amp;copyfr=copylinkpop" target="_blank" rel="noopener">https://wenku.baidu.com/view/fe595521bb68a98271fefad4?pcf=2&amp;fromShare=1&amp;fr=copy&amp;copyfr=copylinkpop</a></p>
<p> <sup><a href="#fn_实模式" id="reffn_实模式">实模式</a></sup>： 实模式采用 16 位寻址模式，在该模式中，最大寻址空间为 1MB，最大分段为 64KB。 由于处理器的设计需要考虑到兼容问题，8086 处理器地址总线扩展到 20 位，但CPU的ALU宽度(数据总线)却只有 16 位，也就是说直接参与运算的数值都是 16 位的。为支持 1MB 寻址空间，8086 处理器在实模式下引入了分段方法。在处理器中设置了四个 16 位的段寄存器:CS、DS、SS、ES，对 应于地址总线中的高 16 位。寻址时，采用以下公式计算实际访问的物理内存地址，这样，便实现了 16 位内存地址到 20 位物理地址的转换。</p>
]]></content>
      <tags>
        <tag>lab</tag>
      </tags>
  </entry>
  <entry>
    <title>Operating Systems</title>
    <url>/2020/07/17/Operating-Systems/</url>
    <content><![CDATA[]]></content>
      <tags>
        <tag>TODO</tag>
        <tag>读书笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>Language-go-goroutine</title>
    <url>/2020/12/03/Language-go-goroutine/</url>
    <content><![CDATA[<h3 id="Goroutine-和-系统线程"><a href="#Goroutine-和-系统线程" class="headerlink" title="Goroutine 和 系统线程"></a>Goroutine 和 系统线程</h3><p>​        Go语言的Goroutine之间是共享内存的。Goroutine是Go语言特有的并发体，是一种轻量级的线程，由go关键字启动。在真实的Go语言的实现中，goroutine和系统线程也<strong>不是等价</strong>的。尽管两者的区别实际上只是一个量的区别，但正是这个量变引发了Go语言并发编程质的飞跃。[1]</p>
<p>​        首先，每个系统级线程都会有一个固定大小的栈（一般默认可能是2MB），这个栈主要用来保存函数递归调用时参数和局部变量。固定了栈的大小导致了两个问题：一是对于很多只需要很小的栈空间的线程来说是一个巨大的<strong>浪费</strong>，二是对于少数需要巨大栈空间的线程来说又面临<strong>栈溢出</strong>的风险。针对这两个问题的解决方案是：要么降低固定的栈大小，提升空间的利用率；要么增大栈的大小以允许更深的函数递归调用，但这两者是没法同时兼得的。相反，一个Goroutine会以一个很<strong>小的栈启动</strong>（可能是2KB或4KB），当遇到深度递归导致当前栈空间不足时，Goroutine会根据需要<strong>动态地伸缩</strong>栈的大小（主流实现中栈的<strong>最大值可达到1GB</strong>）。因为启动的<strong>代价很小</strong>，所以我们可以轻易地启动成千上万个Goroutine。</p>
<p>​        Go的运行时还包含了其自己的调度器，这个调度器使用了一些技术手段，可以在n个操作系统线程上<strong>多工调度</strong>m个Goroutine。Go调度器的工作和内核的调度是相似的，但是这个调度器只关注单独的Go程序中的Goroutine。Goroutine采用的是<strong>半抢占式</strong>的协作调度，只有在当前Goroutine发生阻塞时才会导致调度；同时发生在用户态，调度器会根据具体函数只保存必要的寄存器，<strong>切换的代价</strong>要比系统线程<strong>低</strong>得多。运行时有一个<code>runtime.GOMAXPROCS</code>变量，用于控制当前运行正常非阻塞Goroutine的系统线程数目。</p>
<p>​        在Go语言中启动一个Goroutine不仅和调用函数一样简单，而且Goroutine之间调度代价也很低，这些因素极大地促进了并发编程的流行和发展。</p>
<h3 id="使用-goroutine"><a href="#使用-goroutine" class="headerlink" title="使用 goroutine"></a>使用 goroutine</h3><p>​        go 语言中使用 <code>goroutine</code> 只需要在调用的函数之前加上<code>go</code> 关键字，就可以为函数创建一个<code>goroutine</code>，一个<code>goroutine</code> 必须至少对应一个函数。</p>
<h4 id="启动单个goroutine"><a href="#启动单个goroutine" class="headerlink" title="启动单个goroutine"></a>启动单个goroutine</h4><pre><code class="lang-go">// goroutine_1.go
package main

import "fmt"
import "time"

func hello()  {
    fmt.Println("Hello, Goroutine!")
}

func main()  {
    go hello()  // 启动另外一个goroutine去执行hello函数
    fmt.Println("main goroutine done!")
    time.Sleep(time.Second)
}
</code></pre>
<p>​        在<code>goroutine_1.go</code>中，输出结果仅打印了<code>main goroutine done!</code>，而<code>hello()</code>函数中的结果没有输出，这是因为在程序启动时，Go程序就会为<code>main()</code>函数创建一个默认的主<code>goroutine</code>，当main()函数返回的时候该<code>goroutine</code>就结束了，所有在<code>main()</code>函数中启动的<code>goroutine</code>会一同结束，<code>main</code>函数所在的<code>goroutine</code>就像是权利的游戏中的夜王，其他的<code>goroutine</code>都是异鬼，夜王一死它转化的那些异鬼也就全部GG了 [2]。</p>
<p>如果要打印<code>hello()</code>函数中的内容，就要让<code>main</code>函数等一等。</p>
<pre><code class="lang-go">func main() {
    go hello() // 启动另外一个goroutine去执行hello函数
    fmt.Println("main goroutine done!")
    time.Sleep(time.Second)
}
</code></pre>
<p>​        这时会首先打印<code>main goroutine done!</code>是因为我们在创建新的goroutine的时候需要花费一些时间，而此时main函数所在的<code>goroutine</code>是继续执行的。</p>
<h4 id="启动多个-goroutine"><a href="#启动多个-goroutine" class="headerlink" title="启动多个 goroutine"></a>启动多个 goroutine</h4><p>使用<code>sync.WaitGroup</code>来实现goroutine的同步，实现并发执行，<code>goroutine</code>的调度是随机的。</p>
<pre><code class="lang-go">package main

import "fmt"
// import "time"
import "sync"

var wg sync.WaitGroup

func hello(i int)  {
    defer wg.Done()  // goroutine结束时登记 -1
    fmt.Println("Hello, Goroutine!", i)
}

func main()  {

    for i := 0; i &lt; 10; i++ {
        wg.Add(1) // 启动一个 goroutine 就 +1
        go hello(i)
        // fmt.Println("main loop : i = ", i)
    }

    wg.Wait()  // 等待所有登记的goroutine都结束

}
</code></pre>
<h3 id="原子操作"><a href="#原子操作" class="headerlink" title="原子操作"></a>原子操作</h3><p>​        所谓的原子操作就是并发编程中“最小的且不可并行化”的操作。通常，如果多个并发体对同一个共享资源进行的操作是原子的话，那么同一时刻<strong>最多只能有一个</strong>并发体对该资源进行操作。从线程角度看，在当前线程修改共享资源期间，其它的线程是不能访问该资源的。原子操作对于多线程并发编程模型来说，不会发生有别于单线程的意外情况，共享资源的完整性可以得到保证。</p>
<p>​        一般情况下，原子操作都是通过“互斥”访问来保证的，通常由特殊的CPU指令提供保护。当然，如果仅仅是想模拟下粗粒度的原子操作，我们可以借助于<code>sync.Mutex</code>来实现：</p>
<pre><code class="lang-go">package main

import (
    "sync"
    "fmt"
)

var total struct {
    sync.Mutex
    value int
}

func worker(wg *sync.WaitGroup)  {
    defer wg.Done()

    // fmt.Println("worker")

    for i := 0; i &lt; 10;  {
        total.Lock()
        total.value += 1
        total.Unlock()
        fmt.Println(total.value)
        i++
    }
}

func main()  {
    var wg sync.WaitGroup
    wg.Add(2)
    go worker(&amp;wg)
    go worker(&amp;wg)

    wg.Wait()
    // fmt.Println(total.value)
}
</code></pre>
<h3 id="Channel"><a href="#Channel" class="headerlink" title="Channel"></a>Channel</h3><h4 id="基本操作"><a href="#基本操作" class="headerlink" title="基本操作"></a>基本操作</h4><h5 id="声明"><a href="#声明" class="headerlink" title="声明"></a>声明</h5><p><code>channel</code>是一种引用类型，声明方式为 <code>var 变量 chan 元素类型</code></p>
<pre><code class="lang-go">var ch1 chan int   // 声明一个传递整型的通道
var ch2 chan bool  // 声明一个传递布尔型的通道
var ch3 chan []int // 声明一个传递int切片的通道
</code></pre>
<h5 id="创建channel"><a href="#创建channel" class="headerlink" title="创建channel"></a>创建channel</h5><p><code>channel</code>的缓冲大小是可选的，创建方式为 <code>make(chan 元素类型, [缓冲大小])</code></p>
<pre><code class="lang-go">ch4 := make(chan int)
ch5 := make(chan bool)
ch6 := make(chan []int)
</code></pre>
<h5 id="channel-操作"><a href="#channel-操作" class="headerlink" title="channel 操作"></a>channel 操作</h5><p>通道的操作分为 send, receive, close 三种操作，发送和接受都使用<code>&lt;-</code> 符号</p>
<p>创建一个缓冲大小为1的通道 <code>ch := make(chan int, 1)</code></p>
<p><strong>send</strong>              <code>ch &lt;- 10</code>  // 把10发送到ch</p>
<p><strong>receive</strong>          <code>x := &lt;- ch</code>  // 从ch 接受值赋给变量x</p>
<p><strong>close</strong>              <code>close(ch)</code>     // 调用内置的<code>close</code> 函数关闭通道</p>
<h4 id="创建有缓冲通道"><a href="#创建有缓冲通道" class="headerlink" title="创建有缓冲通道"></a>创建有缓冲通道</h4><pre><code class="lang-go">// goChannel_1.go
func main()  {
    ch := make(chan int, 1) // 创建一个容量为1 的有缓冲区通道
    ch &lt;- 10
    fmt.Println("send success!")
}
</code></pre>
<h4 id="创建无缓冲通道"><a href="#创建无缓冲通道" class="headerlink" title="创建无缓冲通道"></a>创建无缓冲通道</h4><pre><code class="lang-go">// goChannel_2.go

package main

import "fmt"

func recv(c chan int)  {
    ret := &lt;-c
    fmt.Println("receive success, ret = ", ret)
}

func main()  {
    ch := make(chan int) // 创建一个无缓冲区通道
    go recv(ch)
    ch &lt;- 10
    fmt.Println("send success!")
}
</code></pre>
<p>在对无缓冲通道进行操作时，如果像设置了缓冲大小的有缓冲方式对通道进行传递参数，会报错，因此，使用<code>goroutine</code>进行传递参数。</p>
<h4 id="两通道之间传递参数"><a href="#两通道之间传递参数" class="headerlink" title="两通道之间传递参数"></a>两通道之间传递参数</h4><pre><code class="lang-go">// goChannel_3.go

package main

import "fmt"

func main()  {
    ch1 := make(chan int) // 创建一个无缓冲区通道
    ch2 := make(chan int)

    // 开启 goroutine将0~10的数发送到 ch1中
    go func() {
        for i := 0; i &lt; 10; i++ {
            ch1 &lt;- i
        }
        close(ch1)
    }()

    // 开启 goroutine将该数字的平方发送到 ch2中
    go func() {
        for true {
            i, ok := &lt;- ch1  // 通道关闭后再取值，ok = false
            if !ok {
                break
            }
            ch2 &lt;- i * i
        }
        close(ch2)
    }()

    // 在主goroutine 中接收ch2 值
    for i:= range ch2 { // 通道关闭后会退出 循环
        fmt.Println("ch2 = ",i)
    }
}
</code></pre>
<p>使用<code>for range</code>方式读取通道内数据</p>
<pre><code class="lang-go">// goChannel_3plus.go

package main

import "fmt"

func initValue(ch1 chan int)  {
    for i := 0; i &lt; 10; i++ {
        ch1 &lt;- i
    }
    close(ch1)
}

func square(ch2 chan int, ch1 chan int)  {

    for true {
        i, ok := &lt;- ch1
        if !ok {
            break
        }
        ch2 &lt;- i * i
    }
    close(ch2)
}

func main()  {
    ch1 := make(chan int) // 创建一个无缓冲区通道
    ch2 := make(chan int)

    // 开启 goroutine将0~100的数发送到 ch1中
    go initValue(ch1)

    // 开启 goroutine将该数字的平方发送到 ch2中
    go square(ch2, ch1)

    // 在主goroutine 中接收ch2 值
    for i:= range ch2 { // 通道关闭后会退出 循环
        fmt.Println("ch2 = ",i)
    }
}
</code></pre>
<h4 id="单向通道"><a href="#单向通道" class="headerlink" title="单向通道"></a>单向通道</h4><ul>
<li><code>chan&lt;- int</code>是一个只写单向通道（只能对其写入int类型值），可以对其执行发送操作但是不能执行接收操作；</li>
<li><code>&lt;-chan int</code>是一个只读单向通道（只能从其读取int类型值），可以对其执行接收操作但是不能执行发送操作。</li>
</ul>
<pre><code class="lang-go">// goChannel_4.go

package main

import "fmt"

func counter(out chan&lt;- int)  {
    for i := 0; i &lt; 10; i++ {
        out &lt;- i
    }
    close(out)
}

func squarer(out chan&lt;- int, in &lt;-chan int)  {
    for i := range in{
        out &lt;- i * i
    }
    close(out)
}

func printer(in &lt;-chan int)  {
    for i := range in{
        fmt.Println(i)
    }
}

func main()  {
    ch1 := make(chan int) // 创建一个无缓冲区通道
    ch2 := make(chan int)

    // 开启 goroutine将0~100的数发送到 ch1中
    go counter(ch1)

    // 开启 goroutine将该数字的平方发送到 ch2中
    go squarer(ch2, ch1)

    printer(ch2)

}
</code></pre>
<h4 id="channel-总结"><a href="#channel-总结" class="headerlink" title="channel 总结"></a>channel 总结</h4><div class="table-container">
<table>
<thead>
<tr>
<th>channel</th>
<th>nil</th>
<th>非空</th>
<th>空</th>
<th>满</th>
<th>非满</th>
</tr>
</thead>
<tbody>
<tr>
<td>接受</td>
<td><font color="orange">阻塞</font></td>
<td>接收值</td>
<td><font color="orange">阻塞</font></td>
<td>接收值</td>
<td>接收值</td>
</tr>
<tr>
<td>发送</td>
<td><font color="orange">阻塞</font></td>
<td>发送值</td>
<td>发送值</td>
<td><font color="orange">阻塞</font></td>
<td>发送值</td>
</tr>
<tr>
<td>关闭</td>
<td><font color="red">panic</font></td>
<td>关闭成功，读完数据后返回零值</td>
<td>关闭成功，返回零值</td>
<td>关闭成功，读完数据后返回零值</td>
<td>关闭成功，读完数据后返回零值</td>
</tr>
</tbody>
</table>
</div>
<h3 id="References"><a href="#References" class="headerlink" title="References"></a>References</h3><p>[1] <a href="https://chai2010.cn/advanced-go-programming-book/ch1-basic/ch1-05-mem.html" target="_blank" rel="noopener">https://chai2010.cn/advanced-go-programming-book/ch1-basic/ch1-05-mem.html</a><br>[2] <a href="https://www.liwenzhou.com/posts/Go/14_concurrence/#autoid-1-1-0" target="_blank" rel="noopener">https://www.liwenzhou.com/posts/Go/14_concurrence/#autoid-1-1-0</a></p>
]]></content>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title>CHANCEL</title>
    <url>/2021/05/24/CHANCEL/</url>
    <content><![CDATA[<h2 id="导读"><a href="#导读" class="headerlink" title="导读"></a>导读</h2><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">序号</th>
<th style="text-align:left">属性</th>
<th style="text-align:center">内容</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:left">原文PDF</td>
<td style="text-align:center"><a href="https://lifeasageek.github.io/papers/ahmad-chancel.pdf" target="_blank" rel="noopener">paper</a> <a href="https://lifeasageek.github.io/papers/ahmad-chancel-slides.pdf" target="_blank" rel="noopener">slides</a></td>
</tr>
<tr>
<td style="text-align:center">2</td>
<td style="text-align:left">作者信息</td>
<td style="text-align:center"><a href="https://web.ics.purdue.edu/~ahmad37/" target="_blank" rel="noopener">https://web.ics.purdue.edu/~ahmad37/</a> <a href="https://www.cs.purdue.edu/homes/pfonseca/" target="_blank" rel="noopener">https://www.cs.purdue.edu/homes/pfonseca/</a> <a href="https://lifeasageek.github.io/" target="_blank" rel="noopener">https://lifeasageek.github.io/</a></td>
</tr>
<tr>
<td style="text-align:center">3</td>
<td style="text-align:left">核心内容</td>
<td style="text-align:center">在飞地中为多个用户提供隔离保障</td>
</tr>
<tr>
<td style="text-align:center">4</td>
<td style="text-align:left">研究领域</td>
<td style="text-align:center">TEE 可信计算环境</td>
</tr>
<tr>
<td style="text-align:center">5</td>
<td style="text-align:left">全文总览</td>
<td style="text-align:center">在飞地中为多个用户提供隔离保障，从而避免用户执行代码的漏洞导致的隐私数据泄露，在提供安全保证的同时，与多进程沙盒对比，有着明显的性能提升。</td>
</tr>
</tbody>
</table>
</div>
<h2 id="研究动机"><a href="#研究动机" class="headerlink" title="研究动机"></a>研究动机</h2><p>SGX 能够在非可信的云端为用户保护隐私数据，但是应用的程序可能会包含很多漏洞，这些漏洞可能会泄露隐私数据。很多的研究为了解决这个问题，但是没有考虑在同一个飞地中多客户的隔离问题。因此本文的工作是在飞地中为多个用户提供隔离保障。本文提出CHANCEL，其允许程序的线程在处理请求时访问每个线程的内存区以及共享的只读内存区。每个线程一次处理一个客户端的请求，并且客户端之间是利用软件故障隔离方案相互隔离的。</p>
<h2 id="背景知识"><a href="#背景知识" class="headerlink" title="背景知识"></a>背景知识</h2><h3 id="SGX-总览"><a href="#SGX-总览" class="headerlink" title="SGX 总览"></a>SGX 总览</h3><p>SGX（software guard extensions）[1]</p>
<p>SGX 是指<a href="https://software.intel.com/en-us/sgx" target="_blank" rel="noopener">英特尔® Software Guard Extensions</a>（英特尔® SGX）。这是一组指令，应用程序可以使用这些指令为选择的代码和数据留出受保护区域，以防止对执行代码或存储在内存中的数据进行直接攻击。SGX 允许应用程序实例化一个受保护的容器，称为 enclave，它可以防止外部软件访问，包括特权恶意软件。</p>
<p>安全性是云计算中一项极为重要的需求,然而如何保护云计算中关键应用程序和数据的安全、防止云平台管理员泄露用户隐私,仍然是目前没有解决的难题.2013 年,Intel 公司提出了新的处理器安全技术 SGX,能够在计算平台上提供一个可信的隔离空间,保障用户关键代码和数据的机密性和完整性.作为系统安全领域的重大研究进展,SGX 对系统安全,尤其是云计算安全保护方面具有非常重要的意义.</p>
<p>2013 年,Intel 推出 SGX(software guard extensions)指令集扩展,旨在以硬件安全为强制性保障,<strong>不依赖</strong>于<strong>固件和软件</strong>的安全状态,提供用户空间的可信执行环境,通过一组新的指令集扩展与访问控制机制,实现不同程序间的隔离运行,保障用户<strong>关键代码和数据的机密性与完整性</strong>不受恶意软件的破坏.不同于其他安全技术,SGX 的可信计算基(trusted computing base,简称 TCB)<strong>仅包括硬件</strong>,避免了基于软件的 TCB 自身存在软件安全漏洞与威胁的缺陷,极大地提升了系统安全保障;此外,SGX 可保障运行时的可信执行环境,恶意代码<strong>无法访问与篡改其他程序运行时的保护内容</strong>,进一步增强了系统的安全性;基于<strong>指令集的扩展</strong>与<strong>独立的认证</strong>方式,使得应用程序可以灵活调用这一安全功能并进行验证.</p>
<p>SGX 的实现需要处理器、内存管理部件、BIOS、驱动程序、运行时环境等软硬件协同完成.SGX提供的功能大多数是在微指令中实现，但是保护内存不受物理攻击主要是由CPU中的MEE（memory encryption engine）硬件单元提供，这个硬件通过对保护内存读写的解密加密，保证了数据只有在CPU中的enclave内存中才是明文.</p>
<p><strong>功能：</strong>内存隔离/保护安全属性/远程认证/密封.</p>
<h3 id="SGX-架构"><a href="#SGX-架构" class="headerlink" title="SGX 架构"></a>SGX 架构</h3><p><img src="/2021/05/24/CHANCEL/sgx-architecture-1.png" width="600px"></p>
<h3 id="enclave"><a href="#enclave" class="headerlink" title="enclave"></a>enclave</h3><p>地理学上的解释</p>
<blockquote>
<p>外飞地(Exclave)：某国家拥有一块与该国分离开来的领土，该领土被其他国家隔开，则该领土称为某国的外飞地。</p>
<p>内飞地(Enclave): 某国家国境之内有块地区的主权属于别的国家，则该地区是这国家的内飞地，也同时是握有主权国家的外飞地。</p>
</blockquote>
<p>SGX允许应用程序实现一个被称为 enclave 的容器,在应用程序的地址空间中划分出一块被保护的区域,为容器内的代码和数据提供机密性和完整性的保护,免受拥有特殊权限的恶意软件的破坏.</p>
<p>enclave 是一个被保护的容器，存放应用程序敏感数据和代码，SGX允许应用程序指定需要保护的代码和数据，创建enclave之前，不必对其进行分析，加载到enclave之后，必须被完整度量，且之后SGX保证其不能被外部软件所访问.  enclave都驻留在EPC（enclave page cache）中，这是系统内被保护的物理内存，用于存放enclave和SGX数据结构.以支持SGX的一种架构为例，如果在加密保护的DRAM (dynamic random access memory) 中实现EPC，那么他也支持BIOS保留一段PRM（processor reserved memory）的内存.</p>
<p><strong>enclave 特征：</strong></p>
<blockquote>
<p>有自己的代码和数据/机密性保护/完整性保护/可控的入口点/支持多线程/内存具有最高访问权限.</p>
<p>TCS (thread control structure) 保存着进入或者退出enclave时的线程信息, 每一个enclave中的线程都和一个TCS关联, 需要4K对齐.</p>
</blockquote>
<p><strong>enclave 架构图：</strong></p>
<p><img src="/2021/05/24/CHANCEL/sgx-prm-enclave.png" width="800"></p>
<p><img src="/2021/05/24/CHANCEL/enclave-layout.png" width="500"></p>
<p><img src="/2021/05/24/CHANCEL/enclave-privileged.png" width="500"></p>
<p><strong>远端验证：</strong> enclave 可以向远端认证者证明自己的身份，访问该enclave的用户也持有独立的访问秘钥.</p>
<p><strong>Physical Memory Organization:</strong> （下文详细介绍）</p>
<p><img src="/2021/05/24/CHANCEL/enclave-physical-mem-1.png" width="800"></p>
<p><img src="/2021/05/24/CHANCEL/enclave-mem-map-1.png" width="800"></p>
<p><strong>SGX memory control:</strong></p>
<p><img src="/2021/05/24/CHANCEL/SGX-mem-control.png" width="500"></p>
<p><strong>enclave 保护机制：</strong> 1. enclave内存访问语义变化, 2. 应用程序地址映射关系保护</p>
<p><strong>1. 内存访问语义</strong></p>
<blockquote>
<p>系统分配一块被保护的物理内存区域EPC，用于存放enclave和SGX数据结构，该段区域对于外部请求透明（不存在的内存访问）</p>
<p>Fig.4 中的内存保护机制中，系统在SGX调用前处于保护模式，支持分页. SGX提供的内存保护机制，在保护模式提供的段保护、页保护机制基础上增加了进一步的保护机制：</p>
<p>(1). enclave之外应用访问PRM外部内存，按照保护模式进行访问；</p>
<p>(2). enclave之外应用访问EPC内部内存，该内存区域不存在（透明）；</p>
<p>(3). enclave内部程序访问EPC内部内存，该内存区域不存在（透明）；</p>
<p>(4). enclave内部程序访问PRM外部内存，按照保护模式进行访问；</p>
<p>(5). enclave内部程序访问PRM内部内存，硬件阻止访问。</p>
<p>简言之：enclave外部不能访问，内部只能访问属于自己的内存，PRM之外的内存按照系统的保护机制进行访问。</p>
</blockquote>
<p><strong>EPCM （Enclave Page Cache Map）逻辑结构：</strong></p>
<p><img src="/2021/05/24/CHANCEL/EPCM-structure.png" width="500"></p>
<p><strong>2. 内存地址映射保护</strong></p>
<p>EPC内存以页为单位进行管理，页的控制信息保存在EPCM中，类似于OS中的页表，功能是在CPU地址映射过程中执行enclave页面的访问控制，通过PMH(page miss handler)硬件模块访问，在保护模式的段、页保护机制上增加了一层安全的访问控制.</p>
<p><strong>enclave 机密性和完整性保护：</strong></p>
<blockquote>
<p>(1). 由应用程序申请创建一个enclave, 页面分配，复制程序代码、数据并进行度量，度量结果保存在enclave的控制结构中；</p>
<p>(2). 创建好之后，SGX通过初始化指令将结果与enclave所有者签名证书的完整性值进行比较，匹配的话，则进行绑定，否则创建失败；</p>
<p>(3). 成功之后，指定用户可以访问对应的enclave, SGX提供内存保护以及地址映射保护，从而保证enclave的机密性与完整性，远端认证者可以通过enclave的完整性度量结果以及身份，确保其enclave正确创建.</p>
</blockquote>
<h3 id="SGX-漏洞"><a href="#SGX-漏洞" class="headerlink" title="SGX 漏洞"></a>SGX 漏洞</h3><p><strong>1.侧信道攻击</strong></p>
<p>侧信道攻击主要目标是攻击 enclave 数据的机密性.</p>
<p>攻击者来自 non-enclave 部分,包括应用程序和系统软件.系统软件包括 OS,hypervisor,SMM(system management mode),BIOS 等特权级软件.</p>
<p><strong>三个假设：</strong></p>
<blockquote>
<p>1.侧信道攻击者指导enclave初始化的代码和数据，知道内存布局；</p>
<p>2.攻击者知道enclave的输入数据，可以反复多次触发enclave，记录并观察结果；</p>
<p>3.攻击者知道运行enclave平台的配置(CPU、TLB、Cache、DRAM、页表、中断以及异常等)</p>
</blockquote>
<p><strong>enclave运行使用的物理资源及攻击方式总览：</strong></p>
<blockquote>
<p>CPU: 间接访问pipeline/BPB(branch prediction buffer)，可以泄露enclave的控制流或者数据流；</p>
<p>TLB : TLB包括 iTLB,dTLB和 L2 TLB.如果Hyper-Threading打开,两个逻辑核共享一个物理核,这时会大大增加侧信道攻击的可能;</p>
<p>Cache: Cache 包括 L1 instruction Cache,L1 data Cache,L2 Cache 和 L3 Cache(又叫 LLC Cache);</p>
<p>DRAM：DRAM 包括 channels,DIMMs(dual inline memory module),ranks,banks.每个 banks 又包括 rows, columns 和 row buffer;</p>
<p>页表：页表可以通过权限控制来触发缺页异常,也可以通过页表的状态位来表明 CPU 的某些操作.</p>
</blockquote>
<p><img src="/2021/05/24/CHANCEL/SGX-side-channel-attack-surface.png" width="600"></p>
<p><strong>2. SGX 多线程同步</strong></p>
<p>[4] 指出在使用SGX后以往被视为无害的同步漏洞可能会变为严重的安全漏洞。通过在enclave代码中利用UAF(use-after-free)和TOCTTOU(time-of-check-to-time-of-use)漏洞，一个攻击者可以劫持它的控制流或者绕过访问控制。</p>
<p><strong>Native Client</strong> </p>
<p>Native client[5] 是一个用于执行不可信x86主机代码的沙箱，利用沙盒技术防止外来机器代码影响系统安全，限制程序读写的存储器范围，为基于浏览器的应用程序提供本地应用程序的计算性能，而不会影响安全性。09年提出。</p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>sgx 的设计是每个用户是一个单独进程，每个进程绑定一个enclave，enclave之间是相互隔离开的，不涉及数据共享，则会浪费内存空间，因此设计目标是在保证数据共享节约内存空间基础上实现用户的隔离。</p>
<p><img src="/2021/05/24/CHANCEL/sgx-non-share.png" width="600"></p>
<p>在实现多用户间隔离时，chancel保证共享数据的多个用户处于同一个进程空间中，每个用户是一个线程，实现线程级别隔离。</p>
<p><img src="/2021/05/24/CHANCEL/mulit-client-SFI.png" width="600"></p>
<p><img src="/2021/05/24/CHANCEL/chancel-design.png" width="600"></p>
<h2 id="实验结论"><a href="#实验结论" class="headerlink" title="实验结论"></a>实验结论</h2><p>与多进程沙盒作对比，在保证安全的同时提升了4-53倍的性能</p>
<p><img src="/2021/05/24/CHANCEL/benefit.png" width="600"></p>
<h2 id="阅读问题记录"><a href="#阅读问题记录" class="headerlink" title="阅读问题记录"></a>阅读问题记录</h2><ol>
<li><p>本文的核心是什么？多线程并发隔离？</p>
</li>
<li><p><strong>Section V:</strong>本文与原始SGX对比有哪些改动？原始的SGX提供了什么？</p>
</li>
<li><p>SGX与enclave的关系？enclave是一个用户一个还是多用户共享？</p>
<blockquote>
<p>Enclave是SGX提供给用户的一个隔离的执行环境，初始化时建立对应的enclave</p>
</blockquote>
</li>
<li><p>Section V: 文中提到的SecureLayer是什么？MCSFI是本文构建的吗？</p>
</li>
<li><p>r14,15寄存器作用？</p>
<blockquote>
<p>本文r14指向单独线程的私有空间地址，r15指向该进程的共享数据空间。</p>
</blockquote>
</li>
<li><p>native sgx 与 native client 指的是什么？</p>
<blockquote>
<p>sgx 只内存中开辟的空间，nacl指的是挂载到该空间的客户</p>
</blockquote>
</li>
<li><p>SGX 真实的使用中代码的大小有多少？64MB？</p>
</li>
</ol>
<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><p>说明：本文的一些截图来自于以下论文或者网站，图片序号没有标注，其中sgx101[2]是一个不错的sgx学习网站.</p>
<p>[1] 王鹃, 樊成阳, 程越强, 赵波, 韦韬, 严飞, 张焕国,&amp; 马婧. (2018). SGX 技术的分析和研究. <em>软件学报</em>, <em>29</em>(9), 2778-2798.</p>
<p>[2] <a href="https://sslab-gatech.github.io/sgx101/pages/enclave.html" target="_blank" rel="noopener">https://sslab-gatech.github.io/sgx101/pages/enclave.html</a></p>
<p>[3] Costan, V., &amp; Devadas, S. (2016). Intel SGX Explained. <em>IACR</em> <em>Cryptol**.</em> <em>ePrint</em> <em>Arch.</em>, <em>2016</em>(86), 1-118. <a href="https://eprint.iacr.org/2016/086.pdf" target="_blank" rel="noopener">https://eprint.iacr.org/2016/086.pdf</a></p>
<p>[4] Weichbrodt N, Kurmus A, Pietzuch P, Kapitza R. AsyncShock: Exploiting synchronisation bugs in Intel SGX enclaves. In: Proc. of the Computer Security (ESORICS 2016). 2016. 440−457. </p>
<p>[5] Yee, B., Sehr, D., Dardyk, G., Chen, J. B., Muth, R., Ormandy, T., &amp; Fullagar, N. (2009, May). Native client: A sandbox for portable, untrusted x86 native code. In <em>2009 30th IEEE Symposium on Security and Privacy</em> (pp. 79-93). IEEE.</p>
<p>[6] <a href="https://zhuanlan.zhihu.com/p/50894009" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/50894009</a></p>
<p>[7] Xing, B. C., Shanahan, M., &amp; Leslie-Hurd, R. (2016). Intel® Software Guard Extensions (Intel® SGX) software support for dynamic memory allocation inside an enclave. In <em>Proceedings of the Hardware and Architectural Support for Security and Privacy 2016</em> (pp. 1-9).</p>
]]></content>
      <categories>
        <category>NDSS</category>
      </categories>
      <tags>
        <tag>论文解读</tag>
        <tag>TEE</tag>
      </tags>
  </entry>
  <entry>
    <title>PengLai-Enclave</title>
    <url>/2021/07/07/PengLai-Enclave/</url>
    <content><![CDATA[<h2 id="导读"><a href="#导读" class="headerlink" title="导读"></a>导读</h2><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">序号</th>
<th style="text-align:left">属性</th>
<th style="text-align:center">内容</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:left">原文PDF</td>
<td style="text-align:center"><a href="https://www.usenix.org/system/files/osdi20-hao.pdf" target="_blank" rel="noopener">paper</a> <a href="https://www.usenix.org/sites/default/files/conference/protected-files/osdi20_slides_hao.pdf" target="_blank" rel="noopener">slides</a> <a href="https://penglai-enclave.systems/" target="_blank" rel="noopener">penglai</a></td>
</tr>
<tr>
<td style="text-align:center">2</td>
<td style="text-align:left">作者信息</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">3</td>
<td style="text-align:left">核心内容</td>
<td style="text-align:center">LinnOS 实现一种轻量级神经网络细粒度推断SSD性能，实现性能可预测性。</td>
</tr>
<tr>
<td style="text-align:center">4</td>
<td style="text-align:left">研究领域</td>
<td style="text-align:center">Storage</td>
</tr>
<tr>
<td style="text-align:center">5</td>
<td style="text-align:left">全文总览</td>
<td style="text-align:center"></td>
</tr>
</tbody>
</table>
</div>
]]></content>
      <categories>
        <category>OSDI</category>
      </categories>
      <tags>
        <tag>TODO</tag>
        <tag>论文解读</tag>
        <tag>TEE</tag>
      </tags>
  </entry>
  <entry>
    <title>PrivateEye</title>
    <url>/2020/10/09/PrivateEye/</url>
    <content><![CDATA[<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">序号</th>
<th style="text-align:center">属性</th>
<th style="text-align:center">内容</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">原文PDF</td>
<td style="text-align:center"><a href="https://www.usenix.org/system/files/nsdi20-paper-arzani.pdf" target="_blank" rel="noopener">PrivateEye</a></td>
</tr>
<tr>
<td style="text-align:center">2</td>
<td style="text-align:center">作者信息</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">3</td>
<td style="text-align:center">核心内容</td>
<td style="text-align:center">对部署在云上的虚拟机进行保护，而不是对hypervisor进行防护</td>
</tr>
<tr>
<td style="text-align:center">4</td>
<td style="text-align:center">研究领域</td>
<td style="text-align:center">保护云安全</td>
</tr>
<tr>
<td style="text-align:center">5</td>
<td style="text-align:center">全文总览</td>
<td style="text-align:center">通过对少数机器进行保护，得到攻击者特征，并利用此特征对云上全部机器进行保护。</td>
</tr>
</tbody>
</table>
</div>
<h3 id="总览"><a href="#总览" class="headerlink" title="总览"></a>总览</h3><p>​        云中会部署一些可以检测VM是否受攻击的检测系统，但是往往都没有启用，这就使得VM在云上几乎在没有任何保护的情况下运行，这在安全的角度看是十分不可取的。让用户在不受保护的状态下运行或者完全在云供应商提供的检测系统的保护下运行，这两者似乎都不可取。如果不保护，则受攻击的VM可以攻击其余未被攻击的VM，并且不是所有的用户都需要在被严格保护的情况下运行。经过统计，约5%的用户愿意承担云供应商提供的安全监测系统的额外费用。本文基于此提出PrivateEye解决方案，它是一个可扩展、解决隐私保护的解决方案，能够对数据中心全部的VM进行防护。通过检测较少的机器，将检测后结果应用于云中其余的机器进行检测。</p>
<p>保护的定位：<br>针对云上的VMs,而不是hypervisor本身。</p>
<p>使用的方法：<br>利用机器学习的方法，根据已经存在的5%的少数用户特征，应用于云上全部主机检测。</p>
<p>​        本文目标是提供给用户一个透明的（不需要用户权限）可以保护客户机隐私、数据中心级别的保护机制，并且无需进行广泛而昂贵的监控，目标是针对全部的VM进行防护。</p>
<p><img src="/2020/10/09/PrivateEye/private_1.png" width="500px" height="300px"></p>
<h3 id="威胁模型"><a href="#威胁模型" class="headerlink" title="威胁模型"></a>威胁模型</h3><p>​        本文认为任何VM都不是可信的，因为他们可以运行任何的代码，但是，云供应商提供的hypervisor、网络以及硬件是可靠的。并且认为供应商提供的检测方式能够足够精确的保护供应商提供的VMs.其中恶意软件为了掩盖其攻击能够调整自身行为，但是恶意软件无法识别VM是否受到供应商的保护。并且云供应商的保护软件可以通过近期的检测重新训练PrivateEye，因此PrivateEye可以通过不断的训练起到保护云上主机安全的目的。</p>
<p>​        供应商仅能要求使用他们所提供工作负载的第一方VM使用OBDs,但是不能要求全部的VM都使用，并且在Azure的统计显示，超过95%的用户不使用OBDs。正因为用户不愿意使用供应商提供的检测器，所以基于此受限，供应商只能使用非侵入式的检测来保证VM不受侵害。</p>
<p>设计目标：</p>
<ol>
<li><p>GDPR（欧洲数据隐私法）： 要求可以追踪用户的个人隐私信息（PII），以便用户可以检查或者删除此信息。供应商需要在48小时内回答用户请求，这时供应商可以1. 使用原数据对数据进行连接和标记，2. 或者避免存储与PII相关的数据。这就要求VM的公共IP必须映射到用户账户，但公共IP 是动态及时分配的，因此GDPR 对PII的处理代价是十分昂贵的。（PrivateEye是如何处理的？）</p>
</li>
<li><p>较低的运行代价</p>
</li>
<li><p>OBD对大量的VM进行检测获取到充足的攻击数据集。</p>
</li>
<li><p>（OBDs 与PrivateEye关系：后者更宏观，前者更具有通用的保护性）</p>
</li>
</ol>
<p>OBDs是一个广泛的监控器，PrivateEye对VM有着更加严格的监控，目的是避免大量用户没必要的损失。在不必要的更进一步的检测时无需客户机的许可就会对VM进行保护，一旦发现可疑攻击，就会对VM发出警告，以请求更深入的检测VM。</p>
<p><img src="/2020/10/09/PrivateEye/architecture.png" width="500px" height="300px"></p>
<h3 id="Evaluation"><a href="#Evaluation" class="headerlink" title="Evaluation"></a>Evaluation</h3><p>• What is PrivateEye’s accuracy? </p>
<p>​        PrivateEye can detect 95.77% of compromised samples with 1% FPR.</p>
<p>• What causes PrivateEye’s false positives/negatives? </p>
<p>​        PrivateEye’s FNs were mostly OBD false positives.</p>
<p>• How does PrivateEye’s RF compare to other models? </p>
<p>​        PrivateEye’s FPs have similar flow-patterns to compro- mised VMs. </p>
<p>• How does PrivateEye’s sampling limit affect accuracy? </p>
<p>​        The choice of sampling limit is important.</p>
 <font color="green"> 蜜罐 </font>

<p>​        本质上是一种对攻击方进行欺骗的技术，通过布置一些作为诱饵的主机、网络服务或者信息，诱使攻击方对它们实施攻击，从而可以对攻击行为进行捕获和分析，了解攻击方所使用的工具与方法，推测攻击意图和动机，能够让防御方清晰地了解他们所面对的安全威胁，并通过技术和管理手段来增强实际系统的安全防护能力。蜜罐好比是情报收集系统。蜜罐好像是故意让人攻击的目标，引诱黑客前来攻击。所以攻击者入侵后，你就可以知道他是如何得逞的，随时了解针对服务器发动的最新的攻击和漏洞。还可以通过窃听黑客之间的联系，收集黑客所用的种种工具，并且掌握他们的社交网络。</p>
]]></content>
      <categories>
        <category>NSDI</category>
      </categories>
      <tags>
        <tag>Virtual Machine</tag>
        <tag>Hypervisor</tag>
      </tags>
  </entry>
  <entry>
    <title>RADAR</title>
    <url>/2020/07/18/RADAR/</url>
    <content><![CDATA[]]></content>
      <categories>
        <category>Security and Privacy</category>
        <category>TODO</category>
      </categories>
      <tags>
        <tag>论文解读</tag>
      </tags>
  </entry>
  <entry>
    <title>MuonTrap-Preventing Cross-Domain Spectre-Like</title>
    <url>/2021/03/15/MuonTrap-Preventing-Cross-Domain-Spectre-Like/</url>
    <content><![CDATA[<p>清华安全公众号推荐</p>
]]></content>
      <tags>
        <tag>TODO</tag>
      </tags>
  </entry>
  <entry>
    <title>Pioneer</title>
    <url>/2020/11/23/Pioneer/</url>
    <content><![CDATA[<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">序号</th>
<th style="text-align:center">属性</th>
<th style="text-align:center">内容</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">原文PDF</td>
<td style="text-align:center"><a href="https://www.cs.princeton.edu/courses/archive/spr06/cos592/bib/pioneer-seshadri-sosp05.pdf" target="_blank" rel="noopener">Pioneer</a></td>
</tr>
<tr>
<td style="text-align:center">2</td>
<td style="text-align:center">作者信息</td>
<td style="text-align:center">CMU/CyLab</td>
</tr>
<tr>
<td style="text-align:center">3</td>
<td style="text-align:center">核心内容</td>
<td style="text-align:center">one-on-one 方式检测内存信息是否有差别</td>
</tr>
<tr>
<td style="text-align:center">4</td>
<td style="text-align:center">研究领域</td>
<td style="text-align:center">安全检测</td>
</tr>
<tr>
<td style="text-align:center">5</td>
<td style="text-align:center">全文总览</td>
<td style="text-align:center">通过one-on-one 的方法对非可信主机进行检测，从而构造出一个可信的执行环境。</td>
</tr>
</tbody>
</table>
</div>
<h3 id="全文概览"><a href="#全文概览" class="headerlink" title="全文概览"></a>全文概览</h3><p>​        本文提出的pioneer是在不受信任的主机上执行可验证代码的第一步，无需任何硬件的支持，pioneer可以作为构建安全系统的基本构建块。并通过构建内核rootkit检测器来证明其可用性。Pioneer基于扩展的外部可信实体以及 challenge-response ptotocol 通过可信的通讯连接为非可信平台提供了运行时的验证，其中可信主机与非可信主机具有相同的验证函数，包括相同的代码序列和内存布局。</p>
<h3 id="攻击假设"><a href="#攻击假设" class="headerlink" title="攻击假设"></a>攻击假设</h3><p>在非可信的平台执行代码往往会有几种威胁：</p>
<ol>
<li>在代码调用之前进行更改；</li>
<li>引导程序执行备份代码；</li>
<li>在代码执行过程中进行更改。</li>
</ol>
<p>假设：</p>
<p>​        攻击者对其所在机器的软件有绝对的控制权，包括其上的应用程序和操作系统；</p>
<p>​        攻击者不能对硬件进行更改（不能对磁盘或者网络加载恶意的固件），不能调用更快的CPU进行计算，不能够直接使用DMA攻击。</p>
<h3 id="设计架构"><a href="#设计架构" class="headerlink" title="设计架构"></a>设计架构</h3><h4 id="Pioneer中的角色"><a href="#Pioneer中的角色" class="headerlink" title="Pioneer中的角色"></a>Pioneer中的角色</h4><p><strong>dispatcher</strong> ： 预先知道非可信平台的硬件配置信息；</p>
<p><strong>untrusted platform</strong> ： 具有但CPU， 且CPU不支持对称多线程（保证运行时的稳定性，检测时间不会大幅度的变化）</p>
<p><strong>communication channel</strong> : 消息源的认证，在检测时，非可信平台仅与<code>dispatcher</code>进行通讯。</p>
<h4 id="检测协议流程"><a href="#检测协议流程" class="headerlink" title="检测协议流程"></a>检测协议流程</h4><p><img src="/2020/11/23/Pioneer/checkflow.png" height="260"></p>
<p><strong>对rootkits进行检测</strong></p>
<p><img src="/2020/11/23/Pioneer/kma.png" height="260"></p>
<h3 id="检测方法"><a href="#检测方法" class="headerlink" title="检测方法"></a>检测方法</h3><h3 id="验证方法"><a href="#验证方法" class="headerlink" title="验证方法"></a>验证方法</h3><h3 id="本文是否能够回答审稿人的全部问题？"><a href="#本文是否能够回答审稿人的全部问题？" class="headerlink" title="本文是否能够回答审稿人的全部问题？"></a>本文是否能够回答审稿人的全部问题？</h3>]]></content>
      <categories>
        <category>SOSP</category>
      </categories>
      <tags>
        <tag>TODO</tag>
        <tag>论文解读</tag>
      </tags>
  </entry>
  <entry>
    <title>ROP attacks</title>
    <url>/2021/02/01/ROP-attacks/</url>
    <content><![CDATA[<h3 id="栈溢出"><a href="#栈溢出" class="headerlink" title="栈溢出"></a>栈溢出</h3><p>由于<code>C</code> 语言对数组引用不做任何边界检查，从而导致缓冲区溢出<code>buffer overflow</code>，这成为一种常见的漏洞。根据溢出发生的内存位置，可以分为栈溢出和堆溢出。其中，由于栈上保存着局部变量和一些状态信息，例如寄存器值和返回地址等，一旦发生严重溢出，攻击者可以通过复写返回地址来执行任意代码，利用包括<code>shellcode</code>注入、ret2libc、<code>ROP</code>等。</p>
<h3 id="What-is-ROP"><a href="#What-is-ROP" class="headerlink" title="What is ROP"></a>What is ROP</h3><p>最开始，要利用栈溢出只需将返回地址覆盖为 jmp esp 指令的地址，并在后面添加 shellcode 就可以执行。后来引入了 NX 缓解机制，数据所在的内存页被标记为不可执行，此时再执行 shellcode 就会抛出异常。既然注入新代码不可行，那么就复用程序中已有的代码。libc.so 几乎在每个程序执 行时都会加载，攻击者就开始考虑利用 libc 中的函数，这种技术就是 ret2libc。但是这种技术也有缺陷，首先，虽然攻击者可以一个接一个地调用 libc 中的函数，但这个执行流仍然是线性的，而不像代码注入那样任意执行，其次，攻击者只能使用程序 text 段和 libc 中已有的函数，通过移除这些特定的函数就可以限制此类攻击。</p>
<p>论文 <code>The Geometry of Innocent Flesh on the Bone: Return-into-libc without Function Calls (on the x86)</code>提出了一种新的攻击技术——返回导向编程<code>（Return-Oriented Programming, ROP）</code>，无须调用任何函数即可执行任意代码。</p>
<p>使用 ROP 攻击，首先需要扫描文件，提取出可用的 gadget 片段（通常以 ret 指令结尾），然后<br>将这些 gadget 根据所需要的功能进行组合，达到攻击者的目的。举个小例子，exit(0)的 shellcode 由<br>下面 4 条连续的指令组成。</p>
<pre><code class="lang-c">; exit(0) shellcode
xor eax, eax
xor ebx, ebx
inc eax
int 0x80
</code></pre>
<p>如果要将它改写成 ROP 链，则需要分别找到包含这些指令的 gadget，由于它们在地址上不一定<br>是连续的，所以需要通过 ret 指令进行连接，依次执行。</p>
<pre><code class="lang-C">; exit(0) ROP chain
xor eax, eax ; gadget 1
ret
xor ebx, ebx ; gadget 2
ret
inc eax ; gadget 3
ret
int 0x80 ; gadget 4
</code></pre>
<p>为了完成指令序列的构建，首先要找到这些以ret指令为结尾，并且在执行时必然以ret结束而不会跳转到其他地方的gadget，算法如下：</p>
<pre><code class="lang-C">Algorithm GALILEO:
    create a node, root, representing the ret instruction; 
    place root in the trie; 
    for pos from 1 to textseg_len do:
        if the byte at pos is c3, i.e., a ret instruction, then:
            call BUILDFROM(pos, root).

Procedure BuILDFROM(index pos, instruction parent_insn):
    for step from 1 to max_insn_len do:
        if bytes [( pos-step )···(pos-1)] decode as a valid instruction insn then:
            ensure insn is in the trie as a child of parent_insn; 
            if insn isn't boring then:
                call BUILDFROM (pos-step,insn).
</code></pre>
<p>扫描二进制找到 ret（c3）指令，将其作为 trie 的根节点，然后回溯解析前面的指令，如果是有效指令，将其添加为子节点，再判断是否 boring；如果不是，就继续递归回溯。举个例子，在一个 trie 中一个表示 pop %eax 的节点是表示 ret 的根节点的子节点，则这个 gadget 为 pop %eax; ret。<br>如此就能把有用的 gadgets 都找出来了。boring 指令则分为三种情况：<br>（1）该指令是 leave，后跟一个 ret 指令；<br>（2）该指令是一个 pop %ebp，后跟一个 ret 指令；<br>（3）该指令是返回或者非条件跳转。<br>实际上，有很多工具可以帮助我们完成 gadget 搜索的工作，常用的有 ROPgadget、Ropper 等，还可以直接在 ropshell 网站上搜索。gadgets 在多个体系架构上都是图灵完备的，允许任意复杂度的计算，也就是说基本上只要能想到的事情它都可以做。下面简单介绍几种用法。<br>（1）保存栈数据到寄存器。弹出栈顶数据到寄存器中，然后跳转到新的栈顶地址。所以当返回<br>地址被一个 gadget 的地址覆盖，程序将在返回后执行该指令序列。例如：pop eax; ret；<br>（2）保存内存数据到寄存器。例如：mov ecx,[eax]; ret；<br>（3）保存寄存器数据到内存。例如：mov [eax],ecx; ret；<br>（4）算数和逻辑运算。add、sub、mul、xor 等。例如：add eax,ebx; ret, xor edx,edx; ret；<br>（5）系统调用。执行内核中断。例如：int 0x80; ret, call gs:[0x10]; ret；<br>（6）会影响栈帧的 gadget。这些 gadget 会改变 ebp 的值，从而影响栈帧，在一些操作如 stack<br>pivot 时我们需要这样的指令来转移栈帧。例如：leave; ret, pop ebp; ret。</p>
<h3 id="Analyse-ROP"><a href="#Analyse-ROP" class="headerlink" title="Analyse ROP"></a>Analyse ROP</h3><ol>
<li><p>【<code>ROP</code>攻击】 攻击者预先扫描并识别系统中可以利用的gadgets（包含<code>ret</code> 指令并可以跳转到指定地址的代码片段），利用缓冲区溢出，通过对堆栈段的控制，控制访问控制流程（新的流程复用正常的代码段），从而得到攻击者想要的信息，达到攻击的目的；</p>
</li>
<li><p>【可行性】<code>Xen</code> 代码段中确实存在很多可以用于<code>ROP</code>攻击的<code>gadgets</code>，[1] 这篇文章是第一个实现在虚拟化领域的<code>ROP</code>攻击，攻击结果是实现对非特权<code>VM</code>的权限提升；</p>
</li>
<li><p>【ROP不影响代码完整性】[2] 在相关工作中指出，使用<code>ROP</code>攻击的攻击模型，不会对<code>hypervisor</code>代码产生影响，因此，仅检测代码完整性的机制不会检测到该攻击；在文中introduction介绍，非特权级客户机，会控制<code>hypervisor</code>的 <code>ToolStack</code>，从而提升自己的权限并且控制其他的客户机；[3] 在文中也明确提出<code>ROP</code>攻击可以完美的旁路掉代码完整性检测。</p>
</li>
<li><p>综上，我看过的几篇文章中没有提到<code>ROP</code>攻击会对code integrity 产生影响的说明，并且，在<code>Outlier</code>中，对比Checker 是扫描的 <code>Hypervisor</code> 的代码区域，那么这个提到的ROP攻击就会避开我们的检测，所以从理论上来看<code>Outlier</code>确实不会检测到ROP的攻击；ROP在攻击的过程中，会在内存中留下痕迹，但是，应该是在堆、栈段留下痕迹，在代码段没有影响。</p>
</li>
</ol>
<h3 id="how-does-ROP-effect-the-OS"><a href="#how-does-ROP-effect-the-OS" class="headerlink" title="how does ROP effect the OS"></a>how does ROP effect the OS</h3><p>[6] 文中举的例子：</p>
<p>攻击者扫描已有的动态链接库和可执行文件，提取出可以利用的指令片段(gadget)，这些指令片段均以ret指令结尾，即用ret指令实现指令片段执行流的衔接。操作系统通过栈来进行函数的调用和返回。函数的调用和返回就是通过压栈和出栈来实现的。每个程序都会维护一个程序运行栈，栈为所有函数共享，每次函数调用，系统会分配一个栈桢给当前被调用函数，用于参数的传递、局部变量的维护、返回地址的填入等。栈帧是程序运行栈的一部分 ，在<a href="">Linux</a>中 ，通过%esp和 %ebp寄存器维护栈顶指针和栈帧的起始地址 ，%eip是<a href="">程序计数器</a>寄存器 。而ROP攻击则是利用以ret结尾的程序片段 ，操作这些栈相关寄存器，控制程序的流程，执行相应的gadget，实施攻击者预设目标 。ROP不同于retum-to-libc攻击之处在于，<strong>ROP攻击以ret指令结尾的函数代码片段</strong> ，而不是整个函数本身去完成预定的操作。从广义角度讲 ，return-to-libc攻击是ROP攻的特例。最初ROP攻击实现在x86体系结构下，随后扩展到各种体系结构.。与以往攻击技术不同的是，<strong>ROP恶意代码不包含任何指令</strong>，将自己的恶意代码隐藏在正常代码中。因而，它可以绕过W⊕X的防御技术。</p>
<p><img src="/2021/02/01/ROP-attacks/example.png" width="500"></p>
<h3 id="how-can-we-detect"><a href="#how-can-we-detect" class="headerlink" title="how can we detect"></a>how can we detect</h3><h3 id="how-could-it-apply-on-Xen"><a href="#how-could-it-apply-on-Xen" class="headerlink" title="how could it apply on Xen"></a>how could it apply on Xen</h3><h3 id="Xen-hypervisor-and-ROP"><a href="#Xen-hypervisor-and-ROP" class="headerlink" title="Xen hypervisor and ROP"></a>Xen hypervisor and ROP</h3><p>Control-flow Enforcement Technology (CET) is a set of features in hardware designed to combat Return-oriented Programming (ROP, also call/jump COP/¯JOP) attacks. Xen 4.14 can use these hardware features, if available, to protect itself from ROP attacks.[5]</p>
<h3 id="References"><a href="#References" class="headerlink" title="References"></a>References</h3><p>[1] Ding B, Wu Y, He Y, et al. Return-oriented programming attack on the xen hypervisor[C]//2012 Seventh International Conference on Availability, Reliability and Security. IEEE, 2012: 479-484.</p>
<p>[2] Saeed A, Hussain S A, Garraghan P. Cross-VM Network Channel Attacks and Countermeasures within Cloud Computing Environments[J]. IEEE Transactions on Dependable and Secure Computing, 2020.</p>
<p>[3] Jiang J, Jia X, Feng D, et al. HyperCrop: a hypervisor-based countermeasure for return oriented programming[C]//International Conference on Information and Communications Security. Springer, Berlin, Heidelberg, 2011: 360-373.</p>
<p>[4] <a href="https://www.youtube.com/watch?v=n-_QkDek6jY" target="_blank" rel="noopener">https://www.youtube.com/watch?v=n-_QkDek6jY</a> </p>
<p>[5] <a href="https://wiki.xenproject.org/wiki/Xen_Project_4.14_Feature_List" target="_blank" rel="noopener">https://wiki.xenproject.org/wiki/Xen_Project_4.14_Feature_List</a></p>
<p>[6] Zhang J, Hou R, Song W, et al. RAGuard: An Efficient and User-Transparent Hardware Mechanism against ROP Attacks[J]. ACM Transactions on Architecture and Code Optimization (TACO), 2018, 15(4): 1-21.</p>
]]></content>
      <tags>
        <tag>attacks</tag>
        <tag>ROP</tag>
      </tags>
  </entry>
  <entry>
    <title>Protocol-gossip</title>
    <url>/2020/11/07/Protocol-gossip/</url>
    <content><![CDATA[<h3 id="P2P-简介"><a href="#P2P-简介" class="headerlink" title="P2P 简介"></a>P2P 简介</h3><p>​        网络中节点数目的增加，使得传统的C/S计算模型不能满足用户对信息访问等要求，无法满足分布式应用的要求，其限制了网络资源的充分利用，可扩展性较差，无法支持不断增长的客户节点数量等问题越来越明显。</p>
<p>​        P2P 主要解决网络负载不均衡的问题，用户有能力不通过服务器直接进行资源的的共享和交换。Napster是第一个被广泛应用的 Peer-to-Peer 音乐共享服务。</p>
<h4 id="Peer-to-Peerr-分类"><a href="#Peer-to-Peerr-分类" class="headerlink" title="Peer-to-Peerr 分类"></a>Peer-to-Peerr 分类</h4><p>集中式P2P系统</p>
<p>无结构P2P系统</p>
<p>结构化P2P系统</p>
<h3 id="分布式文件定位"><a href="#分布式文件定位" class="headerlink" title="分布式文件定位"></a>分布式文件定位</h3><h4 id="Useful-links"><a href="#Useful-links" class="headerlink" title="Useful links"></a>Useful links</h4><p><a href="https://www.cnblogs.com/zhufanyu/p/12101112.html" target="_blank" rel="noopener">RPC 远程调用</a></p>
<p><a href="https://www.cnblogs.com/gzhcsu/p/11389235.html" target="_blank" rel="noopener">RPC </a></p>
<p><a href="https://blog.csdn.net/daaikuaichuan/article/details/88595202?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.compare&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.compare" target="_blank" rel="noopener">详解RPC </a></p>
<p><a href="https://wiki.p2pfoundation.net/P2P_Computing" target="_blank" rel="noopener">https://wiki.p2pfoundation.net/P2P_Computing</a></p>
]]></content>
      <tags>
        <tag>TODO</tag>
      </tags>
  </entry>
  <entry>
    <title>SOSP-Progress</title>
    <url>/2021/02/18/SOSP-Progress/</url>
    <content><![CDATA[]]></content>
      <tags>
        <tag>TODO</tag>
      </tags>
  </entry>
  <entry>
    <title>RPC go</title>
    <url>/2020/12/03/RPC-go/</url>
    <content><![CDATA[<h3 id="单向单次通讯"><a href="#单向单次通讯" class="headerlink" title="单向单次通讯"></a>单向单次通讯</h3><p>注，Go语言中谨记：</p>
<blockquote>
<p>使用go时，以大写字母开头的字段和变量将被“导出”，并且对其他包可见。 以小写字母开头的字段是“<strong>未导出”</strong>（type main.CheckRemote <strong>has no exported fields</strong>）的，并且仅在其自己的包中可见。encoding / gob包依赖于反射来编码值，并且只能看到导出的struct字段。为了使事情变得可编码，请在stateNode结构中将要保存的每个字段名称的<strong>首字母大写</strong>。</p>
</blockquote>
<h4 id="构造通讯类型"><a href="#构造通讯类型" class="headerlink" title="构造通讯类型"></a>构造通讯类型</h4><pre><code class="lang-go">type sample struct {}

func (p *sample) Echo (request string, reply * string) error {
    *reply = "hello:" + request
    return nil
}
</code></pre>
<p>在<code>Echo</code>方法中，第一个可以看做是输入值，第二个指针类型值看作是返回值，函数真正的返回值是<code>error</code></p>
<h4 id="RPC-服务注册"><a href="#RPC-服务注册" class="headerlink" title="RPC 服务注册"></a>RPC 服务注册</h4><p>在构造了通讯类型之后，可以将 <code>sample</code>类型的对象注册为一个<code>RPC</code>服务：</p>
<pre><code class="lang-go">func main()  {
    rpc.RegisterName("sample", new(sample))

    listener, err := net.Listen("tcp", ":10088")
    if err != nil {
        log.Fatal("ListenTCP  error:", err)
    }

    connect, err := listener.Accept() 
    if err != nil {
        log.Fatal("Accept error:", err)
    }

    rpc.ServeConn(connect)
}
</code></pre>
<p>​        其中<code>rpc.Register</code>函数调用会将对象类型中所有满足<code>RPC</code>规则的对象方法注册为<code>RPC</code>函数，所有注册的方法会放在<code>sample</code>服务空间之下。go在创建网络服务器时需要用到<code>net.Listen</code>生成一个监听器，使用<code>Accept()</code>阻塞处理连接到服务器的请求。然后建立一个唯一的<code>TCP</code>链接，并且通过<code>rpc.ServeConn</code>函数在该TCP链接上为对方提供<code>RPC</code>服务。</p>
<h4 id="Client-端"><a href="#Client-端" class="headerlink" title="Client 端"></a>Client 端</h4><pre><code class="lang-go">func main()  {

    client, err := rpc.Dial("tcp", "localhost:10088")
    if err != nil {
        log.Fatal("dailing:", err)
    }

    var reply string
    err = client.Call("sample.Echo","This is client", &amp;reply)
    if err != nil {
        log.Fatal(err)
    }

    fmt.Println(reply)                                         
}
</code></pre>
<p>​        首先通过<code>rpc.Dial</code>拨号<code>RPC</code>服务，然后通过<code>client.Call</code>调用具体的<code>RPC</code>方法。在调用<code>client.Call</code>时，第一个参数是用点号链接的RPC服务名字和方法名字，第二和第三个参数分别是<code>RPC</code>方法定义的两个参数。</p>
<h3 id="单向多次通信"><a href="#单向多次通信" class="headerlink" title="单向多次通信"></a>单向多次通信</h3><p><strong>Server端处理</strong></p>
<pre><code class="lang-go">func main()  {
    rpc.RegisterName("sample", new(sample))
    fmt.Println("register!")

    go func ()  {
        listener, err := net.Listen("tcp", "0.0.0.0:10088")
        if err != nil {
            log.Fatal("ListenTCP  error:", err)
        }

        for true {
            connect, err := listener.Accept()
            go func ()  {
                if err != nil {
                    log.Fatal("Accept error:", err)
                }
                rpc.ServeConn(connect) // 对请求执行操作
                fmt.Println("q.message : ", q.message)
            }()
        }
    }()
        for true{  // 为了防止主线程退出造成的子线程的中断      
        }
}
</code></pre>
<p>理解：</p>
<p>​        在服务端需要进行的操作为 1. 注册， 2. 创建监听器， 3. 阻塞监听， 4. 处理访问请求</p>
<p>​        其中 2,3 为基础创建步骤，4为执行步骤，第四步同时可能会有多个请求发送，因此要与之前的操作分离开，单独创建子线程。</p>
<p><strong>client端</strong></p>
<pre><code class="lang-go">func main()  {

    client, err := rpc.Dial("tcp", "localhost:10088")
    if err != nil {
        log.Fatal("dailing:", err)
    }

    var reply string
    var inputReader string 

    for true {
        fmt.Scanln(&amp;inputReader)
        err = client.Call("sample.Echo",inputReader, &amp;reply)
        if err != nil {
            log.Fatal(err)
        }

        fmt.Println(reply) 
    }

}
</code></pre>
<p>理解：</p>
<p>​        在client端进行的操作主要是 <code>dial</code> 和 <code>call</code> 操作，拨号操作仅进行一次即可，而发送消息可能要进行多次，因此，要实现多次数据传输操作，要在数据操作时进行循环操作。</p>
<h3 id="双向通讯"><a href="#双向通讯" class="headerlink" title="双向通讯"></a>双向通讯</h3><p>注： 这仅仅是一个<code>sample</code> 程序，一般框架，如果要进行更复杂的操作，需要大量改进。</p>
<pre><code class="lang-go">package main

import (
    "net"
    "fmt"
    "net/rpc"
    "log"
    "time"
)

type sample struct {}

func (p *sample) Echo (request string, reply * string) error {
    *reply = "hello:" + request
    return nil
}

func main()  {
    rpc.RegisterName("sample", new(sample))

    go func() {
        listener, err := net.Listen("tcp", "0.0.0.0:10082")
        if err != nil {
            log.Fatal("ListenTCP  error:", err)
        }

        for true {
            connect, err := listener.Accept()
            go func() {
                if err != nil {
                    log.Fatal("Accept error:", err)
                }
                rpc.ServeConn(connect)
            }()
        }
    }()

    time.Sleep(time.Duration(3) * time.Second)

    client, err := rpc.Dial("tcp", "localhost:10081")
    if err != nil {
        log.Fatal("dailing:", err)
    }
    var reply string
    var inputReader string 

    for true {
        fmt.Scanln(&amp;inputReader)
        err = client.Call("sample.Echo",inputReader, &amp;reply)
        if err != nil {
            log.Fatal(err)
        }
        fmt.Println(reply)
    }
}
</code></pre>
<p><strong>TODO：</strong></p>
<blockquote>
<p>1.在双向发送数据请求时，在terminal 输入指令进行传输；</p>
<p>2.取消 sleep 的操作，实现运行时不中断。</p>
</blockquote>
<h3 id="References"><a href="#References" class="headerlink" title="References"></a>References</h3><p>[1] <a href="https://chai2010.cn/advanced-go-programming-book/ch4-rpc/ch4-01-rpc-intro.html" target="_blank" rel="noopener">https://chai2010.cn/advanced-go-programming-book/ch4-rpc/ch4-01-rpc-intro.html</a></p>
<p>[2] <a href="https://learnku.com/docs/build-web-application-with-golang/084-rpc/3206" target="_blank" rel="noopener">https://learnku.com/docs/build-web-application-with-golang/084-rpc/3206</a></p>
<p>[3] <a href="https://smallnest.gitbooks.io/go-rpc-programming-guide/content/part1/client.html" target="_blank" rel="noopener">https://smallnest.gitbooks.io/go-rpc-programming-guide/content/part1/client.html</a></p>
]]></content>
      <tags>
        <tag>go</tag>
        <tag>RPC</tag>
      </tags>
  </entry>
  <entry>
    <title>PUBG JNG</title>
    <url>/2020/04/18/PUBG-JNG/</url>
    <content><![CDATA[<h3 id="JNG战队发展历程回顾"><a href="#JNG战队发展历程回顾" class="headerlink" title="JNG战队发展历程回顾"></a>JNG战队发展历程回顾</h3><h4 id="JNG初次相遇"><a href="#JNG初次相遇" class="headerlink" title="JNG初次相遇"></a>JNG初次相遇</h4><p>很久很久以前，这支战队的几个骚年游荡在这样一个空旷的平原上</p>
<p><img src="/2020/04/18/PUBG-JNG/1.jpg" alt="IMG_0814"></p>
<p>这个寒假的某一天，他们在飞机上相遇，并开启了他们相识到并肩作战的征程</p>
<p><img src="/2020/04/18/PUBG-JNG/2.jpg" alt="IMG_0815"></p>
<h4 id="睡衣战队红极一时"><a href="#睡衣战队红极一时" class="headerlink" title="睡衣战队红极一时"></a>睡衣战队红极一时</h4><p>在他们相遇不久，便迎来了队伍的第一次胜利</p>
<p><img src="/2020/04/18/PUBG-JNG/3.jpg" alt="IMG_0823"></p>
<p>当时他们采取的是著名的车轮战，即3辆装甲车并驾齐驱，纵横四海的战术</p>
<p><img src="/2020/04/18/PUBG-JNG/4.jpg" alt="IMG_0822"></p>
<h4 id="各种模式吃鸡常态化"><a href="#各种模式吃鸡常态化" class="headerlink" title="各种模式吃鸡常态化"></a>各种模式吃鸡常态化</h4><p>在经历了短短几天的磨合后，这几个小伙子已经将吃鸡常态化</p>
<p>普通模式</p>
<p><img src="/2020/04/18/PUBG-JNG/5.jpg" alt="IMG_0863"></p>
<p><img src="/2020/04/18/PUBG-JNG/20.jpg" alt=""></p>
<p>特种兵模式</p>
<p><img src="/2020/04/18/PUBG-JNG/6.jpg" alt="IMG_0833"></p>
<p>一日两鸡已是正常</p>
<p><img src="/2020/04/18/PUBG-JNG/7.jpg" alt="IMG_0838"></p>
<p><img src="/2020/04/18/PUBG-JNG/8.jpg" alt="IMG_0852"></p>
<h4 id="雪地扔雷，对手一片哀嚎"><a href="#雪地扔雷，对手一片哀嚎" class="headerlink" title="雪地扔雷，对手一片哀嚎"></a>雪地扔雷，对手一片哀嚎</h4><p><img src="/2020/04/18/PUBG-JNG/9.jpg" alt="IMG_0858"></p>
<p><img src="/2020/04/18/PUBG-JNG/10.jpg" alt="IMG_0869"></p>
<p><img src="/2020/04/18/PUBG-JNG/11.jpg" alt="IMG_0871"></p>
<p><img src="/2020/04/18/PUBG-JNG/12.jpg" alt="IMG_0903"></p>
<h4 id="最后一次征战雪地"><a href="#最后一次征战雪地" class="headerlink" title="最后一次征战雪地"></a>最后一次征战雪地</h4><p>在一次极寒模式对决中，几个小伙子竟然连锅端掉了一个满编RMB玩家。在这之后，光子工作室终于对他们下手了，出于人道主义，并不能直接限制玩家们参与游戏，于是乎，默默地移除了他们最擅长的极寒模式，他们再也不用落地寻找暖宝宝了，再也听不到系统提示：“暴风雪还有60秒到达，打开背包，利用打火机生火取暖”。但系统为了其余玩家的游戏体验，只能如此。</p>
<p><img src="/2020/04/18/PUBG-JNG/13.jpg" alt="IMG_0909"></p>
<h4 id="插曲"><a href="#插曲" class="headerlink" title="插曲"></a>插曲</h4><p>性感小wei在线比心</p>
<p><img src="/2020/04/18/PUBG-JNG/14.jpg" alt="IMG_0834"></p>
<h3 id="JNG-建队"><a href="#JNG-建队" class="headerlink" title="JNG 建队"></a>JNG 建队</h3><p>终于，在2020年4月17日，这支战队正式成立了</p>
<p><img src="/2020/04/18/PUBG-JNG/15.jpg" alt="IMG_0855"></p>
<p>属于JNG（Jining Gaming）的时刻已经来临</p>
<p><img src="/2020/04/18/PUBG-JNG/16.jpg" alt=""></p>
<p>今晚，请锁定和平精英，关注这支战队！</p>
<p><img src="/2020/04/18/PUBG-JNG/21.jpg" alt=""></p>
<p>建队首鸡</p>
<p><img src="/2020/04/18/PUBG-JNG/18.jpg" alt=""></p>
<p><img src="/2020/04/18/PUBG-JNG/19.jpg" alt=""></p>
<p>一支穿云箭，千军万马来相见</p>
<p><img src="/2020/04/18/PUBG-JNG/22.jpg" alt=""></p>
<p>雪地彩蛋</p>
<p><img src="/2020/04/18/PUBG-JNG/23.jpg" alt=""></p>
]]></content>
      <tags>
        <tag>game-for-peace</tag>
        <tag>JNG</tag>
      </tags>
  </entry>
  <entry>
    <title>SecVisor</title>
    <url>/2020/07/21/SecVisor/</url>
    <content><![CDATA[<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">序号</th>
<th style="text-align:center">属性</th>
<th style="text-align:center">内容</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">原文PDF</td>
<td style="text-align:center"><a href="http://www.cs.cmu.edu/~arvinds/pubs/secvisor.pdf" target="_blank" rel="noopener">SecVisor</a></td>
</tr>
<tr>
<td style="text-align:center">2</td>
<td style="text-align:center">作者信息</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">3</td>
<td style="text-align:center">核心内容</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">4</td>
<td style="text-align:center">研究领域</td>
<td style="text-align:center">检测</td>
</tr>
<tr>
<td style="text-align:center">5</td>
<td style="text-align:center">全文总览</td>
<td style="text-align:center"></td>
</tr>
</tbody>
</table>
</div>
]]></content>
      <categories>
        <category>SOSP</category>
      </categories>
      <tags>
        <tag>TODO</tag>
        <tag>论文解读</tag>
        <tag>Detection</tag>
      </tags>
  </entry>
  <entry>
    <title>Read Data from LOL Client</title>
    <url>/2021/05/31/Read-Data-from-LOL-Client/</url>
    <content><![CDATA[<h2 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h2><p>读取联盟客户端英雄数据</p>
<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><p>[1] <a href="https://nickcano.com/reversing-league-of-legends-client/" target="_blank" rel="noopener">https://nickcano.com/reversing-league-of-legends-client/</a></p>
<p>[2] <a href="http://www.rohitab.com/apimonitor" target="_blank" rel="noopener">http://www.rohitab.com/apimonitor</a></p>
<p>[3] <a href="https://github.com/nickcano/LibCEF-API-Monitor-Definitions" target="_blank" rel="noopener">https://github.com/nickcano/LibCEF-API-Monitor-Definitions</a></p>
<p>[4] <a href="https://riot-api-libraries.readthedocs.io/en/latest/" target="_blank" rel="noopener">https://riot-api-libraries.readthedocs.io/en/latest/</a></p>
]]></content>
      <tags>
        <tag>TODO</tag>
        <tag>windows 数据读取</tag>
      </tags>
  </entry>
  <entry>
    <title>Software ROT</title>
    <url>/2020/12/02/Software-ROT/</url>
    <content><![CDATA[<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">序号</th>
<th style="text-align:center">属性</th>
<th style="text-align:center">内容</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">原文PDF</td>
<td style="text-align:center"><a href="https://www.cylab.cmu.edu/_files/pdfs/tech_reports/CMUCyLab18003.pdf" target="_blank" rel="noopener">Software ROT</a></td>
</tr>
<tr>
<td style="text-align:center">2</td>
<td style="text-align:center">作者信息</td>
<td style="text-align:center">CMU/CyLab</td>
</tr>
<tr>
<td style="text-align:center">3</td>
<td style="text-align:center">核心内容</td>
<td style="text-align:center">Pioneer 工作的延续</td>
</tr>
<tr>
<td style="text-align:center">4</td>
<td style="text-align:center">研究领域</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">5</td>
<td style="text-align:center">全文总览</td>
</tr>
</tbody>
</table>
</div>
]]></content>
      <categories>
        <category>NDSS</category>
      </categories>
      <tags>
        <tag>TODO</tag>
        <tag>论文解读</tag>
      </tags>
  </entry>
  <entry>
    <title>TPM overview</title>
    <url>/2020/11/07/TPM-overview/</url>
    <content><![CDATA[<h3 id="TPM"><a href="#TPM" class="headerlink" title="TPM"></a>TPM</h3><p>[1]  中不止包括TPM还有TOCTOU攻击讲解</p>
<h3 id="References"><a href="#References" class="headerlink" title="References"></a>References</h3><p>[1] 基于Xen的可信虚拟机系统体系结构设计与若干关键技术研究_孟璟 (TPM1.2)</p>
<p>[2]   </p>
]]></content>
      <tags>
        <tag>TODO</tag>
        <tag>Technology Overview</tag>
      </tags>
  </entry>
  <entry>
    <title>Systematic Review on FHE</title>
    <url>/2020/08/12/Systematic-Review-on-FHE/</url>
    <content><![CDATA[]]></content>
      <tags>
        <tag>TODO</tag>
      </tags>
  </entry>
  <entry>
    <title>The first blog</title>
    <url>/2020/04/18/The-first-blog/</url>
    <content><![CDATA[<h3 id="The-first-bolg"><a href="#The-first-bolg" class="headerlink" title="The first bolg"></a>The first bolg</h3><p>Hello，this is my first bolg of github.io.</p>
<p>I tried for about 12 hours to set up this simple website, right now, the author(me) still feel awsome.</p>
<p>I have written some technology blogs in <a href="https://www.cnblogs.com/Robin5/" target="_blank" rel="noopener">Robin5</a>.</p>
<p>Seize the time and face the bright future！</p>
<p>I will work harder and harder!</p>
<p>Witness me in github.io</p>
]]></content>
      <tags>
        <tag>essay</tag>
        <tag>英文</tag>
      </tags>
  </entry>
  <entry>
    <title>SP&#39;15 Last-Level Cache Side-Channel Attacks are Practical</title>
    <url>/2020/05/18/SP-15-Last-Level-Cache-Side-Channel-Attacks-are-Practical/</url>
    <content><![CDATA[<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">序号</th>
<th style="text-align:center">属性</th>
<th style="text-align:center">内容</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">原文PDF</td>
<td style="text-align:center"><a href="/files/docs/CSCA-004-SP2015.pdf">Last Level Cache Side Channel Attacks are Practical</a></td>
</tr>
<tr>
<td style="text-align:center">2</td>
<td style="text-align:center">作者信息</td>
<td style="text-align:center">Department of Electrical Engineering, Princeton University</td>
</tr>
<tr>
<td style="text-align:center">3</td>
<td style="text-align:center">核心内容</td>
<td style="text-align:center">side channel attacks</td>
</tr>
<tr>
<td style="text-align:center">4</td>
<td style="text-align:center">研究领域</td>
<td style="text-align:center">security cross VM</td>
</tr>
<tr>
<td style="text-align:center">5</td>
<td style="text-align:center">全文总览</td>
<td style="text-align:center">本文详细地讲解了跨虚拟机的侧信道攻击</td>
</tr>
</tbody>
</table>
</div>
]]></content>
      <categories>
        <category>Security and Privacy</category>
      </categories>
      <tags>
        <tag>TODO</tag>
        <tag>论文解读</tag>
        <tag>side channel attack</tag>
        <tag>cross VM</tag>
        <tag>last level cache</tag>
      </tags>
  </entry>
  <entry>
    <title>SystemInfo</title>
    <url>/2021/07/10/SystemInfo/</url>
    <content><![CDATA[<h2 id="Linux-实时显示资源利用率"><a href="#Linux-实时显示资源利用率" class="headerlink" title="Linux 实时显示资源利用率"></a>Linux 实时显示资源利用率</h2><ol>
<li><p>添加indicator-sysmonitor的下载源</p>
<pre><code class="lang-bash"> sudo add-apt-repository ppa:fossfreedom/indicator-sysmonitor
</code></pre>
</li>
<li><p>更新 <code>sudo apt-get update</code></p>
</li>
<li><p>安装<code>indicator-sysmonitor</code></p>
<pre><code class="lang-bash">sudo apt-get install indicator-sysmonitor
</code></pre>
</li>
<li><p>启动</p>
<pre><code class="lang-bash">indicator-sysmonitor &amp;
</code></pre>
</li>
</ol>
<h2 id="Python-读取实时系统信息-精简版"><a href="#Python-读取实时系统信息-精简版" class="headerlink" title="Python 读取实时系统信息-精简版"></a>Python 读取实时系统信息-精简版</h2><h3 id="一、-安装psutil"><a href="#一、-安装psutil" class="headerlink" title="一、 安装psutil"></a>一、 安装psutil</h3><pre><code class="lang-bash">　　pip install psutil
</code></pre>
<p> 二、 监控cpu信息</p>
<pre><code class="lang-python">import psutil
psutil.cpu_times()   #获取cpu（逻辑cpu的平均）占用时间的详细信息 
psutil.cpu_times(percpu=True)   #获取每个cpu占用时间的详细信息
psutil.cpt_times().user   #获取用户进程占用cpu的时间（user+sys+idle+wait=total）
</code></pre>
<p>三、 监控内存信息</p>
<pre><code class="lang-python"> import psutil
 psutil.virtual_memory()   #获取内存信息
 psutil.virtual_memory().total   #获取内存总量
 psutil.swap_memory()   #获取swap信息
 psutil.swqp_memory()   #获取swap总量
</code></pre>
<p>四、 监控磁盘信息</p>
<pre><code class="lang-python"> import psutil
 psutil.disk_partitions()   #获取各分区的信息
 psutil.disk_usage()   #获取各分区的使用情况
 psutil.disk_io_counters(perdisk=True)   #获取各个分区的io情况
 psutil.disk_io_counters(perdisk=True)['sda1'].read_count   #获取sda1的io读取情况
</code></pre>
<p>五、 监控网络信息</p>
<pre><code class="lang-python"> import psutil
 psutil.net_io_counters()   #获取所有网络接口io信息
 psutil.net_io_counters(pernic=True)   #获取每个网络接口的io信息
</code></pre>
<p>六、进程信息</p>
<pre><code class="lang-python">import psutil
psutil.Process(pid)   #查看对应pid的进程信息
 psutil.Process(pid).username()   #查看是哪个用户创建的该进程
 psutil.Process(pid).cmdline()   #查看进程所在的路径
</code></pre>
<p>七、 登录用户信息</p>
<pre><code class="lang-python"> import psutil
 psutil.users()   #查看目前登录用户信息
</code></pre>
<h2 id="Python-读取实时系统信息-实例版"><a href="#Python-读取实时系统信息-实例版" class="headerlink" title="Python 读取实时系统信息-实例版"></a>Python 读取实时系统信息-实例版</h2><p>[2] Python中获取系统信息的另一个好办法是使用<code>psutil</code>这个第三方模块。顾名思义，psutil = process and system utilities.</p>
<p><strong>安装psutil</strong></p>
<pre><code class="lang-bash">$ pip install psutil
</code></pre>
<h3 id="获取CPU信息"><a href="#获取CPU信息" class="headerlink" title="获取CPU信息"></a>获取CPU信息</h3><pre><code>&gt;&gt;&gt; import psutil
&gt;&gt;&gt; psutil.cpu_count() # CPU逻辑数量
4
&gt;&gt;&gt; psutil.cpu_count(logical=False) # CPU物理核心
2
# 2说明是双核超线程, 4则是4核非超线程
</code></pre><p>统计CPU的用户／系统／空闲时间：</p>
<pre><code>&gt;&gt;&gt; psutil.cpu_times()
scputimes(user=10963.31, nice=0.0, system=5138.67, idle=356102.45)
</code></pre><p>实现类似<code>top</code>命令的CPU使用率，每秒刷新一次，累计10次：</p>
<pre><code>&gt;&gt;&gt; for x in range(10):
...     print(psutil.cpu_percent(interval=1, percpu=True))
... 
[14.0, 4.0, 4.0, 4.0]
[12.0, 3.0, 4.0, 3.0]
[8.0, 4.0, 3.0, 4.0]
[12.0, 3.0, 3.0, 3.0]
[18.8, 5.1, 5.9, 5.0]
[10.9, 5.0, 4.0, 3.0]
[12.0, 5.0, 4.0, 5.0]
[15.0, 5.0, 4.0, 4.0]
[19.0, 5.0, 5.0, 4.0]
[9.0, 3.0, 2.0, 3.0]
</code></pre><h3 id="获取内存信息"><a href="#获取内存信息" class="headerlink" title="获取内存信息"></a>获取内存信息</h3><p>使用psutil获取物理内存和交换内存信息，分别使用：</p>
<pre><code>&gt;&gt;&gt; psutil.virtual_memory()
svmem(total=8589934592, available=2866520064, percent=66.6, used=7201386496, free=216178688, active=3342192640, inactive=2650341376, wired=1208852480)
&gt;&gt;&gt; psutil.swap_memory()
sswap(total=1073741824, used=150732800, free=923009024, percent=14.0, sin=10705981440, sout=40353792)
</code></pre><p>返回的是字节为单位的整数，可以看到，总内存大小是8589934592 = 8 GB，已用7201386496 = 6.7 GB，使用了66.6%。</p>
<p>而交换区大小是1073741824 = 1 GB。</p>
<h3 id="获取磁盘信息"><a href="#获取磁盘信息" class="headerlink" title="获取磁盘信息"></a>获取磁盘信息</h3><p>可以通过psutil获取磁盘分区、磁盘使用率和磁盘IO信息：</p>
<pre><code>&gt;&gt;&gt; psutil.disk_partitions() # 磁盘分区信息
[sdiskpart(device='/dev/disk1', mountpoint='/', fstype='hfs', opts='rw,local,rootfs,dovolfs,journaled,multilabel')]
&gt;&gt;&gt; psutil.disk_usage('/') # 磁盘使用情况
sdiskusage(total=998982549504, used=390880133120, free=607840272384, percent=39.1)
&gt;&gt;&gt; psutil.disk_io_counters() # 磁盘IO
sdiskio(read_count=988513, write_count=274457, read_bytes=14856830464, write_bytes=17509420032, read_time=2228966, write_time=1618405)
</code></pre><p>可以看到，磁盘<code>'/'</code>的总容量是998982549504 = 930 GB，使用了39.1%。文件格式是HFS，<code>opts</code>中包含<code>rw</code>表示可读写，<code>journaled</code>表示支持日志。</p>
<h3 id="获取网络信息"><a href="#获取网络信息" class="headerlink" title="获取网络信息"></a>获取网络信息</h3><p>psutil可以获取网络接口和网络连接信息：</p>
<pre><code>&gt;&gt;&gt; psutil.net_io_counters() # 获取网络读写字节／包的个数
snetio(bytes_sent=3885744870, bytes_recv=10357676702, packets_sent=10613069, packets_recv=10423357, errin=0, errout=0, dropin=0, dropout=0)
&gt;&gt;&gt; psutil.net_if_addrs() # 获取网络接口信息
{
  'lo0': [snic(family=&lt;AddressFamily.AF_INET: 2&gt;, address='127.0.0.1', netmask='255.0.0.0'), ...],
  'en1': [snic(family=&lt;AddressFamily.AF_INET: 2&gt;, address='10.0.1.80', netmask='255.255.255.0'), ...],
  'en0': [...],
  'en2': [...],
  'bridge0': [...]
}
&gt;&gt;&gt; psutil.net_if_stats() # 获取网络接口状态
{
  'lo0': snicstats(isup=True, duplex=&lt;NicDuplex.NIC_DUPLEX_UNKNOWN: 0&gt;, speed=0, mtu=16384),
  'en0': snicstats(isup=True, duplex=&lt;NicDuplex.NIC_DUPLEX_UNKNOWN: 0&gt;, speed=0, mtu=1500),
  'en1': snicstats(...),
  'en2': snicstats(...),
  'bridge0': snicstats(...)
}
</code></pre><p>要获取当前网络连接信息，使用<code>net_connections()</code>：</p>
<pre><code>&gt;&gt;&gt; psutil.net_connections()
Traceback (most recent call last):
  ...
PermissionError: [Errno 1] Operation not permitted

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  ...
psutil.AccessDenied: psutil.AccessDenied (pid=3847)
</code></pre><p>你可能会得到一个<code>AccessDenied</code>错误，原因是psutil获取信息也是要走系统接口，而获取网络连接信息需要root权限，这种情况下，可以退出Python交互环境，用<code>sudo</code>重新启动：</p>
<pre><code class="lang-bash">$ sudo python3
Password: ******
Python 3.8 ... on darwin
Type "help", ... for more information.
&gt;&gt;&gt; import psutil
&gt;&gt;&gt; psutil.net_connections()
[
    sconn(fd=83, family=&lt;AddressFamily.AF_INET6: 30&gt;, type=1, laddr=addr(ip='::127.0.0.1', port=62911), raddr=addr(ip='::127.0.0.1', port=3306), status='ESTABLISHED', pid=3725),
    sconn(fd=84, family=&lt;AddressFamily.AF_INET6: 30&gt;, type=1, laddr=addr(ip='::127.0.0.1', port=62905), raddr=addr(ip='::127.0.0.1', port=3306), status='ESTABLISHED', pid=3725),
    sconn(fd=93, family=&lt;AddressFamily.AF_INET6: 30&gt;, type=1, laddr=addr(ip='::', port=8080), raddr=(), status='LISTEN', pid=3725),
    sconn(fd=103, family=&lt;AddressFamily.AF_INET6: 30&gt;, type=1, laddr=addr(ip='::127.0.0.1', port=62918), raddr=addr(ip='::127.0.0.1', port=3306), status='ESTABLISHED', pid=3725),
    sconn(fd=105, family=&lt;AddressFamily.AF_INET6: 30&gt;, type=1, ..., pid=3725),
    sconn(fd=106, family=&lt;AddressFamily.AF_INET6: 30&gt;, type=1, ..., pid=3725),
    sconn(fd=107, family=&lt;AddressFamily.AF_INET6: 30&gt;, type=1, ..., pid=3725),
    ...
    sconn(fd=27, family=&lt;AddressFamily.AF_INET: 2&gt;, type=2, ..., pid=1)
]
</code></pre>
<h3 id="获取进程信息"><a href="#获取进程信息" class="headerlink" title="获取进程信息"></a>获取进程信息</h3><p>通过psutil可以获取到所有进程的详细信息：</p>
<pre><code class="lang-bash">&gt;&gt;&gt; psutil.pids() # 所有进程ID
[3865, 3864, 3863, 3856, 3855, 3853, 3776, ..., 45, 44, 1, 0]
&gt;&gt;&gt; p = psutil.Process(3776) # 获取指定进程ID=3776，其实就是当前Python交互环境
&gt;&gt;&gt; p.name() # 进程名称
'python3.6'
&gt;&gt;&gt; p.exe() # 进程exe路径
'/Users/michael/anaconda3/bin/python3.6'
&gt;&gt;&gt; p.cwd() # 进程工作目录
'/Users/michael'
&gt;&gt;&gt; p.cmdline() # 进程启动的命令行
['python3']
&gt;&gt;&gt; p.ppid() # 父进程ID
3765
&gt;&gt;&gt; p.parent() # 父进程
&lt;psutil.Process(pid=3765, name='bash') at 4503144040&gt;
&gt;&gt;&gt; p.children() # 子进程列表
[]
&gt;&gt;&gt; p.status() # 进程状态
'running'
&gt;&gt;&gt; p.username() # 进程用户名
'michael'
&gt;&gt;&gt; p.create_time() # 进程创建时间
1511052731.120333
&gt;&gt;&gt; p.terminal() # 进程终端
'/dev/ttys002'
&gt;&gt;&gt; p.cpu_times() # 进程使用的CPU时间
pcputimes(user=0.081150144, system=0.053269812, children_user=0.0, children_system=0.0)
&gt;&gt;&gt; p.memory_info() # 进程使用的内存
pmem(rss=8310784, vms=2481725440, pfaults=3207, pageins=18)
&gt;&gt;&gt; p.open_files() # 进程打开的文件
[]
&gt;&gt;&gt; p.connections() # 进程相关网络连接
[]
&gt;&gt;&gt; p.num_threads() # 进程的线程数量
1
&gt;&gt;&gt; p.threads() # 所有线程信息
[pthread(id=1, user_time=0.090318, system_time=0.062736)]
&gt;&gt;&gt; p.environ() # 进程环境变量
{'SHELL': '/bin/bash', 'PATH': '/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:...', 'PWD': '/Users/michael', 'LANG': 'zh_CN.UTF-8', ...}
&gt;&gt;&gt; p.terminate() # 结束进程
Terminated: 15 &lt;-- 自己把自己结束了
</code></pre>
<p>和获取网络连接类似，获取一个root用户的进程需要root权限，启动Python交互环境或者<code>.py</code>文件时，需要<code>sudo</code>权限。</p>
<p>psutil还提供了一个<code>test()</code>函数，可以模拟出<code>ps</code>命令的效果：</p>
<pre><code class="lang-bash">$ sudo python3
Password: ******
Python 3.6.3 ... on darwin
Type "help", ... for more information.
&gt;&gt;&gt; import psutil
&gt;&gt;&gt; psutil.test()
USER         PID %MEM     VSZ     RSS TTY           START    TIME  COMMAND
root           0 24.0 74270628 2016380 ?             Nov18   40:51  kernel_task
root           1  0.1 2494140    9484 ?             Nov18   01:39  launchd
root          44  0.4 2519872   36404 ?             Nov18   02:02  UserEventAgent
root          45    ? 2474032    1516 ?             Nov18   00:14  syslogd
root          47  0.1 2504768    8912 ?             Nov18   00:03  kextd
root          48  0.1 2505544    4720 ?             Nov18   00:19  fseventsd
_appleeven    52  0.1 2499748    5024 ?             Nov18   00:00  appleeventsd
root          53  0.1 2500592    6132 ?             Nov18   00:02  configd
...
</code></pre>
<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><p>[1] <a href="https://www.cnblogs.com/hjw1/p/7901048.html" target="_blank" rel="noopener">https://www.cnblogs.com/hjw1/p/7901048.html</a></p>
<p>[2] <a href="https://www.liaoxuefeng.com/wiki/1016959663602400/1183565811281984" target="_blank" rel="noopener">https://www.liaoxuefeng.com/wiki/1016959663602400/1183565811281984</a></p>
<p>[3] <a href="https://stackoverflow.com/questions/62020140/psutil-network-monitoring-script" target="_blank" rel="noopener">https://stackoverflow.com/questions/62020140/psutil-network-monitoring-script</a></p>
]]></content>
      <tags>
        <tag>sysinfo</tag>
      </tags>
  </entry>
  <entry>
    <title>The outline of Outlier</title>
    <url>/2020/07/14/The-outline-of-Outlier/</url>
    <content><![CDATA[<h3 id="The-Outline-of-Outlier"><a href="#The-Outline-of-Outlier" class="headerlink" title="The Outline of Outlier"></a>The Outline of Outlier</h3><h3 id="0-Abstract"><a href="#0-Abstract" class="headerlink" title="0 Abstract"></a>0 Abstract</h3><h3 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1 Introduction"></a>1 Introduction</h3><ol>
<li>指出虚拟化的多租户云平台优点；</li>
<li>hypervisor对于云平台很重要；</li>
</ol>
<h3 id="2-Background"><a href="#2-Background" class="headerlink" title="2 Background"></a>2 Background</h3><h4 id="2-1-Quick-View-of-Xen-Hypervisor"><a href="#2-1-Quick-View-of-Xen-Hypervisor" class="headerlink" title="2.1 Quick View  of Xen Hypervisor"></a>2.1 Quick View  of Xen Hypervisor</h4><h4 id="2-2-Dynamic-Root-of-Trust"><a href="#2-2-Dynamic-Root-of-Trust" class="headerlink" title="2.2 Dynamic Root of Trust"></a>2.2 Dynamic Root of Trust</h4><h4 id="2-3-Byzantine-Fault-Tolerance"><a href="#2-3-Byzantine-Fault-Tolerance" class="headerlink" title="2.3 Byzantine Fault Tolerance"></a>2.3 Byzantine Fault Tolerance</h4><h3 id="3-Overview"><a href="#3-Overview" class="headerlink" title="3 Overview"></a>3 Overview</h3><h4 id="3-1-Threat-Model-and-Assumptions"><a href="#3-1-Threat-Model-and-Assumptions" class="headerlink" title="3.1 Threat Model and Assumptions"></a>3.1 Threat Model and Assumptions</h4><h4 id="3-2-Goals"><a href="#3-2-Goals" class="headerlink" title="3.2 Goals"></a>3.2 Goals</h4><h4 id="3-3-Design-and-Approaches"><a href="#3-3-Design-and-Approaches" class="headerlink" title="3.3 Design and Approaches"></a>3.3 Design and Approaches</h4><h3 id="4-Implementation"><a href="#4-Implementation" class="headerlink" title="4 Implementation"></a>4 Implementation</h3><h4 id="4-1-Co-protocol"><a href="#4-1-Co-protocol" class="headerlink" title="4.1 Co-protocol"></a>4.1 Co-protocol</h4><h4 id="4-2-Checker"><a href="#4-2-Checker" class="headerlink" title="4.2 Checker"></a>4.2 Checker</h4><h3 id="5-Security-Analysis"><a href="#5-Security-Analysis" class="headerlink" title="5 Security Analysis"></a>5 Security Analysis</h3><h4 id="5-1-Theorems-in-the-Co-protocol"><a href="#5-1-Theorems-in-the-Co-protocol" class="headerlink" title="5.1 Theorems in the Co-protocol"></a>5.1 Theorems in the Co-protocol</h4><h4 id="5-2-Subverting-Outlier"><a href="#5-2-Subverting-Outlier" class="headerlink" title="5.2 Subverting Outlier"></a>5.2 Subverting Outlier</h4><h4 id="5-3-Attacking-Hypervisor-Code-Integrity"><a href="#5-3-Attacking-Hypervisor-Code-Integrity" class="headerlink" title="5.3 Attacking Hypervisor Code Integrity"></a>5.3 Attacking Hypervisor Code Integrity</h4><h4 id="5-4-Limitations-and-Future-Work"><a href="#5-4-Limitations-and-Future-Work" class="headerlink" title="5.4 Limitations and Future Work"></a>5.4 Limitations and Future Work</h4><h3 id="6-Evaluation"><a href="#6-Evaluation" class="headerlink" title="6 Evaluation"></a>6 Evaluation</h3><h4 id="6-1-CPU-Overhead"><a href="#6-1-CPU-Overhead" class="headerlink" title="6.1 CPU Overhead"></a>6.1 CPU Overhead</h4><h4 id="6-2-Network-Overhead"><a href="#6-2-Network-Overhead" class="headerlink" title="6.2 Network Overhead"></a>6.2 Network Overhead</h4><h4 id="6-3-Detection-Time"><a href="#6-3-Detection-Time" class="headerlink" title="6.3 Detection Time"></a>6.3 Detection Time</h4><h3 id="7-Related-Work"><a href="#7-Related-Work" class="headerlink" title="7 Related Work"></a>7 Related Work</h3><h3 id="8-Conclusion"><a href="#8-Conclusion" class="headerlink" title="8 Conclusion"></a>8 Conclusion</h3>]]></content>
      <tags>
        <tag>TODO</tag>
        <tag>paper</tag>
      </tags>
  </entry>
  <entry>
    <title>Timing-Based Attestation</title>
    <url>/2021/07/07/Timing-Based-Attestation/</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>Transient Execution Attacks</title>
    <url>/2020/12/30/Transient-Execution-Attacks/</url>
    <content><![CDATA[<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">序号</th>
<th style="text-align:center">属性</th>
<th style="text-align:center">内容</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">原文PDF</td>
<td style="text-align:center"><a href="https://www.cs.princeton.edu/courses/archive/spr06/cos592/bib/pioneer-seshadri-sosp05.pdf" target="_blank" rel="noopener">Pioneer</a></td>
</tr>
<tr>
<td style="text-align:center">2</td>
<td style="text-align:center">作者信息</td>
<td style="text-align:center">CMU/CyLab</td>
</tr>
<tr>
<td style="text-align:center">3</td>
<td style="text-align:center">核心内容</td>
<td style="text-align:center">one-on-one 方式检测内存信息是否有差别</td>
</tr>
<tr>
<td style="text-align:center">4</td>
<td style="text-align:center">研究领域</td>
<td style="text-align:center">安全检测</td>
</tr>
<tr>
<td style="text-align:center">5</td>
<td style="text-align:center">全文总览</td>
<td style="text-align:center">通过one-on-one 的方法对非可信主机进行检测，从而构造出一个可信的执行环境。</td>
</tr>
</tbody>
</table>
</div>
<p>瞬时攻击</p>
]]></content>
      <categories>
        <category>OSDI</category>
      </categories>
      <tags>
        <tag>TODO</tag>
        <tag>论文解读</tag>
      </tags>
  </entry>
  <entry>
    <title>Socket编程基础总结</title>
    <url>/2020/10/19/Socket%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<p>Socket编程基础总结</p>
<h3 id="Socket是什么"><a href="#Socket是什么" class="headerlink" title="Socket是什么"></a>Socket是什么</h3><h3 id="Linux下Socket通讯"><a href="#Linux下Socket通讯" class="headerlink" title="Linux下Socket通讯"></a>Linux下Socket通讯</h3><p>socket 的原意是“插座”，在计算机通信领域，socket 被翻译为“套接字”，它是计算机之间进行通信的一种约定或一种方式。通过 socket 这种约定，一台计算机可以接收其他计算机的数据，也可以向其他计算机发送数据。</p>
<p>在 UNIX/Linux 系统中，为了统一对各种硬件的操作，简化接口，不同的硬件设备也都被看成一个文件。对这些文件的操作，等同于对磁盘上普通文件的操作。</p>
<p>为了表示和区分已经打开的文件，UNIX/Linux 会给每个文件分配一个 ID，这个 ID 就是一个整数，被称为文件描述符（File Descriptor）。例如：</p>
<ul>
<li>通常用 0 来表示标准输入文件（stdin），它对应的硬件设备就是键盘；</li>
<li>通常用 1 来表示标准输出文件（stdout），它对应的硬件设备就是显示器。</li>
</ul>
<p>UNIX/Linux 程序在执行任何形式的 I/O 操作时，都是在读取或者写入一个文件描述符。一个文件描述符只是一个和打开的文件相关联的整数，它的背后可能是一个硬盘上的普通文件、FIFO、管道、终端、键盘、显示器，甚至是一个网络连接。</p>
<p>请注意，网络连接也是一个文件，它也有文件描述符！</p>
<p>我们可以通过 socket() 函数来创建一个网络连接，或者说打开一个网络文件，socket() 的返回值就是文件描述符。有了文件描述符，我们就可以使用普通的文件操作函数来传输数据了，例如：</p>
<ul>
<li>用 read() 读取从远程计算机传来的数据；</li>
<li>用 write() 向远程计算机写入数据。</li>
</ul>
<p>只要用 socket() 创建了连接，剩下的就是文件操作了！</p>
<h4 id="Server-代码"><a href="#Server-代码" class="headerlink" title="Server 代码"></a><strong>Server 代码</strong></h4><pre><code class="lang-c">#include &lt;stdio.h&gt;
#include &lt;string.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;unistd.h&gt;
#include &lt;arpa/inet.h&gt;
#include &lt;sys/socket.h&gt;
#include &lt;netinet/in.h&gt;

int main(){
    //创建套接字
    int serv_sock = socket(AF_INET, SOCK_STREAM, IPPROTO_TCP);

    //将套接字和IP、端口绑定
    struct sockaddr_in serv_addr;
    memset(&amp;serv_addr, 0, sizeof(serv_addr));  //每个字节都用0填充
    serv_addr.sin_family = AF_INET;  //使用IPv4地址
    serv_addr.sin_addr.s_addr = inet_addr("127.0.0.1");  //具体的IP地址
    serv_addr.sin_port = htons(1234);  //端口
    bind(serv_sock, (struct sockaddr*)&amp;serv_addr, sizeof(serv_addr));

    //进入监听状态，等待用户发起请求
    listen(serv_sock, 20);

    //接收客户端请求
    struct sockaddr_in clnt_addr;
    socklen_t clnt_addr_size = sizeof(clnt_addr);
    int clnt_sock = accept(serv_sock, (struct sockaddr*)&amp;clnt_addr, &amp;clnt_addr_size);

    //向客户端发送数据
    char str[] = "Hello world!";
    write(clnt_sock, str, sizeof(str));

    //关闭套接字
    close(clnt_sock);
    close(serv_sock);

    return 0;
}
</code></pre>
<h4 id="Client-代码"><a href="#Client-代码" class="headerlink" title="Client 代码"></a><strong>Client 代码</strong></h4><pre><code class="lang-c">#include &lt;stdio.h&gt;
#include &lt;string.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;unistd.h&gt;
#include &lt;arpa/inet.h&gt;
#include &lt;sys/socket.h&gt;

int main(){
    //创建套接字
    int sock = socket(AF_INET, SOCK_STREAM, 0);

    //向服务器（特定的IP和端口）发起请求
    struct sockaddr_in serv_addr;
    memset(&amp;serv_addr, 0, sizeof(serv_addr));  //每个字节都用0填充
    serv_addr.sin_family = AF_INET;  //使用IPv4地址
    serv_addr.sin_addr.s_addr = inet_addr("127.0.0.1");  //具体的IP地址(server的IP)
    serv_addr.sin_port = htons(1234);  //端口
    connect(sock, (struct sockaddr*)&amp;serv_addr, sizeof(serv_addr));

    //读取服务器传回的数据
    char buffer[40];
    read(sock, buffer, sizeof(buffer)-1);

    printf("Message form server: %s\n", buffer);

    //关闭套接字
    close(sock);

    return 0;
}
</code></pre>
<blockquote>
<p>启动一个终端（Shell），先编译 server.cpp 并运行：</p>
<p>[admin@localhost ~]$ g++ server.cpp -o server</p>
<p>[admin@localhost ~]$ ./server<br>#等待请求的到来</p>
<p>正常情况下，程序运行到 accept() 函数就会被阻塞，等待客户端发起请求。</p>
<p>接下再启动一个终端，编译 client.cpp 并运行：</p>
<p>[admin@localhost ~]$ g++ client.cpp -o client</p>
<p>[admin@localhost ~]$ ./client<br>Message form server:Hello World!</p>
<p>client 接收到从 server发送过来的字符串就运行结束了，同时，server 完成发送字符串的任务也运行结束了。大家可以通过两个打开的终端来观察。</p>
<p>client 运行后，通过 connect() 函数向 server 发起请求，处于监听状态的 server 被激活，执行 accept() 函数，接受客户端的请求，然后执行 write() 函数向 client 传回数据。client 接收到传回的数据后，connect() 就运行结束了，然后使用 read() 将数据读取出来。</p>
<blockquote>
<p>server 只接受一次 client 请求，当 server 向 client 传回数据后，程序就运行结束了。如果想再次接收到服务器的数据，必须再次运行 server，所以这是一个非常简陋的 socket 程序，不能够一直接受客户端的请求。</p>
</blockquote>
</blockquote>
<h4 id="源码解析"><a href="#源码解析" class="headerlink" title="源码解析"></a><strong>源码解析</strong></h4><p> server.cpp 中的代码。</p>
<p>第 11 行通过 socket() 函数创建了一个套接字，参数 AF_INET 表示使用 IPv4 地址，SOCK_STREAM 表示使用面向连接的套接字，IPPROTO_TCP 表示使用 TCP 协议。在 Linux 中，socket 也是一种文件，有文件描述符，可以使用 write() / read() 函数进行 I/O 操作。</p>
<p>第 19 行通过 bind() 函数将套接字 serv_sock 与特定的 IP 地址和端口绑定，IP 地址和端口都保存在 sockaddr_in 结构体中。socket() 函数确定了套接字的各种属性，bind() 函数让套接字与特定的IP地址和端口对应起来，这样客户端才能连接到该套接字。</p>
<p>第 22 行让套接字处于被动监听状态。所谓被动监听，是指套接字一直处于“睡眠”中，直到客户端发起请求才会被“唤醒”。</p>
<p>第 27 行的 accept() 函数用来接收客户端的请求。程序一旦执行到 accept() 就会被阻塞（暂停运行），直到客户端发起请求。</p>
<p>第 31 行的 write() 函数用来向套接字文件中写入数据，也就是向客户端发送数据。</p>
<p>和普通文件一样，socket 在使用完毕后也要用 close() 关闭。</p>
<p> <strong>client.cpp 中的代码</strong></p>
<p>第 19 行代码通过 connect() 向服务器发起请求，服务器的IP地址和端口号保存在 sockaddr_in 结构体中。直到服务器传回数据后，connect() 才运行结束。</p>
<p>第 23 行代码通过 read() 从套接字文件中读取数据。</p>
<h3 id="socket-创建套接字"><a href="#socket-创建套接字" class="headerlink" title="socket()创建套接字"></a>socket()创建套接字</h3><p>在 Linux 下使用 <sys socket.h=""> 头文件中 socket() 函数来创建套接字，原型为：</sys></p>
<pre><code class="lang-c">int socket(int af, int type, int protocol);
</code></pre>
<p>1) af 为地址族（Address Family），也就是 IP 地址类型，常用的有 AF_INET 和 AF_INET6。AF 是“Address Family”的简写，INET是“Inetnet”的简写。AF_INET 表示 IPv4 地址，例如 127.0.0.1(本机IP)；AF_INET6 表示 IPv6 地址，例如 1030::C9B4:FF12:48AA:1A2B。PF前缀等价于AF前缀。</p>
<p>2) type 为数据传输方式/套接字类型，常用的有 SOCK_STREAM（流格式套接字/面向连接的套接字） 和 SOCK_DGRAM（数据报套接字/无连接的套接字）。</p>
<p>3) protocol 表示传输协议，常用的有 IPPROTO_TCP 和 IPPTOTO_UDP，分别表示 TCP 传输协议和 UDP 传输协议。</p>
<p>有了地址类型和数据传输方式，还不足以决定采用哪种协议吗？为什么还需要第三个参数呢？</p>
<p>正如大家所想，一般情况下有了 af 和 type 两个参数就可以创建套接字了，操作系统会自动推演出协议类型，除非遇到这样的情况：有两种不同的协议支持同一种地址类型和数据传输类型。如果不指明使用哪种协议，操作系统是没办法自动推演的。</p>
<p>以 IPv4 地址为例，参数 af 的值为 PF_INET。如果使用 SOCK_STREAM 传输数据，那么满足这两个条件的协议只有 TCP，因此可以这样来调用 socket() 函数：</p>
<pre><code class="lang-c">int tcp_socket = socket(PF_INET, SOCK_STREAM, IPPROTO_TCP);  //IPPROTO_TCP表示TCP协议
</code></pre>
<p>这种套接字称为 TCP 套接字。</p>
<p>如果使用 SOCK_DGRAM 传输方式，那么满足这两个条件的协议只有 UDP，因此可以这样来调用 socket() 函数：</p>
<pre><code class="lang-c">int udp_socket = socket(AF_INET, SOCK_DGRAM, IPPROTO_UDP);  //IPPROTO_UDP表示UDP协议
</code></pre>
<p>这种套接字称为 UDP 套接字。</p>
<p>上面两种情况都只有一种协议满足条件，可以将 protocol 的值设为 0，系统会自动推演出应该使用什么协议，如下所示：</p>
<pre><code class="lang-c">int tcp_socket = socket(AF_INET, SOCK_STREAM, 0);  //创建TCP套接字
int udp_socket = socket(AF_INET, SOCK_DGRAM, 0);  //创建UDP套接字
</code></pre>
<h3 id="bind-connect-函数"><a href="#bind-connect-函数" class="headerlink" title="bind() connect()函数"></a>bind() connect()函数</h3><h4 id="bind-函数的原型"><a href="#bind-函数的原型" class="headerlink" title="bind() 函数的原型"></a>bind() 函数的原型</h4><pre><code class="lang-c">int bind(int sock, struct sockaddr *addr, socklen_t addrlen);
</code></pre>
<p>sock 为 socket 文件描述符，addr 为 sockaddr 结构体变量的指针，addrlen 为 addr 变量的大小，可由 sizeof() 计算得出。</p>
<p>下面的代码，将创建的套接字与IP地址 127.0.0.1、端口 1234 绑定：</p>
<pre><code class="lang-c">//创建套接字
int serv_sock = socket(AF_INET, SOCK_STREAM, IPPROTO_TCP);
//创建sockaddr_in结构体变量
struct sockaddr_in serv_addr;
memset(&amp;serv_addr, 0, sizeof(serv_addr));  //每个字节都用0填充
serv_addr.sin_family = AF_INET;            //使用IPv4地址
serv_addr.sin_addr.s_addr = inet_addr("127.0.0.1");  //具体的IP地址
serv_addr.sin_port = htons(1234);  //端口
//将套接字和IP、端口绑定
bind(serv_sock, (struct sockaddr*)&amp;serv_addr, sizeof(serv_addr));
</code></pre>
<p>在这里使用 sockaddr_in 结构体，然后再强制转换为 sockaddr 类型。</p>
<p><strong>sockaddr_in 结构体</strong></p>
<p> sockaddr_in 结构体的成员变量如下：</p>
<pre><code class="lang-c">struct sockaddr_in{    
    sa_family_t     sin_family;   //地址族（Address Family），也就是地址类型    
    uint16_t        sin_port;     //16位的端口号    
    struct in_addr  sin_addr;     //32位IP地址    
    char            sin_zero[8];  //不使用，一般用0填充
};
</code></pre>
<p>1) sin_family 和 socket() 的第一个参数的含义相同，取值也要保持一致。</p>
<p>2) sin_prot 为端口号。uint16_t 的长度为两个字节，理论上端口号的取值范围为 0~65536，但 0~1023 的端口一般由系统分配给特定的服务程序，例如 Web 服务的端口号为 80，FTP 服务的端口号为 21，所以要尽量在 1024~65536 之间分配端口号。</p>
<font color="DodgerBlue"> 端口号需要用 htons() 函数转换。</font>

<p>3) sin_addr 是 struct in_addr 结构体类型的变量。</p>
<p>4) sin_zero[8] 是多余的8个字节，没有用，一般使用 memset() 函数填充为 0。上面的代码中，先用 memset() 将结构体的全部字节填充为 0，再给前3个成员赋值，剩下的 sin_zero 自然就是 0 了。</p>
<p><strong>in_addr 结构体</strong></p>
<p>sockaddr_in 的第3个成员是 in_addr 类型的结构体，该结构体只包含一个成员，如下所示：</p>
<pre><code class="lang-c">struct in_addr{    
    in_addr_t  s_addr;  //32位的IP地址
};
</code></pre>
<p>in_addr_t 在头文件<code>&lt;netinet/in.h&gt;</code>中定义，等价于 unsigned long，长度为4个字节。也就是说，s_addr 是一个整数，而IP地址是一个字符串，所以需要 inet_addr() 函数进行转换，例如：</p>
<pre><code class="lang-c">unsigned long ip = inet_addr("127.0.0.1");
printf("%ld\n", ip); // 结果为 16777343
</code></pre>
<p>图解 sockaddr_in 与 sockaddr结构体</p>
<p><img src="/2020/10/19/Socket%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80%E6%80%BB%E7%BB%93/addr_in.jpg" width="280"><img src="/2020/10/19/Socket%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80%E6%80%BB%E7%BB%93/sockaddr.jpg" width="280"></p>
<p>sockaddr 结构体的定义如下：</p>
<pre><code class="lang-c">struct sockaddr{    
    sa_family_t  sin_family;   //地址族（Address Family），也就是地址类型    
    char         sa_data[14];  //IP地址和端口号
};
</code></pre>
<p>可以认为，sockaddr 是一种通用的结构体，可以用来保存多种类型的IP地址和端口号，而 sockaddr_in 是专门用来保存 IPv4 地址的结构体。另外还有 sockaddr_in6，用来保存 IPv6 地址，它的定义如下：</p>
<pre><code class="lang-c">struct sockaddr_in6 {     
    sa_family_t sin6_family;    //(2)地址类型，取值为AF_INET6    
    in_port_t sin6_port;        //(2)16位端口号    
    uint32_t sin6_flowinfo;     //(4)IPv6流信息    
    struct in6_addr sin6_addr;  //(4)具体的IPv6地址    
    uint32_t sin6_scope_id;     //(4)接口范围ID
};
</code></pre>
<p>正是由于通用结构体 sockaddr 使用不便，才针对不同的地址类型定义了不同的结构体。</p>
<h4 id="connect-函数"><a href="#connect-函数" class="headerlink" title="connect() 函数"></a>connect() 函数</h4><p>connect() 函数用来建立连接，它的原型为：</p>
<pre><code class="lang-c">int connect(int sock, struct sockaddr *serv_addr, socklen_t addrlen);
</code></pre>
<p>各个参数的说明和 bind() 相同。</p>
<h3 id="listen-accept-函数"><a href="#listen-accept-函数" class="headerlink" title="listen() accept() 函数"></a>listen() accept() 函数</h3><h4 id="listen-函数"><a href="#listen-函数" class="headerlink" title="listen()函数"></a><strong>listen()函数</strong></h4><p>通过 listen() 函数可以让套接字进入被动监听状态，它的原型为：</p>
<pre><code class="lang-c">int listen(int sock, int backlog);
</code></pre>
<p><code>sock</code> 为需要进入监听状态的套接字，<code>backlog</code>为请求队列的最大长度。</p>
<p>所谓被动监听，是指当没有客户端请求时，套接字处于“睡眠”状态，只有当接收到客户端请求时，套接字才会被“唤醒”来响应请求。</p>
<p><strong>请求队列</strong></p>
<p>当套接字正在处理客户端请求时，如果有新的请求进来，套接字是没法处理的，只能把它放进缓冲区，待当前请求处理完毕后，再从缓冲区中读取出来处理。如果不断有新的请求进来，它们就按照先后顺序在缓冲区中排队，直到缓冲区满。这个缓冲区，就称为请求队列（Request Queue）。</p>
<p>缓冲区的长度（能存放多少个客户端请求）可以通过 <code>listen()</code> 函数的 <code>backlog</code>参数指定，但究竟为多少并没有什么标准，可以根据你的需求来定，并发量小的话可以是10或者20。</p>
<p>如果将 <code>backlog</code>的值设置为 <code>SOMAXCONN</code>，就由系统来决定请求队列长度，这个值一般比较大，可能是几百，或者更多。</p>
<p>当请求队列满时，就不再接收新的请求，对于 Linux，客户端会收到 <code>ECONNREFUSED</code>错误，对于 Windows，客户端会收到 WSAECONNREFUSED 错误。</p>
<p>注意：<code>listen()</code> 只是让套接字处于监听状态，并没有接收请求。接收请求需要使用 <code>accept()</code> 函数。</p>
<h4 id="accept-函数"><a href="#accept-函数" class="headerlink" title="accept() 函数"></a><strong>accept() 函数</strong></h4><p>当套接字处于监听状态时，可以通过 <code>accept()</code> 函数来接收客户端请求。它的原型为：</p>
<pre><code class="lang-c">int accept(int sock, struct sockaddr *addr, socklen_t *addrlen);
</code></pre>
<p>它的参数与 <code>listen()</code> 和 <code>connect()</code> 是相同的：sock 为服务器端套接字，addr 为 <code>sockaddr_in</code>结构体变量，addrlen 为参数 addr 的长度，可由<code>sizeof()</code>求得。</p>
<p>accept() 返回一个新的套接字来和客户端通信，addr 保存了客户端的IP地址和端口号，而 sock 是服务器端的套接字，注意区分。后面和客户端通信时，要使用这个新生成的套接字，而不是原来服务器端的套接字。</p>
<p>最后需要说明的是：listen() 只是让套接字进入监听状态，并没有真正接收客户端请求，listen() 后面的代码会继续执行，直到遇到 accept()。accept() 会阻塞程序执行（后面代码不能被执行），直到有新的请求到来。</p>
<h3 id="write-read-函数"><a href="#write-read-函数" class="headerlink" title="write() read() 函数"></a>write() read() 函数</h3><p>Linux 不区分套接字文件和普通文件，使用 write() 可以向套接字中写入数据，使用 read() 可以从套接字中读取数据。</p>
<p>两台计算机之间的通信相当于两个套接字之间的通信，在服务器端用 write() 向套接字写入数据，客户端就能收到，然后再使用 read() 从套接字中读取出来，就完成了一次通信。</p>
<h4 id="write-的原型"><a href="#write-的原型" class="headerlink" title="write() 的原型"></a>write() 的原型</h4><pre><code class="lang-c">ssize_t write(int fd, const void *buf, size_t nbytes);
</code></pre>
<p>fd 为要写入的文件的描述符，buf 为要写入的数据的缓冲区地址，nbytes 为要写入的数据的字节数。</p>
<blockquote>
<p>size_t 是通过 typedef 声明的 unsigned int 类型；</p>
<p>ssize_t 在 “size_t” 前面加了一个”s”，代表 signed，即 ssize_t 是通过 typedef 声明的 signed int 类型。</p>
</blockquote>
<p>write() 函数会将缓冲区 buf 中的 nbytes 个字节写入文件 fd，成功则返回写入的字节数，失败则返回 -1。</p>
<h4 id="read-的原型"><a href="#read-的原型" class="headerlink" title="read() 的原型"></a>read() 的原型</h4><pre><code class="lang-c">ssize_t read(int fd, void *buf, size_t nbytes);
</code></pre>
<p>fd 为要读取的文件的描述符，buf 为要接收数据的缓冲区地址，nbytes 为要读取的数据的字节数。</p>
<p>read() 函数会从 fd 文件中读取 nbytes 个字节并保存到缓冲区 buf，成功则返回读取到的字节数（但遇到文件结尾则返回0），失败则返回 -1。</p>
<h3 id="Socket代码Plus"><a href="#Socket代码Plus" class="headerlink" title="Socket代码Plus"></a>Socket代码Plus</h3><h4 id="Server"><a href="#Server" class="headerlink" title="Server"></a>Server</h4><pre><code class="lang-c">//
// Created by ykma on 20-10-19.
//

#include &lt;arpa/inet.h&gt;
#include &lt;string.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;sys/types.h&gt;
#include &lt;sys/socket.h&gt;
#include &lt;unistd.h&gt;
#include &lt;stdio.h&gt;
#include &lt;time.h&gt;
#include &lt;errno.h&gt;

#define port 9080
#define BUF_SIZE 1024

int main(void)
{
    //create socket
    int serverSock = socket(AF_INET, SOCK_STREAM, IPPROTO_TCP);

    // create socket (both server and client)
    struct sockaddr_in clientAddr, serverAddr;
    memset(&amp;clientAddr, 0, sizeof(clientAddr));
    memset(&amp;serverAddr, 0, sizeof(serverAddr));

    // init sock
    serverAddr.sin_family = AF_INET;
    serverAddr.sin_port = htons(port);
    serverAddr.sin_addr.s_addr = inet_addr("0.0.0.0"); // 在server端默认写该IP地址，本机所有IP！

    // bind socket
    // bind(serverSock, (struct sockaddr*)&amp;serverAddr, sizeof(serverAddr));
    if (bind(serverSock, (struct sockaddr*)&amp;serverAddr, sizeof(serverAddr)) &lt; 0)
    {
        printf("bind error = %d (%s)\n", errno, strerror(errno));
        return 0;
    }

    // ready to listen
    // listen(serverSock, 10);
    if (listen(serverSock, 10) &lt; 0)
    {
        printf("listen error = %d (%s)\n", errno, strerror(errno));
        return 0;
    }

    // set buffer
    char RecvBuffer[BUF_SIZE] = {0};
    char SendBuffer[BUF_SIZE] = {0};

    socklen_t addrlen = sizeof(struct sockaddr);

    while(1) {
        // wait to recieve from client
        int clientSock = accept(serverSock, (struct sockaddr*)&amp;clientAddr, &amp;addrlen);

        // output IP address
        printf("output IP address\n");
        printf("Client IP : %s \n", inet_ntoa(clientAddr.sin_addr));

        // read from client
        int messagelen = read(clientSock, RecvBuffer, BUF_SIZE);
        printf("Message from client : %s \n", RecvBuffer);

        // sent to client
        printf("Send to client: \n");
        fgets(SendBuffer, sizeof(SendBuffer), stdin);
        write(clientSock, SendBuffer, messagelen);

        // close socket
        close(clientSock);
        memset(RecvBuffer, 0, BUF_SIZE);
        memset(SendBuffer, 0, BUF_SIZE);
    }

    return 0;
}
</code></pre>
<h4 id="Client"><a href="#Client" class="headerlink" title="Client"></a>Client</h4><pre><code class="lang-c">#include &lt;stdio.h&gt;
#include &lt;arpa/inet.h&gt;
#include &lt;string.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;sys/types.h&gt;
#include &lt;sys/socket.h&gt;
#include &lt;unistd.h&gt;
#include &lt;netinet/in.h&gt;
#include &lt;errno.h&gt;

#define port 9088  // 定义通讯接口
#define BUF_SIZE 1024

int main(void)
{
    // create socket
    struct sockaddr_in clientAddr;
    // init sock
    memset(&amp;clientAddr, 0, sizeof(clientAddr));
    clientAddr.sin_family = AF_INET;
    clientAddr.sin_port = htons(port);
    clientAddr.sin_addr.s_addr = inet_addr("127.0.0.1"); // 主机IP地址

    char SendBuffer[BUF_SIZE] = {0};
    char RecvBuffer[BUF_SIZE] = {0};

    while(1)
    {
        // create socket
        int clientSock = socket(AF_INET, SOCK_STREAM, IPPROTO_TCP);
        // connect to server
        //connect(clientSock, (struct sockaddr*)&amp;clientAddr, sizeof(clientAddr));

        if (connect(clientSock, (struct sockaddr*)&amp;clientAddr, sizeof(clientAddr)) &lt; 0)
        {
            printf("%s %d\n",strerror(errno), errno);
            // perror("connect()");
            return 0;
        }

        // input message and sent to server
        printf("Input a string: ");
        fgets(SendBuffer, sizeof(SendBuffer), stdin);
        write(clientSock, SendBuffer, BUF_SIZE);

        // receive message from server and print
        read(clientSock, RecvBuffer, BUF_SIZE);
        printf("Message from server: %s \n", RecvBuffer);

        // reset buffer
        memset(SendBuffer, 0, BUF_SIZE);
        memset(RecvBuffer, 0, BUF_SIZE);

        // close socket
        close(clientSock);
    }

    return 0;
}
</code></pre>
]]></content>
      <tags>
        <tag>总结</tag>
        <tag>Socket</tag>
      </tags>
  </entry>
  <entry>
    <title>TimeCrypt</title>
    <url>/2020/07/22/TimeCrypt/</url>
    <content><![CDATA[<div class="table-container">
<table>
<thead>
<tr>
<th>序号</th>
<th style="text-align:center">属性</th>
<th style="text-align:center">内容</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td style="text-align:center">原文PDF</td>
<td style="text-align:center"><a href="https://www.usenix.org/system/files/nsdi20-paper-burkhalter.pdf" target="_blank" rel="noopener">TimeCrypt</a></td>
</tr>
<tr>
<td>2</td>
<td style="text-align:center">作者信息</td>
<td style="text-align:center">1. <a href="https://people.inf.ethz.ch/burlukas/" target="_blank" rel="noopener">Lukas Burkhalter</a> Distributed Systems Group at ETH Zurich 苏黎世联邦理工学院分布式系统组研究助理；2. Sylvia Ratnasamy  Berkeley associate professor；3. Anwar Hithnawi is a researcher at the NetSys Lab at UC Berkeley, USA；4. Hossein Shafagh is a researcher at the Distributed Systems Group at ETH Zurich.</td>
</tr>
<tr>
<td>3</td>
<td style="text-align:center">核心内容</td>
<td style="text-align:center">时间序列流数据加密，用户访问控制</td>
</tr>
<tr>
<td>4</td>
<td style="text-align:center">研究领域</td>
<td style="text-align:center">同态加密，密码学，时间序列</td>
</tr>
<tr>
<td>5</td>
<td style="text-align:center">全文总览</td>
<td style="text-align:center">本文目的是构建一个对时间序列数据更细粒度的访问控制策略，可以实现数据的端到端共享，数据所有者可以对访问权限加以约束。</td>
</tr>
<tr>
<td>6</td>
<td style="text-align:center">补充介绍</td>
<td style="text-align:center"><a href="https://timecrypt.io/" target="_blank" rel="noopener">https://timecrypt.io/</a></td>
</tr>
<tr>
<td>7</td>
<td style="text-align:center">开源代码</td>
<td style="text-align:center"><a href="https://github.com/TimeCrypt/timecrypt" target="_blank" rel="noopener">https://github.com/TimeCrypt/timecrypt</a></td>
</tr>
<tr>
<td>8</td>
<td style="text-align:center">同态加密</td>
<td style="text-align:center"><a href="https://web.archive.org/web/20130704120108/http://www.cs.ut.ee/~lipmaa/crypto/link/public/homomorphic.php" target="_blank" rel="noopener">https://web.archive.org/web/20130704120108/http://www.cs.ut.ee/~lipmaa/crypto/link/public/homomorphic.php</a></td>
</tr>
</tbody>
</table>
</div>
<h3 id="研究背景"><a href="#研究背景" class="headerlink" title="研究背景"></a>研究背景</h3><p>    许多的设备都可以在云端存储一些时间序列信息，在云环境中，许多的服务都可以获取到这些时间序列信息，这是对用户隐私的一种侵犯。而且随着物联网的到来，更加速了这些数据的生成。目前，人们提高了对隐私数据的重视程度，致力于保护这些数据的机密性。</p>
<h3 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h3><p>本文是发表在NSDI‘20的一篇文章，目的是构建一个针对时序数据加密并且能够进行访问控制的系统。数据的加密与解密过程都存在与客户端，因此发送给服务器端（云平台）的数据都默认是加密的，数据加密防止了云平台对用户传输数据的窥探。</p>
<h3 id="Background-Time-Series-Data"><a href="#Background-Time-Series-Data" class="headerlink" title="Background-Time Series Data"></a>Background-Time Series Data</h3><ol>
<li><p>时间序列数据应用广泛：个人健康、农业、交通运输和智慧城市等</p>
</li>
<li><p>时间序列数据特征：</p>
<p>a.只追加，产生频率高，存储占用多 </p>
<p>b.高吞吐、需要可扩展 </p>
<p>c.查询通常是基于时间范围考虑，满足用户在不同的时间粒度进行查询</p>
</li>
<li><p>对时间序列数据的操作：</p>
<p>a.查询通常用于汇总、统计 </p>
<p>b.通常这些时间数据由机器产生且是大量连续的，数据价值随着时间的推移递减，一般最近的数据要比较早的数据价值高，因此要对较早的数据进行聚合操作。</p>
</li>
</ol>
<h3 id="Thread"><a href="#Thread" class="headerlink" title="Thread"></a>Thread</h3><p>  许多的设备都可以在云端存储一些时间序列信息，在云环境中，许多的服务都可以获取到这些时间序列信息，这是对用户隐私的一种侵犯。而且随着物联网的到来，更加速了这些数据的生成。目前，人们提高了对隐私数据的重视程度，致力于保护这些数据的机密性。</p>
<h3 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h3><p>数据端到端的加密通常：不信任云供应商的安全性，因此在客户端对数据进行加密，传输密文到云中进行存储，客户端读取数据时进行解密。</p>
<p>刚提到的是时间序列数据产生频率很高，数据量很大，它所需要的高吞吐低延时的查询，在对数据加密之后可以实现吗？</p>
<h3 id="Challenge"><a href="#Challenge" class="headerlink" title="Challenge"></a>Challenge</h3><p>为了达到这个目的，本文面临的挑战是：数据的可扩展性以及与用户的交互性。</p>
<p>当前的时序数据库所提供的仅仅是数据追加操作以及在指定时间范围内的查询操作。因为对数据加密的代价是比较高的，所以为了满足挑战1，要在数据加密的同时对时序数据库大量数据进行高吞吐的写入，以及对指定时间的数据查询。</p>
<p>另一个挑战是安全共享</p>
<p>拿个人的健康数据举例子，个人的医生可能想看到个人每小时的平均心率数据，运动时可能想看下运动过程每分钟的平均心率，这就需要个人的数据以不同的时间间隔共享给指定的用户，同时在云端的存储是加密的。这就要求有选择的共享个人时序数据。</p>
<h3 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h3><p>宏观来看TimeCrypt有两个角色，一个是Client端，一个是Server端，后者是非可信的，仅仅用于存储以及索引数据。</p>
<p>其中Client可以分为Data Producer和 Data Consumer，后者需要从前者得到访问权限才可以对数据在指定范文内以指定的时间间隔进行解密。</p>
<p>在这个系统中，将时序数据库中的分块压缩和数据序列化等操作放在了Client端，这样更改之后server端仅仅对加密的数据进行存储以及满足Client Consumer查询操作。Writer（Producer）这个角色以最小的时间间隔将收集到的数据打包源源不断的发送给Server端。</p>
<h3 id="Writing-Stream"><a href="#Writing-Stream" class="headerlink" title="Writing Stream"></a>Writing Stream</h3><p>细节部分可以看到Writer（Producer）以最小的时间间隔将收集到的数据打包源源不断的发送给Server端。</p>
<p>因为对时间序列数据的操作中提到过，对这种数据进行的查询通常是统计学上的一些操作，比如取平均值、加和、计数等等。因此在Client中首先对数据在基本单位时间内进行初步的计算，并将这些计算的结果打包发送给Server端进行存储。那么，如何满足不同时间间隔的查询呢？本文将不同的时间间隔命名为分辨率，在不同分辨率的查询结果是不同时间间隔的统计结果。</p>
<p>作者就想：能不能在Server端对这些数据进行一步聚合操作，就直接等价于对明文数据进行了一步聚合操作呢？</p>
<p>上文提到，他们18年就是在同态加密上做的一个工作。因此，他们是有这个技术积累的。同态加密就是一种加密形式，在密文上的计算解密后与明文上的执行一致。这样可以不危及数据隐私，同时对数据进行计算。但是呢，目前的同态加密手段基本都是非对称的加密，这种加密虽然保证了数据的安全性，但是代价是十分昂贵的。比如对8bytes数据进行加密<sup><a href="#fn_describe" id="reffn_describe">describe</a></sup>，产生的密文是明文的96倍，两段明文加密的代价是1028倍，这显然不适合于源源不断产生的大量的时序数据。因此需要对该方法进行改进，使得能满足对时序数据的加密与查询需求。</p>
<h3 id="Goals"><a href="#Goals" class="headerlink" title="Goals"></a>Goals</h3><p>作者分析了很多现存的时序数据库的访问控制策略，这些访问控制粒度很粗糙，只是在数据库接口设置控制机制，要么用户可以访问全部数据，要么拒绝访问。</p>
<p>但是考虑到，医生想查看患者每小时的心率数据、健身教练想查看每分钟的心率数据这些情形，需要一个很细粒度的访问策略，同时对数据进行保护。</p>
<p>本文的目标是：将之前时序数据库中对数据的分享机制进行访问控制，实现更细粒度的访问。</p>
<h3 id="访问控制"><a href="#访问控制" class="headerlink" title="访问控制"></a>访问控制</h3><p><img src="/2020/07/22/TimeCrypt/Tree.png" style="zoom:40%;"></p>
<p>构建一个适合时间序列数据的加密方式，其中秘钥的分发采用将 $K_i$与 $K_{i+1}$ 以正值与负值分发给第$i$条明文用于加密，由于时间序列数据是连续的，因此在解密过程只获得收尾两个秘钥即可对此区间的所有数据进行解密。同时数据所有者对不同的client分发不同分辨率数据的秘钥，即可对数据实现访问控制。</p>
<p><img src="/2020/07/22/TimeCrypt/KeyStream.png" style="zoom:40%;"></p>
<p><img src="/2020/07/22/TimeCrypt/KeyTree.png" style="zoom:40%;"></p>
<p>本文提到的秘钥分发过程采用二叉树形式，在设置秘钥的过程中，将树的高度设置为一个很大的值，因此，存储在叶子节点的秘钥的数量基本接近无限大，这对时间序列的数据处理是有效的。同时在分发密钥时，对相应的节点进行派发，由于秘钥的单向性，也能够对用户的访问权限加以限制。</p>
<h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><p><img src="/2020/07/22/TimeCrypt/Evaluation.png" style="zoom:40%;"></p>
<p>在实验结果中可以看到，采用新形势的秘钥分发策略，系统的吞吐提升明显。对比实验的后两者是没有改进的同态加密策略。</p>
<p><img src="/2020/07/22/TimeCrypt/EvaluationLatency.png" style="zoom:40%;"></p>
<p>在实验结果中看到对不同分辨率的数据进行查询的时间延迟都是在秒级以内，是可以接受的。</p>
<h3 id="同态加密"><a href="#同态加密" class="headerlink" title="同态加密"></a>同态加密</h3><p>同态加密（HE）是一种加密形式，允许对密文进行计算，生成加密结果，加密后的结果与操作结果相匹配，就好像它们是在明文上执行一样。使用这样的工具，可以在不危及数据隐私的情况下外包存储或计算。</p>
<p>一般的加密方案关注的都是<strong>数据存储安全</strong>。即，我要给其他人发个加密的东西，或者要在计算机或者其他服务器上存一个东西，我要对数据进行加密后在发送或者存储。没有密钥的用户，不可能从加密结果中得到有关原始数据的任何信息。只有拥有密钥的用户才能够正确解密，得到原始的内容。我们注意到，这个过程中<strong>用户是不能对加密结果做任何操作的</strong>，只能进行存储、传输。对加密结果做任何操作，都将会导致错误的解密，甚至解密失败。</p>
<p>同态加密方案最有趣的地方在于，其关注的是<strong>数据处理安全</strong>。同态加密提供了一种<strong>对加密数据进行处理的功能</strong>。也就是说，其他人可以对加密数据进行处理，但是处理过程不会泄露任何原始内容。同时，拥有密钥的用户对处理过的数据进行解密后，得到的正好是处理后的结果。</p>
<p>允许人们对密文进行特定形式的代数运算得到仍然是加密的结果，将其解密所得到的结果与对明文进行同样的运算结果一样。换言之，这项技术令人们可以在加密的数据中进行诸如检索、比较等操作，得出正确的结果，而在整个处理过程中无需对数据进行解密。其意义在于，真正从根本上解决将数据及其操作委托给第三方时的保密问题，例如对于各种云计算的应用。</p>
<p>同态加密几乎就是为云计算而量身打造的！如果一个用户想要处理一个数据，但是他的计算机计算能力较弱。这个用户可以使用云计算来帮助他进行处理而得到结果。但是如果直接将数据交给云，无法保证安全性。于是，他可以使用同态加密，然后让云来对加密数据进行直接处理，并将处理结果返回给他。这样一来：</p>
<ul>
<li>用户向云服务商付款，得到了处理的结果；</li>
<li>云服务商挣到了费用，并在不知道用户数据的前提下正确处理了数据；</li>
</ul>
<p>优点：</p>
<ul>
<li>不必对每一个密文解密后再计算而花费高昂的计算代价。</li>
<li>可以实现无密钥方对密文的计算，密文计算无须经过密钥方，既可以减少通信代价，又可以转移计算任务。</li>
<li>第三方为明文未知，提高了信息的安全性。</li>
<li>对密文计算后解密的结果与明文进行同样运算的结果一致，保证了运算的正确性。</li>
</ul>
<p>缺点：</p>
<ul>
<li>同态加密技术目前的难度在于效率,效率一词包含两个方面，一个是加密数据的处理速度，一个是这个加密方案的数据存储量。</li>
<li>满足同态加密的算法并不容易实现。</li>
</ul>
<h3 id="References"><a href="#References" class="headerlink" title="References"></a>References</h3><p>[1] <a href="http://www.vontroy.com/2018/01/25/homomorphic-encryption-survey/" target="_blank" rel="noopener">http://www.vontroy.com/2018/01/25/homomorphic-encryption-survey/</a></p>
<p>[2] <a href="https://zh.wikipedia.org/wiki/同态加密" target="_blank" rel="noopener">https://zh.wikipedia.org/wiki/%E5%90%8C%E6%80%81%E5%8A%A0%E5%AF%86</a></p>
<p>[3] <a href="https://www.zhihu.com/question/27645858/answer/37598506" target="_blank" rel="noopener">https://www.zhihu.com/question/27645858/answer/37598506</a></p>
<blockquote id="fn_cassandra">
<sup>cassandra</sup>. <strong>Apache Cassandra</strong>（社区内一般简称为C*）是一套开源分布式<a href="https://zh.wikipedia.org/wiki/NoSQL" target="_blank" rel="noopener">NoSQL</a>数据库系统。它最初由<a href="https://zh.wikipedia.org/wiki/Facebook" target="_blank" rel="noopener">Facebook</a>开发，用于改善电子邮件系统的搜索性能的简单格式数据，集<a href="https://zh.wikipedia.org/wiki/Google" target="_blank" rel="noopener">Google</a> <a href="https://zh.wikipedia.org/wiki/BigTable" target="_blank" rel="noopener">BigTable</a>的数据模型与<a href="https://zh.wikipedia.org/wiki/Amazon" target="_blank" rel="noopener">Amazon</a> <a href="https://zh.wikipedia.org/w/index.php?title=Dynamo&amp;action=edit&amp;redlink=1" target="_blank" rel="noopener">Dynamo</a>的完全分布式架构于一身。Facebook于2008将 Cassandra 开源，此后，由于Cassandra良好的<a href="https://zh.wikipedia.org/wiki/可扩展性" target="_blank" rel="noopener">可扩展性</a>和性能，被 Apple<a href="https://zh.wikipedia.org/wiki/Cassandra#cite_note-1" target="_blank" rel="noopener">[1]</a>, Comcast<a href="https://zh.wikipedia.org/wiki/Cassandra#cite_note-2" target="_blank" rel="noopener">[2]</a>,Instagram<a href="https://zh.wikipedia.org/wiki/Cassandra#cite_note-3" target="_blank" rel="noopener">[3]</a>, Spotify<a href="https://zh.wikipedia.org/wiki/Cassandra#cite_note-4" target="_blank" rel="noopener">[4]</a>, eBay<a href="https://zh.wikipedia.org/wiki/Cassandra#cite_note-5" target="_blank" rel="noopener">[5]</a>, Rackspace<a href="https://zh.wikipedia.org/wiki/Cassandra#cite_note-6" target="_blank" rel="noopener">[6]</a>, Netflix<a href="https://zh.wikipedia.org/wiki/Cassandra#cite_note-7" target="_blank" rel="noopener">[7]</a>等知名网站所采用，成为了一种流行的分布式结构化数据存储方案。<a href="#reffn_cassandra" title="Jump back to footnote [cassandra] in the text."> ↩</a>
</blockquote>
<blockquote id="fn_describe">
<sup>describe</sup>. 加密过程是将明文对等加密，如果明文的长度低于256字节，则扩充为256字节长度之后再对其进行加密，由于本文的思想是对最小时间间隔的数据打包发送至云平台进行存储，因此在此间隔产生的数据大小是固定的，如果采用加密方式，则自然会增加加密的代价。同时传统的秘钥分发方式，解密过程也会有很高的延迟以及较大的IO.<a href="#reffn_describe" title="Jump back to footnote [describe] in the text."> ↩</a>
</blockquote>
]]></content>
      <categories>
        <category>NSDI</category>
      </categories>
      <tags>
        <tag>论文解读</tag>
        <tag>encrypt</tag>
      </tags>
  </entry>
  <entry>
    <title>Xen log 1 服务器部署Debian9+Xen4.11记录</title>
    <url>/2020/07/17/Xen-log-1-%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2Debian9-Xen4-11%E8%AE%B0%E5%BD%95/</url>
    <content><![CDATA[<h3 id="服务器网络部署"><a href="#服务器网络部署" class="headerlink" title="服务器网络部署"></a>服务器网络部署</h3><p>目前遇到的这个问题可能不是普遍试用，但是在操作过程中的确遇到过。</p>
<h4 id="固件问题"><a href="#固件问题" class="headerlink" title="固件问题"></a>固件问题</h4><p><img src="/2020/07/17/Xen-log-1-%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2Debian9-Xen4-11%E8%AE%B0%E5%BD%95/firmwareError.png"></p>
<p><img src="/2020/07/17/Xen-log-1-%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2Debian9-Xen4-11%E8%AE%B0%E5%BD%95/firmwareIP.png"></p>
<p>安装系统或者配置网络时报错：</p>
<pre><code class="lang-shell">some of your hardware needs non-free firmware files to operate.
The missing firmware files are： bnx2/bnx2-mips-09-6.2.1b.fw
</code></pre>
<p><strong>解决方法</strong></p>
<p>在官方公布的固件中找到自己需要的内容 <a href="https://wiki.debian.org/Firmware" target="_blank" rel="noopener">https://wiki.debian.org/Firmware</a></p>
<p><a href="http://cdimage.debian.org/cdimage/unofficial/non-free/firmware/" target="_blank" rel="noopener">http://cdimage.debian.org/cdimage/unofficial/non-free/firmware/</a></p>
<p><strong>ubuntu 下的解决方法</strong></p>
<p><img src="/2020/07/17/Xen-log-1-%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2Debian9-Xen4-11%E8%AE%B0%E5%BD%95/firmwareSolution.png"></p>
<pre><code class="lang-sehll">1. 在USB中创建路径 /lib/firmware/bnx2/,将固件移动到此目录下
2. 如果安装系统是无法发现固件，则先忽略该步骤，安装好系统后再搞
3. ip link set enp3s0f0 up
</code></pre>
<h4 id="网络接口设置"><a href="#网络接口设置" class="headerlink" title="网络接口设置"></a>网络接口设置</h4><p>目前，该服务器预设网络接口4个，但是，仔细查验后发现，只有一个网络接口连接了网线，因此如果没有恰当的设置后，会出现机器ping 不通网络的问题。</p>
<p><strong>解决方法</strong></p>
<p>在安装系统过程中，记录下四个网口的名称，如果安装完系统后，ping网关不成功的话，说明网口设置有问题，需要修改，否则不需要。</p>
<p>网口配置文件 /etc/network/interfaces</p>
<pre><code># The primary network interface
allow-hotplug XXXX
iface XXXX inet static
</code></pre><p>上述的XXXX为目标网口名称，更改为接入网线的口即可</p>
<p>重启，ping网关，如果ping通，则OK</p>
<h4 id="Ping-www-baidu-com"><a href="#Ping-www-baidu-com" class="headerlink" title="Ping www.baidu.com"></a>Ping www.baidu.com</h4><p>测试ping www.baidu.com失败</p>
<p>可能是网关设置问题, /etc/resolv.conf</p>
<pre><code>添加 namesever 8.8.8.8
</code></pre><p>修改完，再测试下，ok</p>
<h3 id="换源"><a href="#换源" class="headerlink" title="换源"></a>换源</h3><p>这里使用合适的国内源，进行挂载</p>
<p>清华源</p>
<pre><code>https://mirrors.tuna.tsinghua.edu.cn/help/debian/
</code></pre><p>修改 /etc/apt/sources.list  </p>
<pre><code>deb http://mirrors.163.com/debian/ stretch main non-free contrib
deb http://mirrors.163.com/debian/ stretch-updates main non-free contrib
deb http://mirrors.163.com/debian/ stretch-backports main non-free contrib
deb-src http://mirrors.163.com/debian/ stretch main non-free contrib
deb-src http://mirrors.163.com/debian/ stretch-updates main non-free contrib
deb-src http://mirrors.163.com/debian/ stretch-backports main non-free contrib
deb http://mirrors.163.com/debian-security/ stretch/updates main non-free contrib
deb-src http://mirrors.163.com/debian-security/ stretch/updates main non-free contrib
</code></pre><p>更新操作</p>
<pre><code>apt update &amp;&amp; apt upgrade
</code></pre><h3 id="部署Xen4-11"><a href="#部署Xen4-11" class="headerlink" title="部署Xen4.11"></a>部署Xen4.11</h3><h4 id="配置依赖环境"><a href="#配置依赖环境" class="headerlink" title="配置依赖环境"></a>配置依赖环境</h4><p>install the <em>build-essential</em> package:</p>
<pre><code>apt-get install build-essential
</code></pre><p>install these additional debs:</p>
<pre><code>apt-get install bcc bin86 gawk bridge-utils iproute libcurl3 libcurl4-openssl-dev bzip2 transfig tgif 
apt-get install texinfo texlive-latex-base texlive-latex-recommended texlive-fonts-extra texlive-fonts-recommended pciutils-dev mercurial
apt-get install make gcc libc6-dev zlib1g-dev python python-dev python-twisted libncurses5-dev patch libvncserver-dev libsdl-dev 
apt-get install iasl libbz2-dev e2fslibs-dev git-core uuid-dev ocaml ocaml-findlib libx11-dev bison flex xz-utils libyajl-dev
apt-get install gettext libpixman-1-dev libaio-dev markdown pandoc
</code></pre><p>under Debian :</p>
<pre><code>apt-get build-dep xen
</code></pre><p>failed to install (不安装的话，暂时没啥影响)</p>
<pre><code># apt-get module-init-tools libjpeg62-dev
</code></pre><h4 id="下载Xen"><a href="#下载Xen" class="headerlink" title="下载Xen"></a>下载Xen</h4><pre><code>git clone git://xenbits.xen.org/xen.git
</code></pre><p>or </p>
<pre><code>git clone -b stable-4.11 git://xenbits.xen.org/xen.git
</code></pre><h4 id="安装Xen"><a href="#安装Xen" class="headerlink" title="安装Xen"></a>安装Xen</h4><pre><code>cd xen
./configure
make xen -j8
make tools -j8
make install-xen
make install-tools
# dpkg-divert --divert /etc/grub.d/08_linux_xen --rename /etc/grub.d/20_linux_xen (这句没执行)
</code></pre><p>更新grub (此时重启电脑会出现 xen hypervisor 信息)</p>
<pre><code>update-grub
</code></pre><p>此时，开机时应当记录下机器默认的开机顺序，方便后续设置系统重启进入带有hypervisor的系统</p>
<h3 id="开启服务"><a href="#开启服务" class="headerlink" title="开启服务"></a>开启服务</h3><pre><code>sudo service xendomains start
sudo service xencommons start or restart
sudo update-rc.d xencommons defaults 19 18
sudo update-rc.d xendomains defaults 21 20
ldconfig
</code></pre><h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><pre><code>xl list 或 xentop
</code></pre><p>当出现 domain0 信息说明部署成功</p>
<h3 id="再次设置-grub"><a href="#再次设置-grub" class="headerlink" title="再次设置 grub"></a>再次设置 grub</h3><p>根据首次重启后开机顺序，确定xen hypervisor的启动序号 n</p>
<p>注意，序号从0开始计数，记录从上到下应当为0,1,2，$\cdots$</p>
<pre><code>进入 /etc/default/grub 文件
更改 GRUB_DEFAULT = x 为 GRUB_DEFAULT = n
更新内容
update-grub
reboot
</code></pre><hr>
<p>此文档记录了在集群上部署xen的方法，目的是为后面的分布式检测做准备。</p>
]]></content>
      <tags>
        <tag>Linux</tag>
        <tag>Debian</tag>
        <tag>Xen log</tag>
      </tags>
  </entry>
  <entry>
    <title>Xen log 0 Ubuntu18源码安装Xen4.11</title>
    <url>/2020/05/22/Xen-log-0-Ubuntu18%E6%BA%90%E7%A0%81%E5%AE%89%E8%A3%85Xen4-11/</url>
    <content><![CDATA[<p>在部署Xen的时候采用的是Ubuntu18.04(英文版) + Xen4.11</p>
<p>由于安装Ubuntu后，使用国外的源比较慢，修改为国内源，这样速度快很多。</p>
<h3 id="Ubuntu换源"><a href="#Ubuntu换源" class="headerlink" title="Ubuntu换源"></a>Ubuntu换源</h3><p>我采用的是修改阿里源为Ubuntu18.04的源</p>
<p><strong>备份 sources.list</strong></p>
<pre><code>cp /etc/apt/sources.list /etc/apt/sources.list.bak
</code></pre><p><strong>添加阿里源(ubuntu-18.04)</strong></p>
<p>在<strong>/etc/apt/sources.list</strong>文件前添加如下条目</p>
<pre><code>deb http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiverse
deb http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiverse
deb http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiverse
deb http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiverse
deb http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse
deb-src http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiverse
deb-src http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiverse
deb-src http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiverse
deb-src http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiverse
deb-src http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse
</code></pre><p>如需其他系统或其他版本的源，访问<a href="https://mirror.tuna.tsinghua.edu.cn/help/ubuntu/" target="_blank" rel="noopener">清华大学开源软件镜像</a></p>
<p><strong>更新源</strong></p>
<pre><code>sudo apt-get update
sudo apt-get upgrade
</code></pre><h3 id="安装依赖包"><a href="#安装依赖包" class="headerlink" title="安装依赖包"></a>安装依赖包</h3><p><strong>For Ubuntu 18.04:</strong></p>
<pre><code class="lang-sh">apt-get install build-essential
apt-get install bcc bin86 gawk bridge-utils iproute2 libcurl4 libcurl4-openssl-dev bzip2 module-init-tools transfig tgif
apt-get install texinfo texlive-latex-base texlive-latex-recommended texlive-fonts-extra texlive-fonts-recommended pciutils-dev mercurial
apt-get install make gcc libc6-dev zlib1g-dev python python-dev python-twisted libncurses5-dev patch libvncserver-dev libsdl-dev libjpeg-dev
apt-get install libnl-route-3-200 libnl-3-dev libnl-cli-3-dev libnl-genl-3-dev libnl-route-3-dev
apt-get install iasl libbz2-dev e2fslibs-dev git-core uuid-dev ocaml ocaml-findlib libx11-dev bison flex xz-utils libyajl-dev
apt-get install gettext libpixman-1-dev libaio-dev markdown pandoc

apt-get install libc6-dev-i386
apt-get install lzma lzma-dev liblzma-dev
apt-get install libsystemd-dev
</code></pre>
<h3 id="下载Xen4-11源码"><a href="#下载Xen4-11源码" class="headerlink" title="下载Xen4.11源码"></a>下载Xen4.11源码</h3><pre><code>git clone git://xenbits.xen.org/xen.git
cd xen
git checkout origin/stable-4.11
</code></pre><p>或者</p>
<pre><code class="lang-sh">git clone -b stable-4.11 git://xenbits.xen.org/xen.git
</code></pre>
<h3 id="Install"><a href="#Install" class="headerlink" title="Install"></a>Install</h3><p>解压之后进入Xen目录下</p>
<pre><code class="lang-sh">./configure --enable-systemd
make dist // 也可以使用 make world(same like make clean &amp;&amp; make dist).
make install
</code></pre>
<p>上两步make过程会等很久(使用 make dist -j8 可以加速，开启8个线程操作)</p>
<p>或者参考Debain下的安装方法</p>
<pre><code class="lang-sh">./confiugre
make xen -j8
make tools -j8
sudo make install-xen
sudo make install-tools
</code></pre>
<p>ps：若在<code>make install</code> 时遇到error，可以先对下面的<code>xen-tools</code> 进行make.</p>
<p><strong>可能会遇到的问题-1</strong></p>
<p>如果遇到error信息如下，预编译器不识别<strong>sizeof</strong> 函数导致</p>
<p><img src="/2020/05/22/Xen-log-0-Ubuntu18%E6%BA%90%E7%A0%81%E5%AE%89%E8%A3%85Xen4-11/1.png" width="500px" height="300px"></p>
<p>解决方法：</p>
<pre><code class="lang-C"> #define BITS_PER_LONG           (sizeof (unsigned long) * BITS_PER_BYTE)
 改成
 #define BITS_PER_LONG           (__SIZEOF_LONG__ * BITS_PER_BYTE)
</code></pre>
<p>解决完问题后，重复安装过程。</p>
<p><strong>可能会遇到的问题-2</strong></p>
<p>在部署了Xen的ubuntu 18.04版本中，重启之后可能会出现 <code>error - can't find command hwmatch</code> 这种错误，修复时需要在<code>/etc/default/grub</code> 文件中添加如下命令，绕过<code>hwmatch</code>：</p>
<p><code>GRUB_GFXPAYLOAD_LINUX=keep</code></p>
<p>其中的如下命令，添加参数：</p>
<p><code>GRUB_TIMEOUT_STYLE=hidden</code></p>
<p><code>GRUB_TIMEOUT=5</code></p>
<h3 id="Post-Install"><a href="#Post-Install" class="headerlink" title="Post-Install"></a>Post-Install</h3><p><strong>Reload dynamic libraries:</strong></p>
<pre><code>/sbin/ldconfig
</code></pre><h3 id="Grube-Settings"><a href="#Grube-Settings" class="headerlink" title="Grube-Settings"></a>Grube-Settings</h3><p>在部署了Xen虚拟机管理器之后，我们需要<strong>切换开机启动顺序</strong>，一般在<code>Ubuntu18</code>或者<code>Debian9</code>上进行实验的话，默认原始系统顺序为0，部署了Xen之后的系统内核启动顺序为2.</p>
<p>位置 <code>/etc/default/grub</code>,将默认的启动顺序设置为2即可 .</p>
<pre><code class="lang-bash">GRUB_DEFAULT=2
GRUB_TIMEOUT_STYLE=hidden
GRUB_TIMEOUT=0
GRUB_DISTRIBUTOR=`lsb_release -i -s 2&gt; /dev/null || echo Debian`
GRUB_CMDLINE_LINUX_DEFAULT="debian-installer/custom-installation=/custom find_preseed=/preseed.cfg auto pr$
GRUB_CMDLINE_LINUX=""
</code></pre>
<p><strong>Update grub:</strong></p>
<pre><code>update-grub
</code></pre><p><strong>删除xendomains</strong></p>
<p>当前版本有一个小bug，需要删除一个xendomains文件</p>
<pre><code>rm /etc/init.d/xendomains
</code></pre><p>注意：此时可以跳过Xen-tools的安装步骤，直接开启Xen Services，如果在重启之后出现了安装成功的标志，则不需要进行Xen-tools的安装，否则需要在Ubuntu系统中按顺序进行下述操作。</p>
<h3 id="安装-xen-tools"><a href="#安装-xen-tools" class="headerlink" title="安装 xen-tools"></a>安装 xen-tools</h3><pre><code>apt install lvm2 debootstrap libconfig-inifiles-perl libdata-validate-domain-perl libdata-validate-ip-perl libdata-validate-uri-perl libfile-slurp-perl libfile-which-perl libsort-versions-perl libterm-ui-perl libtext-template-perl openssh-client perl debian-archive-keyring rinse libtest-notabs-perl
</code></pre><h4 id="Download-and-make"><a href="#Download-and-make" class="headerlink" title="Download and make"></a>Download and make</h4><p>(最好是放在Xen目录下)</p>
<pre><code>git clone https://github.com/xen-tools/xen-tools.git
cd xen-tools
make install
</code></pre><h3 id="开启xen-services"><a href="#开启xen-services" class="headerlink" title="开启xen services"></a>开启xen services</h3><pre><code>systemctl enable xen-qemu-dom0-disk-backend.service
systemctl enable xen-init-dom0.service
systemctl enable xenconsoled.service
systemctl enable xenstored.service
systemctl enable xendomains.service
systemctl enable xen-watchdog.service
</code></pre><h3 id="Reboot"><a href="#Reboot" class="headerlink" title="Reboot"></a>Reboot</h3><p>重启选择带有xen-hypervisor 4.11 启动</p>
<p><strong>安装成功与否测试</strong></p>
<pre><code>xentop
</code></pre><p>如果出现下图的domain0则说明安装成功</p>
<p><img src="/2020/05/22/Xen-log-0-Ubuntu18%E6%BA%90%E7%A0%81%E5%AE%89%E8%A3%85Xen4-11/2.jpg" width="500px" height="100px"></p>
<h3 id="References"><a href="#References" class="headerlink" title="References"></a>References</h3><p>[1] <a href="www.baudi.com">Build Xen for ubuntu</a></p>
<p>[2] <a href="https://wiki.xenproject.org/wiki/Compiling_Xen_From_Source" target="_blank" rel="noopener">Compiling Xen From Source</a></p>
<p>[3] <a href="https://www.linuxidc.com/Linux/2018-08/153709.htm" target="_blank" rel="noopener">Ubuntu 18.04修改默认源为国内源</a></p>
<p>[4] <a href="https://blog.csdn.net/FJDJFKDJFKDJFKD/article/details/105982709" target="_blank" rel="noopener">qemu 安装  error</a></p>
]]></content>
      <tags>
        <tag>Xen log</tag>
        <tag>虚拟机</tag>
      </tags>
  </entry>
  <entry>
    <title>Xen log 3 Using Serial Debug Xen</title>
    <url>/2020/10/09/Xen-log-3-Using-Serial-Debug-Xen/</url>
    <content><![CDATA[<p>注：本文的配置是在<a href="https://wiki.xenproject.org/wiki/Xen_Serial_Console" target="_blank" rel="noopener">官网</a>指导下进行的，因为在配置过程中遇到一点问题，记录下配置过程。</p>
<p>Xen的log信息是打印在内存中的，读取打印信息需要<code>xl dm</code> 进行查看，如果在查看之前xen崩溃的话，是读取不到任何信息的，通过串口的方式可以将数据实时的打印出来，方便调试。</p>
<p>这里使用的是usb转rs232.</p>
<h3 id="配置读取设备"><a href="#配置读取设备" class="headerlink" title="配置读取设备"></a>配置读取设备</h3><p>在读取设备和Xen机器上配置<code>minicom</code> 用于测试串口。</p>
<pre><code class="lang-sh">Ubuntu dmesg | grep tty
</code></pre>
<p>输出信息如下</p>
<pre><code class="lang-sh">[    0.094791] printk: console [tty0] enabled
[    0.757835] 00:02: ttyS0 at I/O 0x3f8 (irq = 4, base_baud = 115200) is a 16550A
[    0.779505] 0000:00:16.3: ttyS4 at I/O 0xf060 (irq = 19, base_baud = 115200) is a 16550A
[    2.825408] usb 1-13: pl2303 converter now attached to ttyUSB0
[ 3435.257916] pl2303 ttyUSB0: pl2303 converter now disconnected from ttyUSB0
[ 3437.386713] usb 1-14: pl2303 converter now attached to ttyUSB0
[13860.597447] pl2303 ttyUSB0: pl2303_set_control_lines - failed: -19
[13860.597451] pl2303 ttyUSB0: error sending break = -19
[13860.597584] pl2303 ttyUSB0: pl2303 converter now disconnected from ttyUSB0
[13863.385826] usb 1-8: pl2303 converter now attached to ttyUSB0
</code></pre>
<p>于是设置默认串口为 <code>ttyUSB0</code> ,使用<code>minicom -s</code> 进入<code>serial prot setup</code> 进行设置</p>
<p><img src="/2020/10/09/Xen-log-3-Using-Serial-Debug-Xen/xen-3.png" width="500px" height="300px"> </p>
<p>(配置完没有截图，取自 [2] )，配置好读取设备后，静置，备用。</p>
<h3 id="配置Xen-设备"><a href="#配置Xen-设备" class="headerlink" title="配置Xen 设备"></a>配置Xen 设备</h3><p>读取Xen设备信息</p>
<pre><code class="lang-sh">dmesg | grep tty
</code></pre>
<p>输出信息</p>
<pre><code class="lang-sh">console [tty0] enabled
ttyS0 at I/O 0x3f8 (irq = 4, base_baud = 115200) is a 16550A
ttyS4 at I/O 0xc0c0 (irq = 16, base_baud = 115200) is a XR16850
ttyS5 at I/O 0xc0c8 (irq = 16, base_baud = 115200) is a XR16850
</code></pre>
<p>这里看到 tty0 、ttyS0  、 ttyS4 、ttyS5 （如果没有输出全部信息的话，执行下面的命令查看）</p>
<pre><code class="lang-sh">cat /proc/tty/driver/serial
</code></pre>
<p>输出信息</p>
<pre><code class="lang-sh">serinfo:1.0 driver revision:
0: uart:16550A port:000003F8 irq:4 tx:0 rx:0
1: uart:unknown port:000002F8 irq:3
2: uart:unknown port:000003E8 irq:4
3: uart:unknown port:000002E8 irq:3
4: uart:XR16850 port:0000C0C0 irq:16 tx:0 rx:0
5: uart:XR16850 port:0000C0C8 irq:16 tx:0 rx:0 CTS|DTR|DSR|CD|RI
</code></pre>
<p>可以确定，Xen设备的串口是<code>ttyS5</code> 物理地址为 <code>0xc0c8</code> </p>
<h4 id="测试串口通讯情况"><a href="#测试串口通讯情况" class="headerlink" title="测试串口通讯情况"></a>测试串口通讯情况</h4><p>在Xen设备的<code>minicom</code> 上设置默认的端口为<code>ttyS5</code> 看两台机器是否能够正常通讯，即，在读取设备输入，在Xen设备上可以输出相应内容，反之亦然。</p>
<h4 id="修改Grub文件"><a href="#修改Grub文件" class="headerlink" title="修改Grub文件"></a>修改Grub文件</h4><p>在<code>/etc/default/grub</code>文件中 添加如下内容</p>
<pre><code class="lang-sh"># This can guarantee sync output when using `printk`
GRUB_CMDLINE_XEN="loglvl=all guest_loglvl=all sync_console console_to_ring com1=115200,8n1,0x3080 console=com1,vga com0_mem=4096"

GRUB_CMDLINE_LINUX_DEFAULT="console=tty0 console=ttyS5,115200n8"
GRUB_CMDLINE_LINUX="console=hvc0 earlyprintk=xen"
</code></pre>
<ul>
<li><code>sync_console</code>: 保证输出是同步的，以防一些内容在xen crash之前打不出来</li>
<li><code>console_to_ring</code>: 将Guest的log同步到dom0中打印输出.</li>
<li><code>console=com1,vga</code>: 将终端连到com1上，这样我们就可以通过串口输入用户名密码登陆</li>
</ul>
<p>输入 <code>sudo update-grub</code> 更新grub文件，重启</p>
<h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><p>在自定义<a href="https://ykma.gitee.io/2020/07/19/Xen-log-2-Add-a-new-Hypercall/" target="_blank" rel="noopener">Hypercall</a> 后，执行<code>privcmd.c</code> 文件会在读取设备上看到相应的log信息，这里不放图了。</p>
<h3 id="踩坑指南"><a href="#踩坑指南" class="headerlink" title="踩坑指南"></a>踩坑指南</h3><p>我刚配置串口的时候，采用Ubuntu18读取日志信息，Debian9编译Xen，两台机器通信正常，<code>reboot</code> Xen设备后会打印开机日志，随后便是一通乱码，不输出用户自定义log信息。调整两台设备的编码格式、语言（en.utf-8）等均未果，至今没有解决这个bug</p>
<p>感受一下乱码：分别是正常读取与16进制读取的结果</p>
<pre><code class="lang-sh">�`�f���f�����`�f���f���怀�`�f���f����~x�~~x�~�`�f���f���怀�`�f��~怀

�`�f���f枞f�~x��枘�����f��ff��~��~fx�f��~������~��~��~��fx�

06 fe 60 e6 66 fe 06 f8 00 f8 66 fe 00 f8 e6 80 06 fe 60 e6 66 fe 06 f8 00 f8 6
</code></pre>
<h3 id="References"><a href="#References" class="headerlink" title="References"></a>References</h3><p>[1] <a href="https://wiki.xenproject.org/wiki/Xen_Serial_Console" target="_blank" rel="noopener">https://wiki.xenproject.org/wiki/Xen_Serial_Console</a><br>[2] <a href="** https://silentming.net/blog/2016/09/18/xen-log-5-debug-xen/**">Xen Log 5-Debug Xen on Physical Machine</a><br>[3] <a href="https://xenbits.xen.org/docs/unstable/misc/xen-command-line.html" target="_blank" rel="noopener">https://xenbits.xen.org/docs/unstable/misc/xen-command-line.html</a></p>
]]></content>
      <tags>
        <tag>Virtualization</tag>
        <tag>Linux</tag>
        <tag>Xen log</tag>
      </tags>
  </entry>
  <entry>
    <title>Xen-log-Extend-SPECCPU2006安装与运行</title>
    <url>/2020/12/16/Xen-log-Extend-SPECCPU2006%E5%AE%89%E8%A3%85%E4%B8%8E%E8%BF%90%E8%A1%8C/</url>
    <content><![CDATA[<h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><h4 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h4><p>本文描述在<code>Debain9</code>上安装<code>speccpu2006</code>的实验记录</p>
<p><code>gcc version 6.3.0 20170516 (Debian 6.3.0-18+deb9u1)</code></p>
<h4 id="speccpu6"><a href="#speccpu6" class="headerlink" title="speccpu6"></a>speccpu6</h4><p>新建文件夹，保存镜像<code>speccpu2006v1.0.1.iso</code>内容</p>
<pre><code class="lang-shell">mkdir speccpu          # 保存iso镜像内容
mkdir speccpu2006      # speccpu安装位置
sudo mount ./speccpu2006v1.0.1.iso ./speccpu/
cd ./speccpu/
</code></pre>
<p>当前目录结构</p>
<pre><code class="lang-shell">.
|-- speccpu       # 镜像文件保存位置
|-- speccpu2006   # 安装位置
</code></pre>
<p><strong>下面开始安装</strong></p>
<p>输入如下命令</p>
<pre><code class="lang-shell">sudo ./install.sh
</code></pre>
<p>并按照log提示进行操作输入如下命令</p>
<pre><code class="lang-shell">linux-suse101-AMD64
./speccpu2006
</code></pre>
<p>等待执行结束，进入<code>speccpu2006</code>目录准备安装<code>tools</code></p>
<h4 id="tools"><a href="#tools" class="headerlink" title="tools"></a>tools</h4><p>进入<code>./specspu2006/tools/src/</code></p>
<p>执行<code>PERLFLAGS="-A libs=-lm -A libs=-ldl" ./buildtools</code></p>
<p>可能会遇到的问题</p>
<ul>
<li><p>错误1: <code>error building specmd5sum</code></p>
</li>
<li><p>注释<code>specmd5sum/md5sum.c</code>的第38行</p>
</li>
</ul>
<ul>
<li><p>错误2: <code>error in tool/perl SysV.xs: asm/page.h :No such file or directory</code></p>
</li>
<li><p>注释掉 <code>perl-5.8.7/ext/IPC/SysV/SysV.xs</code> 中 <code>include &lt;asm/page.h&gt;</code></p>
</li>
<li><p>文件<code>perl-5.8.7/makedepend.SH</code> 中 <code>&lt;command line&gt;</code>改为<code>&lt;command-line&gt;</code></p>
</li>
</ul>
<p><img src="/2020/12/16/Xen-log-Extend-SPECCPU2006%E5%AE%89%E8%A3%85%E4%B8%8E%E8%BF%90%E8%A1%8C/command.png" width="600"></p>
<ul>
<li><p>错误4: <code>relocation R_X86_64_32S against '.rodata'....-fPIC</code></p>
<p><img src="/2020/12/16/Xen-log-Extend-SPECCPU2006%E5%AE%89%E8%A3%85%E4%B8%8E%E8%BF%90%E8%A1%8C/relocation.png" width="600"></p>
</li>
<li><p>解决: 在<code>buildtools</code>对应命令位置添加 <code>-fPIC</code></p>
<p><img src="/2020/12/16/Xen-log-Extend-SPECCPU2006%E5%AE%89%E8%A3%85%E4%B8%8E%E8%BF%90%E8%A1%8C/relocation-su.png" width="600"></p>
</li>
</ul>
<ul>
<li><p>错误5: 缺少数学库</p>
<p><img src="/2020/12/16/Xen-log-Extend-SPECCPU2006%E5%AE%89%E8%A3%85%E4%B8%8E%E8%BF%90%E8%A1%8C/lack-mathlib.png" width="600"></p>
</li>
<li><p>解决：添加 <code>-Dcc="gcc -lm"</code></p>
<p><img src="/2020/12/16/Xen-log-Extend-SPECCPU2006%E5%AE%89%E8%A3%85%E4%B8%8E%E8%BF%90%E8%A1%8C/lm-math.png" width="600"></p>
</li>
<li><p>错误6: <code>You haven't done a "make depend" yet!</code></p>
<p><img src="/2020/12/16/Xen-log-Extend-SPECCPU2006%E5%AE%89%E8%A3%85%E4%B8%8E%E8%BF%90%E8%A1%8C/depend.png" width="600"></p>
</li>
<li><p>解决：</p>
<pre><code class="lang-shell">sudo rm /bin/sh
sudo ln -s /bin/bash /bin/sh
</code></pre>
</li>
</ul>
<p>安装<code>perl</code> 相关库</p>
<p>在<a href="http://www.perl.org/get.html" target="_blank" rel="noopener">官网</a> 下载<code>perl</code>源码包。下载 <strong>perl-5.x.y.tar.gz</strong> 文件后执行以下操作。</p>
<pre><code class="lang-shell">  $ tar -xzf perl-5.x.y.tar.gz
  $ cd perl-5.x.y
  $ ./Configure -de
  $ make
  $ make test
  $ make install
</code></pre>
<p>接下来使用<code>perl -v</code> 查看是否安装成功。</p>
<p>当出现如下<code>successfully</code>关键字时，说明安装成功！</p>
<p><img src="/2020/12/16/Xen-log-Extend-SPECCPU2006%E5%AE%89%E8%A3%85%E4%B8%8E%E8%BF%90%E8%A1%8C/success.png" width="600"></p>
<p>编译成功后，按照提示进入指定目录下并执行 <code>source  ./shrc</code></p>
<h3 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h3><h4 id="安装库"><a href="#安装库" class="headerlink" title="安装库"></a>安装库</h4><pre><code class="lang-shell">gcc g++ gfortran #安装
</code></pre>
<p>更改相关配置的路径</p>
<p><img src="/2020/12/16/Xen-log-Extend-SPECCPU2006%E5%AE%89%E8%A3%85%E4%B8%8E%E8%BF%90%E8%A1%8C/gcc-lib.png" width="600"></p>
<p><img src="/2020/12/16/Xen-log-Extend-SPECCPU2006%E5%AE%89%E8%A3%85%E4%B8%8E%E8%BF%90%E8%A1%8C/gcc-config.png" width="600"></p>
<h4 id="命令分析"><a href="#命令分析" class="headerlink" title="命令分析"></a>命令分析</h4><pre><code class="lang-shell">runspec -c linux64-amd64-gcc42.cfg -i test -I all -nobuild
-nobuild # 如果进行连续测试，则不必进行再次编译，可以加参数
runspec -c linux64-amd64-gcc42.cfg -i ref -n 3 -I all

1. runspec -c linux64-amd64-gcc42.cfg -i test -I all -nobuild
# 基于最小测试数据集快速执行所有的测试，测试过程中如果某个用例发生错误，则跳过错误用例，继续执行其他用例
2. runspec -c linux64-amd64-gcc42.cfg -i ref -n 3 -I all
# 基于最大测试数据集全面执行所有的测试，用于测试单核CPU，测试过程中如果某个用例发生错误，则跳过错误用例，继续执行其他用例 
3. runspec -c linux64-amd64-gcc42.cfg -i ref -n 3 fp
# 基于最大测试数据集，只运行fp测试 
4. runspec -c linux64-amd64-gcc42.cfg -i ref -n 3 int
# 基于最大测试数据集，只运行int测试 
5. runspec -c linux64-amd64-gcc42.cfg -i ref 473.astar
# 基于最大测试数据集只执行473.astar单个测试
6. runspec -c linux64-amd64-gcc42.cfg -i ref --rate 4 int
# 基于最大数据测试集进行rate测试，运行4线程测试的分值
</code></pre>
<p><strong>命令说明</strong></p>
<pre><code class="lang-shell">例如：runspec -c linux-mipsel-gcc -i ref -n 3 all 命令参数说明：

-c: # 读取测试配置文件，linux-mipsel-gcc位于SPEC CPU2006安装目录的config目录下，该文件可以根据实际信息进行修改。其编译选项不建议修改。
-i: # 输入测试数据集的大小，ref代表最大测试数据集，test代表最小测试数据集。
-I:  # 测试过程中如果某个用例发生错误，则跳过错误用例，继续执行其他用例。
-n: # 每个测试项目运行的次数，如果需要SPEC CPU2006自动计算测试分值，需要指定运行次数等于或大于3，即n&gt;=3。
-all:# SPEC CPU2006将运行基准测试程序中的所有测试项目。
-nobuild: # 如果进行连续测试，则不必进行再次编译，可以加参数
</code></pre>
<p><strong>最终执行命令</strong></p>
<pre><code class="lang-shell">runspec -c config.cfg -i ref -l int
runspec -c config.cfg -i ref -l fp
</code></pre>
<h4 id="运行结果"><a href="#运行结果" class="headerlink" title="运行结果"></a>运行结果</h4><p>运行结果显示 invalid， 官方网站给出的解释是:<code>If a run is marked "invalid" because some flags are "unknown"</code></p>
<p><img src="/2020/12/16/Xen-log-Extend-SPECCPU2006%E5%AE%89%E8%A3%85%E4%B8%8E%E8%BF%90%E8%A1%8C/output.png" width="600"></p>
<h3 id="References"><a href="#References" class="headerlink" title="References"></a>References</h3><p>[1] <a href="https://www.spec.org/cpu2006/Docs/install-guide-unix.html" target="_blank" rel="noopener">官方教程</a> </p>
<p>[2] <a href="https://sjp38.github.io/post/spec_cpu2006_install/" target="_blank" rel="noopener">Install / execute spec cpu2006 benchmark</a></p>
<p>[3] <a href="https://note.youdao.com/ynoteshare1/index.html?id=1b691816e6e25bc428792cee2f6896d9&amp;type=note" target="_blank" rel="noopener">师姐教程</a></p>
]]></content>
      <tags>
        <tag>Xen log</tag>
        <tag>SPECCPU2006</tag>
      </tags>
  </entry>
  <entry>
    <title>Xen log modify 脚本简化操作</title>
    <url>/2020/08/05/Xen-log-modify-%E8%84%9A%E6%9C%AC%E7%AE%80%E5%8C%96%E6%93%8D%E4%BD%9C/</url>
    <content><![CDATA[<h3 id="基本命令"><a href="#基本命令" class="headerlink" title="基本命令"></a>基本命令</h3><p>目标用户ID与ip: </p>
<pre><code>root:101.101.101.10
</code></pre><p>第一个脚本文件</p>
<pre><code class="lang-python">#!/bin/bash
scp test.txt root@101.101.101.10:/home/
</code></pre>
<h4 id="执行权限"><a href="#执行权限" class="headerlink" title="执行权限"></a>执行权限</h4><pre><code class="lang-python">chmod +x ./test.sh  #使脚本具有执行权限
./test.sh  #执行脚本
</code></pre>
<h4 id="自动输入密码"><a href="#自动输入密码" class="headerlink" title="自动输入密码"></a>自动输入密码</h4><p>免密登陆</p>
<pre><code>ssh-copy-id -i ~/.ssh/id_rsa.pub user@ip
</code></pre><h4 id="获取当前目录"><a href="#获取当前目录" class="headerlink" title="获取当前目录"></a>获取当前目录</h4><p>获取当前目录</p>
<pre><code class="lang-shell">workdir=$(cd $(dirname $0); pwd)
</code></pre>
<h3 id="修改文件实战"><a href="#修改文件实战" class="headerlink" title="修改文件实战"></a>修改文件实战</h3><h4 id="目录说明"><a href="#目录说明" class="headerlink" title="目录说明"></a>目录说明</h4><blockquote>
<p>脚本所在目录 /xen-modify/</p>
<p>其中 <code>*.sh</code> 文件是要执行的脚本文件，<code>*.c *.h</code> 是在本地（最终文件是要覆盖在服务器上的）修改后的文件。</p>
<p>└──xen<br>└── xen-modify<br>   │    ├── backup.sh<br>   │    ├── hypercall.h<br>   │    ├── install-lib.sh<br>   │    ├── install-xen.sh<br>   │    ├── mm.c<br>   │    ├── move.sh<br>   │    ├── privcmd.c<br>   │    ├── pv<br>   │    │  └── hypercall.c<br>   │    ├── x86<br>   │    │  └── hypercall.c<br>   │    └── xen.h</p>
</blockquote>
<h4 id="backup-sh"><a href="#backup-sh" class="headerlink" title="backup.sh"></a>backup.sh</h4><blockquote>
<p>​        backup的目的是备份即将被修改的文件，目标文件的位置在xen文件夹内，<code>backup.sh</code> 文件在<code>xen-modify</code> 文件夹内，在获得当前目录后，需要依次进入目标文件所在目录，对文件进行备份。<br>​        因为是对原始文件进行备份，所以在执行此操作时，仅在首次备份时执行，以后不执行。</p>
</blockquote>
<pre><code class="lang-shell">workdir=$(cd $(dirname $0); pwd)
cd ${workdir}/../xen/xen/include/public/
cp xen.h xen-backup.h

cd ${workdir}/../xen/xen/arch/x86/
cp hypercall.c hypercall-backup.c

cd ${workdir}/../xen/xen/arch/x86/pv/
cp hypercall.c hypercall-backup.c

cd ${workdir}/../xen/xen/include/xen/
cp hypercall.h hypercall-backup.h

cd ${workdir}/../xen/xen/arch/x86/
cp mm.c mm-backup.c
</code></pre>
<h4 id="install-xen-sh"><a href="#install-xen-sh" class="headerlink" title="install-xen.sh"></a>install-xen.sh</h4><blockquote>
<p>这里只需要进入<code>xen</code> 目录一次就可以进行操作，所以直接使用 <code>cd ../xen</code> 进入目标目录。</p>
<p>这一步是在编译<code>xen</code> 源码的时候进行的。</p>
</blockquote>
<pre><code class="lang-shell">cd ../xen
./configure
make xen -j8
make tools -j8
make install-xen
make install-tools
update-grub
</code></pre>
<h4 id="install-lib-sh"><a href="#install-lib-sh" class="headerlink" title="install-lib.sh"></a>install-lib.sh</h4><blockquote>
<p>搭建 <code>xen</code> 的依赖。</p>
</blockquote>
<pre><code class="lang-shell">apt-get install build-essential -y
apt-get install bcc bin86 gawk bridge-utils iproute libcurl3 libcurl4-openssl-dev bzip2 transfig tgif  -y
apt-get install texinfo texlive-latex-base texlive-latex-recommended texlive-fonts-extra texlive-fonts-recommended pciutils-dev mercurial -y
apt-get install make gcc libc6-dev zlib1g-dev python python-dev python-twisted libncurses5-dev patch libvncserver-dev libsdl-dev -y
apt-get install iasl libbz2-dev e2fslibs-dev git-core uuid-dev ocaml ocaml-findlib libx11-dev bison flex xz-utils libyajl-dev -y
apt-get install gettext libpixman-1-dev libaio-dev markdown pandoc -y
apt-get build-dep xen -y
</code></pre>
<h4 id="move-sh"><a href="#move-sh" class="headerlink" title="move.sh"></a>move.sh</h4><blockquote>
<p>将<code>xen-modify</code> 文件夹下的文件依次覆盖原始文件。</p>
</blockquote>
<pre><code class="lang-shell">workdir=$(cd $(dirname $0); pwd)

cp xen.h /${workdir}/../xen/xen/include/public/
cp x86/hypercall.c /${workdir}/../xen/xen/arch/x86/
cp pv/hypercall.c /${workdir}/../xen/xen/arch/x86/pv/
cp hypercall.h /${workdir}/../xen/xen/include/xen/
cp mm.c /${workdir}/../xen/xen/arch/x86/
</code></pre>
<hr>
<p>modify log</p>
<p>​    2020年8月5日      创建<br>​    2020年9月30日    增加<code>xen</code> 的脚本命令</p>
]]></content>
      <tags>
        <tag>Linux</tag>
        <tag>Xen log</tag>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title>Xen虚拟化技术完全导读</title>
    <url>/2020/07/19/Xen%E8%99%9A%E6%8B%9F%E5%8C%96%E6%8A%80%E6%9C%AF%E5%AE%8C%E5%85%A8%E5%AF%BC%E8%AF%BB/</url>
    <content><![CDATA[]]></content>
      <tags>
        <tag>TODO</tag>
        <tag>读书笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>Xen log plus Centos7源码安装Xen4.11</title>
    <url>/2020/11/25/Xen-log-plus-Centos7%E6%BA%90%E7%A0%81%E5%AE%89%E8%A3%85Xen4-11/</url>
    <content><![CDATA[<p>​        本文的安装步骤是参照<a href="https://wiki.xenproject.org/wiki/Compiling_Xen_From_Source#Build_Dependencies_-_RHEL_.2F_Centos" target="_blank" rel="noopener">官网</a>指导下进行的，因为实验需要扩展，所以打算在通用的CentOS上对Xen虚拟机进行部署，从而进行下一步实验。由于需要扩展到的主机上运行的服务比较多，为了避免安装失误，因此记录下此步骤进行参考。</p>
<h3 id="CentOS换源-（先不换源试试）"><a href="#CentOS换源-（先不换源试试）" class="headerlink" title="CentOS换源 （先不换源试试）"></a>CentOS换源 （先不换源试试）</h3><p>目前没有执行换源操作 (采用官方源，速度ok)</p>
<h3 id="安装依赖"><a href="#安装依赖" class="headerlink" title="安装依赖"></a>安装依赖</h3><pre><code class="lang-shell">yum groupinstall "Development Tools"

yum install transfig wget tar less texi2html libaio-devel dev86 glibc-devel e2fsprogs-devel gitk mkinitrd iasl xz-devel bzip2-devel
yum install pciutils-libs pciutils-devel SDL-devel libX11-devel gtk2-devel bridge-utils PyXML qemu-common qemu-img mercurial texinfo
yum install libidn-devel yajl yajl-devel ocaml ocaml-findlib ocaml-findlib-devel python-devel uuid-devel libuuid-devel openssl-devel
yum install python-markdown pandoc systemd-devel glibc-devel.i686
</code></pre>
<p>此时缺少必要的安装包，<code>./configure</code>会报错</p>
<p><img src="/2020/11/25/Xen-log-plus-Centos7%E6%BA%90%E7%A0%81%E5%AE%89%E8%A3%85Xen4-11/checkerror.png"></p>
<p>安装 <code>as86</code></p>
<pre><code class="lang-shell">wget http://mirror.centos.org/centos/6/os/x86_64/Packages/dev86-0.16.17-15.1.el6.x86_64.rpm
rpm -ivh dev86-0.16.17-15.1.el6.x86_64.rpm
</code></pre>
<p>安装完之后会还会报错，需要安装<code>curses</code></p>
<p><img src="/2020/11/25/Xen-log-plus-Centos7%E6%BA%90%E7%A0%81%E5%AE%89%E8%A3%85Xen4-11/checkerror2.png">c</p>
<p>解决办法：</p>
<pre><code class="lang-shell">安装 ncurses-devel ncurses

yum install ncurses-devel ncurses
</code></pre>
<h3 id="源码下载"><a href="#源码下载" class="headerlink" title="源码下载"></a>源码下载</h3><pre><code class="lang-shell">git clone -b stable-4.11 git://xenbits.xen.org/xen.git
</code></pre>
<h3 id="Install"><a href="#Install" class="headerlink" title="Install"></a>Install</h3><pre><code class="lang-shell">./configure 
# ./configure --libdir=/usr/lib
make dist -j
make install (root)
</code></pre>
<h3 id="安装dom0-内核-（4-4之后版本）"><a href="#安装dom0-内核-（4-4之后版本）" class="headerlink" title="安装dom0 内核 （4.4之后版本）"></a>安装dom0 内核 （4.4之后版本）</h3><p>注：这里提供了两种内核的安装步骤，选用一种即可。</p>
<h4 id="更新内核"><a href="#更新内核" class="headerlink" title="更新内核"></a>更新内核</h4><pre><code class="lang-shell">rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org
rpm -Uvh http://www.elrepo.org/elrepo-release-7.0-3.el7.elrepo.noarch.rpm
yum --enablerepo=elrepo-kernel install kernel-lt -y
</code></pre>
<h4 id="配置grub"><a href="#配置grub" class="headerlink" title="配置grub"></a>配置grub</h4><pre><code class="lang-shell">grub2-mkconfig -o /etc/grub2.cfg
reboot
</code></pre>
<h3 id="安装-dom0内核-（4-4之前版本）"><a href="#安装-dom0内核-（4-4之前版本）" class="headerlink" title="安装 dom0内核 （4.4之前版本）"></a>安装 dom0内核 （4.4之前版本）</h3><h4 id="下载-Linux-内核源码"><a href="#下载-Linux-内核源码" class="headerlink" title="下载 Linux 内核源码"></a>下载 Linux 内核源码</h4><pre><code class="lang-shell">wget https://www.kernel.org/pub/linux/kernel/v3.x/linux-3.15.4.tar.xz
tar xf linux-3.15.4.tar.xz
</code></pre>
<h4 id="配置-Dom0-内核、编译、安装"><a href="#配置-Dom0-内核、编译、安装" class="headerlink" title="配置 Dom0 内核、编译、安装"></a>配置 Dom0 内核、编译、安装</h4><pre><code class="lang-shell">make menuconfig 
# 在执行上一步骤后，会出现选择界面，不选择配置，直接保存退出
# 退出后会生成 .config 文件，对此文件进行配置
</code></pre>
<h4 id="配置内核信息"><a href="#配置内核信息" class="headerlink" title="配置内核信息"></a>配置内核信息</h4><pre><code class="lang-shell"># 在配置文件中找到相应的选项，配置为以下内容
CONFIG_X86_IO_APIC=y
CONFIG_ACPI=y
CONFIG_ACPI_PROCFS=y (optional)
CONFIG_XEN_DOM0=y
CONFIG_PCI_XEN=y
CONFIG_XEN_DEV_EVTCHN=y
CONFIG_XENFS=y
CONFIG_XEN_COMPAT_XENFS=y
CONFIG_XEN_SYS_HYPERVISOR=y
CONFIG_XEN_GNTDEV=y
CONFIG_XEN_BACKEND=y
CONFIG_XEN_NETDEV_BACKEND=m
CONFIG_XEN_BLKDEV_BACKEND=m
CONFIG_XEN_PCIDEV_BACKEND=m
CONFIG_XEN_BALLOON=y
CONFIG_XEN_SCRUB_PAGES=y
</code></pre>
<h4 id="编译内核"><a href="#编译内核" class="headerlink" title="编译内核"></a>编译内核</h4><pre><code class="lang-shell">make
make modules

make modules_install
make install
</code></pre>
<h4 id="配置grub-1"><a href="#配置grub-1" class="headerlink" title="配置grub"></a>配置grub</h4><pre><code class="lang-shell">grub2-mkconfig -o /etc/grub2.cfg
</code></pre>
<p><strong>查看</strong> grub2.cfg 相关配置，并把<strong>第一个引导</strong>配置到下面的文件中</p>
<pre><code class="lang-shell">/etc/grub.d/40_custom
</code></pre>
<p>添加修改</p>
<pre><code class="lang-shell">+ multiboot /xen.gz
linux 、linux16 -&gt; module
</code></pre>
<p>修改后的内容</p>
<pre><code class="lang-shell">menuentry 'CentOS Linux (3.15.4) 7 (Core), with Linux 3.15.4 Xen' --class centos --class gnu-linux --class gnu --class os --unrestricted $menuentry_id_option 'gnulinux-3.15.4-advanced-93383681-c2e1-4b56-a8a5-30da87350f60' {
        load_video
        insmod gzio
        insmod part_msdos
        insmod xfs
        set root='hd0,msdos1'
        if [ x$feature_platform_search_hint = xy ]; then
          search --no-floppy --fs-uuid --set=root --hint-bios=hd0,msdos1 --hint-efi=hd0,msdos1 --hint-baremetal=ahci0,msdos1 --hint='hd0,msdos1'  22b31dce-d2b9-4403-9a20-4090f6edc175
        else
          search --no-floppy --fs-uuid --set=root 22b31dce-d2b9-4403-9a20-4090f6edc175
        fi
        multiboot /xen.gz
        module /vmlinuz-3.15.4 root=/dev/mapper/centos-root ro crashkernel=auto spectre_v2=retpoline rd.lvm.lv=centos/root rd.lvm.lv=centos/swap rhgb quiet
        module /initramfs-3.15.4.img
}
</code></pre>
<p>更新grub</p>
<pre><code class="lang-shell">grub2-mkconfig -o /etc/grub2.cfg
reboot
</code></pre>
<h3 id="Post-Install"><a href="#Post-Install" class="headerlink" title="Post-Install"></a>Post-Install</h3><h4 id="挂载-xenfs"><a href="#挂载-xenfs" class="headerlink" title="挂载 xenfs"></a>挂载 xenfs</h4><pre><code class="lang-shell">modprobe xenfs  
mount -t xenfs xenfs /proc/xen 

ls /proc/xen/ # 查看挂载是否成功
# 输出结果
# capabilities  privcmd  xenbus  xsd_kva  xsd_port
</code></pre>
<h4 id="进一步配置"><a href="#进一步配置" class="headerlink" title="进一步配置"></a>进一步配置</h4><pre><code class="lang-shell">ln -s /usr/local/lib/libxentoollog.so.1 libxentoollog.so.1
ln -s /usr/local/lib/libxlutil.so.4.11 libxlutil.so.4.11
ln -s /usr/local/lib/libxlutil.so.4.11.0 libxlutil.so.4.11
ln -s /usr/local/lib/libxlutil.so.4.11.0 libxlutil.so.4.11
ln -s /usr/local/lib/libxlutil.so.4.11.0 libxlutil.so
ln -s /usr/local/lib/libxenlight.so.4.11.0 libxenlight.so.4.11
ln -s /usr/local/lib/libxenlight.so.4.11.0 libxenlight.so
ln -s /usr/local/lib/libxenctrl.so.4.11.0 libxenctrl.so.4.11
ln -s /usr/local/lib/libxenguest.so.4.11.0 libxenguest.so.4.11
ln -s /usr/local/lib/libxenguest.so.4.11.0 libxenguest.so
ln -s /usr/local/lib/libxenevtchn.so.1 libxenevtchn.so
ln -s /usr/local/lib/libxenevtchn.so.1 libxenevtchn.so.1
ln -s /usr/local/lib/libxentoolcore.so.1 libxentoolcore.so.1
ln -s /usr/local/lib/libxengnttab.so.1 libxengnttab.so.1
ln -s /usr/local/lib/libxencall.so.1 libxencall.so.1
ln -s /usr/local/lib/libxenstat.so.0.0 libxenstat.so.0
ln -s /usr/local/lib/libxenstat.so.0.0 libxenstat.so
ln -s /usr/local/lib/libxenstore.so.3.0.3 libxenstore.so.3.0
ln -s /usr/local/lib/libxenstore.so.3.0.3 libxenstore.so
ln -s /usr/local/lib/libxenvchan.so.1.0.0 libxenvchan.so.1.0
ln -s /usr/local/lib/libxenvchan.so.1.0.0 libxenvchan.so
ln -s /usr/local/lib/libblktapctl.so.1.0.0 libblktapctl.so.1.0
ln -s /usr/local/lib/libblktapctl.so.1.0.0 libblktapctl.so
ln -s /usr/local/lib/libxenforeignmemory.so.1 libxenforeignmemory.so.1
ln -s /usr/local/lib/libxendevicemodel.so.1 libxendevicemodel.so.1
</code></pre>
<h4 id="导入动态共享库"><a href="#导入动态共享库" class="headerlink" title="导入动态共享库"></a>导入动态共享库</h4><pre><code class="lang-shell">ldconfig
</code></pre>
<h4 id="开启服务"><a href="#开启服务" class="headerlink" title="开启服务"></a>开启服务</h4><pre><code class="lang-shell">chkconfig xencommons on  
# chkconfig xendomains on  
# chkconfig xen-watchdog on
</code></pre>
<h4 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h4><pre><code class="lang-shell">xl dm
</code></pre>
<p>正常输出xen 信息则配置ok.</p>
<h4 id="配置开机启动项"><a href="#配置开机启动项" class="headerlink" title="配置开机启动项"></a>配置开机启动项</h4><p>设置为开机自动进入编译过Xen的系统中[6]。</p>
<p>在开机页面查看<code>with xen hypervisor</code> 的系统顺序，设置为对应项（从0开始）。</p>
<p><img src="/2020/11/25/Xen-log-plus-Centos7%E6%BA%90%E7%A0%81%E5%AE%89%E8%A3%85Xen4-11/centos-xen.png" height="300"></p>
<p>如上图中<code>CentOs Linux,with Xen hypervisor</code>位于第4项，所以设置参数为4.</p>
<pre><code class="lang-shell">grub2-set-default 4
grub2-editenv list # 查看默认启动顺序
</code></pre>
<p>注：在更改启动顺序之前，记录好默认的顺序。</p>
<h3 id="References"><a href="#References" class="headerlink" title="References"></a>References</h3><p>[1] <a href="https://blog.csdn.net/u011808596/article/details/78176514" target="_blank" rel="noopener">https://blog.csdn.net/u011808596/article/details/78176514</a></p>
<p>[2] <a href="https://www.cnblogs.com/tswcypy/articles/4670374.html" target="_blank" rel="noopener">https://www.cnblogs.com/tswcypy/articles/4670374.html</a></p>
<p>[3] <a href="https://wiki.xenproject.org/wiki/Compiling_Xen_From_Source#Build_Dependencies_-_RHEL_.2F_Centos" target="_blank" rel="noopener">https://wiki.xenproject.org/wiki/Compiling_Xen_From_Source#Build_Dependencies_-_RHEL_.2F_Centos</a></p>
<p>[4] <a href="http://chenbaocheng.com/2015/07/16/在CentOS-7-x上源码安装Xen-4-5/" target="_blank" rel="noopener">http://chenbaocheng.com/2015/07/16/%E5%9C%A8CentOS-7-x%E4%B8%8A%E6%BA%90%E7%A0%81%E5%AE%89%E8%A3%85Xen-4-5/</a></p>
<p>[5] <a href="https://blog.csdn.net/yzy1103203312/article/details/80555484" target="_blank" rel="noopener">https://blog.csdn.net/yzy1103203312/article/details/80555484</a></p>
<p>[6] <a href="https://wiki.centos.org/zh/HowTos/Grub2" target="_blank" rel="noopener">https://wiki.centos.org/zh/HowTos/Grub2</a></p>
]]></content>
      <tags>
        <tag>Linux</tag>
        <tag>Xen log</tag>
        <tag>CentOS</tag>
      </tags>
  </entry>
  <entry>
    <title>dp-01背包问题</title>
    <url>/2021/02/13/dp-01%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<h3 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h3><p>有N件物品和容量为M的背包，给出i件物品的重量以及价值，求解让装入背包的物品重量不超过背包容量且价值最大 。</p>
<p>这种问题的特点是，每种物品只有一种，可以选择放入背包或者不放入背包。</p>
<h3 id="算法核心"><a href="#算法核心" class="headerlink" title="算法核心"></a>算法核心</h3><p>利用二维数组构造状态转移方程</p>
<p><code>f[i][V]=max{f[i-1][V],f[i-1][V-weight[i]]+value[i]}</code></p>
<h3 id="算法演练"><a href="#算法演练" class="headerlink" title="算法演练"></a>算法演练</h3><p><img src="/2021/02/13/dp-01%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98/物资.png" height="200"></p>
<p>在面对三个物品，背包最大容量为4时构造这样一个求解的二维数组</p>
<p><img src="/2021/02/13/dp-01%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98/init.png" height="200"></p>
<p>在仅有吉他时，背包容量从1到4时选取的最优解如下</p>
<p><img src="/2021/02/13/dp-01%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98/init1.png" height="200"></p>
<p>待选物品加入音响之后，可以得到的最优解为</p>
<p><img src="/2021/02/13/dp-01%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98/init2.png" height="200"></p>
<p>其中，比较的公式为</p>
<p><img src="/2021/02/13/dp-01%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98/equation.png" height="150"></p>
<p>则最终依次加入三种物品后的最优解为</p>
<p><img src="/2021/02/13/dp-01%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98/3个.png" height="200"></p>
<p>遍历选择顺序的代码为</p>
<pre><code class="lang-c">    int j = M;
    int x[Maxsize] = {0};

    for (int i = N; i &gt; 0; --i) {
        if (f[i][j] &gt; f[i-1][j]){ // 比较最新物品是否加入背包
            x[i-1] = 1;
            j = j - w[i-1];
        }
    }
</code></pre>
<h3 id="coding"><a href="#coding" class="headerlink" title="coding"></a>coding</h3><pre><code class="lang-c">#include &lt;stdio.h&gt;

#define Maxsize 4+1
#define M 3+2
#define N 4+1
#define max(x,y) (x)&gt;(y)?(x):(y)

int weight[Maxsize] = {0,1,4,3,1};
int value[Maxsize] = {0,1500,3000,2000,2000};

void traverse(int f[M][N]); // 遍历最终的最优价值矩阵
void traverse_w_v(int w[Maxsize], int v[Maxsize]);  // 遍历价值与重量
void choose(int f[M][N], int w[Maxsize], int v[Maxsize]);  // 选择最优价值
void choose_order(int f[M][N], int w[Maxsize], int v[Maxsize]);  // 选择物品序号

int main(void) {

    int f[M][N] = {0};
    traverse_w_v(weight,value);
    choose(f, weight, value);
    choose_order(f, weight, value);
    traverse(f);

    return 0;
}

void traverse(int f[M][N])
{
    for (int i = 1; i &lt; M; ++i) {
        for (int j = 1; j &lt; N; ++j) {
            printf("%d ",f[i][j]);
        }
        printf("\n");
    }

    return;
}

void traverse_w_v(int w[Maxsize],int v[Maxsize])  // 遍历价值与重量
{
    for (int i = 1; i &lt; Maxsize; ++i) {
        printf("w[%d] = %d, v[%d] = %d\n", i,w[i],i,v[i]);
    }

    return;
}

void choose(int f[M][N], int w[Maxsize], int v[Maxsize])  // 选择最优价值
{
    for (int i = 1; i &lt; M; ++i) {
        for (int j = 1; j &lt; N; ++j) {
            if (j &gt;= w[i]){  // 比较当前物品的重量和背包能装入的最大重量
               f[i][j] = max(f[i-1][j],v[i]+f[i-1][j-w[i]]);
            }
            else{
                f[i][j] = f[i-1][j];
            }
        }
    }

    return;
}

void choose_order(int f[M][N], int w[Maxsize], int v[Maxsize])  // 选择物品序号
{
    int j = M;
    int x[Maxsize] = {0};

    for (int i = N; i &gt; 0; --i) {
        if (f[i][j] &gt; f[i-1][j]){
            x[i-1] = 1;
            j = j - w[i-1];
        }
    }

    for (int i = 1; i &lt; N; ++i) {
        if (x[i] == 1){
            printf("%d ",i);
            printf("%d\n",v[i]);
        }
    }

    return;
}
</code></pre>
<h3 id="References"><a href="#References" class="headerlink" title="References"></a>References</h3><p><a href="https://blog.csdn.net/qq_39630587/article/details/77535557?utm_medium=distribute.pc_relevant.none-task-blog-baidujs_baidulandingword-2&amp;spm=1001.2101.3001.4242" target="_blank" rel="noopener">动态规划之背包问题（C语言）</a></p>
<p><a href="https://www.cnblogs.com/mfrank/p/10849505.html" target="_blank" rel="noopener">动态规划-背包问题</a></p>
]]></content>
      <tags>
        <tag>算法</tag>
        <tag>dp</tag>
      </tags>
  </entry>
  <entry>
    <title>m1racles</title>
    <url>/2021/05/31/m1racles/</url>
    <content><![CDATA[<h2 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h2><ol>
<li>调研一下M1芯片漏洞；</li>
<li>以及幽灵漏洞，熔断漏洞</li>
</ol>
<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><p>[1] <a href="https://m1racles.com/" target="_blank" rel="noopener">https://m1racles.com/</a></p>
]]></content>
      <tags>
        <tag>TODO</tag>
        <tag>漏洞分析</tag>
      </tags>
  </entry>
  <entry>
    <title>Xen log 2 Add a new Hypercall</title>
    <url>/2020/07/19/Xen-log-2-Add-a-new-Hypercall/</url>
    <content><![CDATA[<p>当前使用的xen版本为Xen-4.11</p>
<h2 id="修改Xen文件"><a href="#修改Xen文件" class="headerlink" title="修改Xen文件"></a>修改Xen文件</h2><p>在Xen-4.11中，仅对hypercall.c hypercall.h文件进行修改即可实现用户添加hypercall</p>
<p>当前xen源码的顶级目录为Xen</p>
<h3 id="修改xen-h"><a href="#修改xen-h" class="headerlink" title="修改xen.h"></a>修改xen.h</h3><p>目标文件位置</p>
<pre><code class="lang-bash">Xen/xen/include/public/xen.h
</code></pre>
<p>39号调用是给用户预留的，可以使用自己的hypercall替换掉预定义hypercall</p>
<pre><code class="lang-bash">  #define __HYPERVISOR_tmem_op                 38
+ #define __HYPERVISOR_Alice_op                39
</code></pre>
<h3 id="修改hypercall-h"><a href="#修改hypercall-h" class="headerlink" title="修改hypercall.h"></a>修改hypercall.h</h3><p>目标文件位置</p>
<pre><code class="lang-bash">Xen/xen/include/xen/hypercall.h
</code></pre>
<p>添加内容</p>
<pre><code class="lang-bash">+ extern int
  do_Alice_op(void);
</code></pre>
<h3 id="修改hypercall-c"><a href="#修改hypercall-c" class="headerlink" title="修改hypercall.c"></a>修改hypercall.c</h3><p>目标文件位置</p>
<pre><code class="lang-bash">Xen/xen/arch/x86/pv/hypercall.c
</code></pre>
<p>添加内容</p>
<pre><code class="lang-bash">  COMPAT_CALL(callback_op),
+ HYPERCALL(Alice_op),
</code></pre>
<p>目标文件位置</p>
<pre><code class="lang-bash">Xen/xen/arch/x86/hypercall.c
</code></pre>
<p>添加内容</p>
<pre><code class="lang-bash">  ARGS(arcg_1, 1),
+ ARGS(Alice_op, 0), // 这里0 对应do_Alice_op(void) 函数中参数个数
</code></pre>
<h2 id="函数实现"><a href="#函数实现" class="headerlink" title="函数实现"></a>函数实现</h2><p>hypercal如果是共用功能的话，可以放在 Xen/xen/common 下的函数中实现</p>
<p>为了打印输出方便，测试函数放在了mm.c中实现</p>
<p>目标文件位置</p>
<pre><code class="lang-bash">Xen/xen/arch/x86/mm.c
</code></pre>
<p>添加内容</p>
<pre><code class="lang-c">+ int do_Alice_op(void)
  {
      printk("Alice Hypercall!\n");
    return 0;
  }
</code></pre>
<h2 id="重新编译xen"><a href="#重新编译xen" class="headerlink" title="重新编译xen"></a>重新编译xen</h2><pre><code class="lang-bash">make xen -j8
make tools -j8
make install-xen
make install-tools
update-grub
reboot
</code></pre>
<p>重启之后测试下添加的hypercall能不能正常被调用</p>
<p>采用privcmd工具实现</p>
<pre><code class="lang-c">#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt; 
#include &lt;errno.h&gt;
#include &lt;sys/ioctl.h&gt;
#include &lt;linux/types.h&gt;
#include &lt;fcntl.h&gt;
#include &lt;xenctrl.h&gt;
#include &lt;xen/sys/privcmd.h&gt;
#include &lt;string.h&gt;

int main(void)
{
        int fd, ret;
        char * message;
        privcmd_hypercall_t alice_op={
                __HYPERVISOR_Alice_op,
                {0,0,0,0,0}
        };
        fd = open("/proc/xen/privcmd", O_RDWR);
        if(fd&lt;0){
                perror("can't open /proc/xen/privcmd");
                exit(1);
        } else {
                printf("privcmd's fd = %d\n", fd);
        }
        ret = ioctl(fd, IOCTL_PRIVCMD_HYPERCALL, &amp;alice_op);
        printf("ret = %d\n", ret);
        return 0;
}
</code></pre>
<p> 若代码显示不全，参见下图</p>
<p><img src="/2020/07/19/Xen-log-2-Add-a-new-Hypercall/privcmd.jpg"></p>
<p>编译</p>
<pre><code class="lang-bash">gcc -o test privcmd.c
</code></pre>
<p>执行</p>
<pre><code class="lang-bash">./test
</code></pre>
<p>输出结果</p>
<pre><code class="lang-bash">privcmd's fd = 3
ret = 0
</code></pre>
<p>注：如果ioctl()函数返回值为-1，说明出错</p>
<p>查看日志信息</p>
<p>命令</p>
<pre><code class="lang-bash">xl dm
</code></pre>
<p>输出</p>
<pre><code class="lang-bash">(XEN) Bogus DMIBAR 0xfed18001 on 0000:00:00.0
(XEN) Alice Hypercall!
</code></pre>
<p>当看到自定义输出的信息时，说明此hypercall调用正常！</p>
<p>现在，按照此方法就可以调用hypecall了~</p>
]]></content>
      <tags>
        <tag>Virtualization</tag>
        <tag>Hypervisor</tag>
        <tag>Linux</tag>
        <tag>Xen log</tag>
      </tags>
  </entry>
  <entry>
    <title>hypersafe</title>
    <url>/2021/07/02/hypersafe/</url>
    <content><![CDATA[<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">序号</th>
<th style="text-align:left">属性</th>
<th style="text-align:center">内容</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:left">原文PDF</td>
<td style="text-align:center"><a href="https://www.cs.fsu.edu/~zwang/files/oakland10.pdf" target="_blank" rel="noopener">Paper</a></td>
</tr>
<tr>
<td style="text-align:center">2</td>
<td style="text-align:left">作者信息</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">3</td>
<td style="text-align:left">核心内容</td>
<td style="text-align:center">Hypervisor code integrity</td>
</tr>
<tr>
<td style="text-align:center">4</td>
<td style="text-align:left">研究领域</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">5</td>
<td style="text-align:left">全文总览</td>
<td style="text-align:center"></td>
</tr>
</tbody>
</table>
</div>
]]></content>
      <categories>
        <category>Security and Privacy</category>
      </categories>
      <tags>
        <tag>TODO</tag>
        <tag>论文解读</tag>
        <tag>Storage</tag>
      </tags>
  </entry>
  <entry>
    <title>从硬件层认识计算机</title>
    <url>/2020/11/23/%E4%BB%8E%E7%A1%AC%E4%BB%B6%E5%B1%82%E8%AE%A4%E8%AF%86%E8%AE%A1%E7%AE%97%E6%9C%BA/</url>
    <content><![CDATA[]]></content>
      <tags>
        <tag>TODO</tag>
      </tags>
  </entry>
  <entry>
    <title>云虚拟化安全攻防实践</title>
    <url>/2020/07/19/%E4%BA%91%E8%99%9A%E6%8B%9F%E5%8C%96%E5%AE%89%E5%85%A8%E6%94%BB%E9%98%B2%E5%AE%9E%E8%B7%B5/</url>
    <content><![CDATA[<p>写在前面：此次阅读，目的是补充一下对虚拟化安全的了解，可能思考不是很透彻，在此记录一下，方便后面补充学习。</p>
<h3 id="认识-Hypervisor"><a href="#认识-Hypervisor" class="headerlink" title="认识 Hypervisor"></a>认识 Hypervisor</h3><p><a href="https://zh.wikipedia.org/wiki/Hypervisor#类型_I：原生或裸机_hypervisor" target="_blank" rel="noopener">Hypervisor 分类</a></p>
<h4 id="云计算起源"><a href="#云计算起源" class="headerlink" title="云计算起源"></a>云计算起源</h4><h4 id="基础概念"><a href="#基础概念" class="headerlink" title="基础概念"></a>基础概念</h4><h4 id="Hypervisor-分类"><a href="#Hypervisor-分类" class="headerlink" title="Hypervisor 分类"></a>Hypervisor 分类</h4><h4 id="虚拟化技术"><a href="#虚拟化技术" class="headerlink" title="虚拟化技术"></a>虚拟化技术</h4><h3 id="Docker-容器安全"><a href="#Docker-容器安全" class="headerlink" title="Docker 容器安全"></a>Docker 容器安全</h3><h3 id="QEMU-与-KVM-安全"><a href="#QEMU-与-KVM-安全" class="headerlink" title="QEMU 与 KVM 安全"></a>QEMU 与 KVM 安全</h3><h3 id="Xen-安全"><a href="#Xen-安全" class="headerlink" title="Xen 安全"></a>Xen 安全</h3><h3 id="Hyper-v-安全"><a href="#Hyper-v-安全" class="headerlink" title="Hyper-v 安全"></a>Hyper-v 安全</h3><h3 id="Hypervisor-漏洞防御技术"><a href="#Hypervisor-漏洞防御技术" class="headerlink" title="Hypervisor 漏洞防御技术"></a>Hypervisor 漏洞防御技术</h3>]]></content>
      <tags>
        <tag>TODO</tag>
        <tag>读书笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>内嵌汇编学习</title>
    <url>/2020/11/30/%E5%86%85%E5%B5%8C%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[]]></content>
      <tags>
        <tag>TODO</tag>
      </tags>
  </entry>
  <entry>
    <title>Untrusted Hypervisor AMD Memory Encryption</title>
    <url>/2021/01/11/Untrusted-Hypervisor-AMD-Memory-Encryption/</url>
    <content><![CDATA[<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">序号</th>
<th style="text-align:center">属性</th>
<th style="text-align:center">内容</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">原文PDF</td>
<td style="text-align:center"><a href="https://ipads.se.sjtu.edu.cn/_media/publications/fidelius_hpca18.pdf" target="_blank" rel="noopener">Fidelius</a></td>
</tr>
<tr>
<td style="text-align:center">2</td>
<td style="text-align:center">作者信息</td>
<td style="text-align:center"><a href="https://ipads.se.sjtu.edu.cn/" target="_blank" rel="noopener">IPADS</a></td>
</tr>
<tr>
<td style="text-align:center">3</td>
<td style="text-align:center">核心内容</td>
<td style="text-align:center">在非可信的Hypervisor上通过加密内存对VM进行保护</td>
</tr>
<tr>
<td style="text-align:center">4</td>
<td style="text-align:center">研究领域</td>
<td style="text-align:center">系统安全</td>
</tr>
<tr>
<td style="text-align:center">5</td>
<td style="text-align:center">全文总览</td>
<td style="text-align:center">本文提出了系统Fidelius，该系统利用AMD硬件特性，在非可信Hypervisor上对内存进行加密处理，从而对客户机提供保护</td>
</tr>
</tbody>
</table>
</div>
]]></content>
      <categories>
        <category>HPCA</category>
      </categories>
      <tags>
        <tag>TODO</tag>
        <tag>论文解读</tag>
        <tag>Untrusted Hypervisor</tag>
        <tag>Virtualization</tag>
      </tags>
  </entry>
  <entry>
    <title>RAMBleed Reading Bits in Memory Without Accessing Them</title>
    <url>/2020/06/15/%C2%96%C2%96RAMBleed-Reading-Bits-in-Memory-Without-Accessing-Them/</url>
    <content><![CDATA[<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">序号</th>
<th style="text-align:center">属性</th>
<th style="text-align:center">内容</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">原文PDF</td>
<td style="text-align:center"><a href="https://rambleed.com/docs/20190603-rambleed-web.pdf" target="_blank" rel="noopener">RAMBleed Reading Bits in Memory Without Accessing Them</a></td>
</tr>
<tr>
<td style="text-align:center">2</td>
<td style="text-align:center">作者信息</td>
<td style="text-align:center">University of Michigan;Graz University of Technology;University of Adelaide and Data61</td>
</tr>
<tr>
<td style="text-align:center">3</td>
<td style="text-align:center">核心内容</td>
<td style="text-align:center">Rowhammer attack,Bit Flips</td>
</tr>
<tr>
<td style="text-align:center">4</td>
<td style="text-align:center">研究领域</td>
<td style="text-align:center">Microarchitecture attacks</td>
</tr>
<tr>
<td style="text-align:center">5</td>
<td style="text-align:center">全文总览</td>
<td style="text-align:center">本文利用DRAM中临位的比特反转(bit flips)所得到的信息，推断出内存中的数据项，并依次读取目标信息。</td>
</tr>
<tr>
<td style="text-align:center">6</td>
<td style="text-align:center">扩展信息</td>
<td style="text-align:center"><a href="https://rambleed.com/" target="_blank" rel="noopener">RAMBleed</a></td>
</tr>
</tbody>
</table>
</div>
<h3 id="Rowhammer-Attack"><a href="#Rowhammer-Attack" class="headerlink" title="Rowhammer Attack"></a>Rowhammer Attack</h3><p>  Rowhammer比特翻转攻击是指利用临近内存单元之间电子的互相影响，在足够多的访问次数后让某个单元的值从1变成0，反之亦然。这种攻击可以在不访问目标内存区域的前提下使其产生数据错误。 这次的攻击与操作系统和软件无关，纯粹是硬件上的漏洞导致的。</p>
<p>  这是个特别针对Memory的攻击技术，但不是缓冲区破坏或溢出攻击。一般的计算机Memory介质中，每个存储单元（晶体管+电容器）存放1bit数据，这个比特位要么是0，要么是1——存储单元中充满电子表示1，清空表示0。内存就是由上亿这样的存储单元构成的，数据也因此得以存储。</p>
<p>  不过电容器会泄露，一个电容器充满电子后，只需要几毫秒就会泄露殆尽。这就要求CPU（内存控制器）对电容进行充电，让“1”这个值能够保持住。整个过程是由内存控制器先读取电容器中的值，然后再把数据写回去。这种刷新操作，每秒会执行几千次。</p>
<p>  内存容量正在大幅度上涨，所以存储比特位的电容器也就越来越小，排列越来越近。要防止相邻的电容之间相互干扰，难度也就变得更大。如果能够快速、反复访问一排电容，相邻行的电容更容易产生干扰错误和所谓的“比特位翻转”，也就是0变成1。</p>
<p>  其实正常的数据读写一般是不会发生比特位翻转的，可是如果对某些行进行<strong>反复读写</strong>，问题就有可能产生。2014年卡内基梅陇大学的研究人员层发表过一篇论文，题为《无访问情况下的内存比特位翻转——DRAM干扰行错误的试验研究》，其本质是通过机器码指令CLFUSH或Cache Line Flush，强制进行这种比特位的读取和更新。据说利用这种方式，可引起大量比特位翻转。</p>
<p>  利用比特位翻转，很多事情都可以做，比如说执行未经授权的代码。这就是所谓的Rowhammer。这是一种颠覆人类对安全认知的攻击技术，软件层面几乎解决无望。先前已经有研究人员演示，如何用Rowhammer来进行提权，以及打破安全沙盒。</p>
<p>  不过看原理就知道，这种攻击实在有够理想化，存在诸多不确定性，因为攻击者根本无法精准控制比特位如何翻转。比如说，这种攻击对数据所在的内存位置首先就有要求，这样才能实施内存翻转：但敏感数据存储在这些位置的几率可能并不算高。</p>
<h3 id="RAMBleed概况"><a href="#RAMBleed概况" class="headerlink" title="RAMBleed概况"></a>RAMBleed概况</h3><p>  该攻击<strong>基于位翻转漏洞Rowhammer</strong>，可绕过ECC机制，允许黑客使用普通用户权限从OpenSSH服务器中提取签名密钥。黑客通过观察Rowhammer引发的位翻转，<strong>可推断出附近DRAM行中的值，</strong>进而读取其它进程中的物理内存。</p>
<h3 id="获取物理地址"><a href="#获取物理地址" class="headerlink" title="获取物理地址"></a>获取物理地址</h3><p>  该攻击的重点是获取到虚拟地址到物理地址之间的映射。</p>
<h4 id="伙伴算法"><a href="#伙伴算法" class="headerlink" title="伙伴算法"></a>伙伴算法</h4><p><img src="/2020/06/15/%C2%96%C2%96RAMBleed-Reading-Bits-in-Memory-Without-Accessing-Them/buddy-memory-allocation.jpg" width="500px" height="300px"></p>
<p>首先我们假设我们一个内存块有1024K，当我们需要给A分配70K内存的时候，</p>
<ol>
<li>我们发现1024K的一半大于70K，然后我们就把1024K的内存分成两半，一半512K。</li>
<li>然后我们发现512K的一半仍然大于70K，于是我们再把512K的内存再分成两半，一半是128K。</li>
<li>此时，我们发现128K的一半小于70K，于是我们就分配为A分配128K的内存。</li>
</ol>
<p> 后面的，B，C，D都这样，而释放内存时，则会把相邻的块一步一步地合并起来（合并也必需按分裂的逆操作进行合并）。</p>
<p>  论文<a href="http://export.arxiv.org/pdf/1511.08756" target="_blank" rel="noopener">DRAMA</a>中提到只要获得了物理上连续的$2MiB$空间，采用反向工程即可获取低22位物理空间地址。</p>
<p><img src="/2020/06/15/%C2%96%C2%96RAMBleed-Reading-Bits-in-Memory-Without-Accessing-Them/幻灯片13.jpg" width="600px" height="450px"></p>
<p>  基于Linux内存的伙伴分配算法，分配空间大小为$4KiB*2^N$，此处取$N = 10$,即分配$4MiB$空间，并将此 $4MiB$ 物理空间分裂为两个 $2MiB$ 的物理空间，通过$MMap$系统调用，消耗掉前面低于$2MiB$的存储空间，最后剩余的空间一定是一个连续的 $2MiB$ 的物理空间。</p>
<h3 id="内存风水逆转"><a href="#内存风水逆转" class="headerlink" title="内存风水逆转"></a>内存风水逆转</h3><p>  针对Rowhammer的内存位置限制，有人开发出一种名为 <a href="https://www.usenix.org/system/files/conference/usenixsecurity16/sec16_paper_razavi.pdf" target="_blank" rel="noopener">Flip Feng Shui</a>（风水翻转）的攻击技术，这本质上也是Rowhammer。这种攻击就是篡改deduplication操作——deduplication在云端主机中应用得很常见，这种技术可让两个或者更多虚拟主机共享特定的数据块，起到节约内存资源的作用。</p>
<p>  Flip Feng Shui在<strong>物理内存</strong>上做手脚，可致加密密钥和其他敏感数据存储到<strong>内存特定的位置</strong>——这些位置就很容易受Rowhammer的影响了。所以才叫风水翻转，就是让数据在内存中的“风水”位置变更好，Rowhammer攻击变得更可靠。</p>
<h3 id="RAMBleed攻击"><a href="#RAMBleed攻击" class="headerlink" title="RAMBleed攻击"></a>RAMBleed攻击</h3><h4 id="比特翻转"><a href="#比特翻转" class="headerlink" title="比特翻转"></a>比特翻转</h4><p><img src="/2020/06/15/%C2%96%C2%96RAMBleed-Reading-Bits-in-Memory-Without-Accessing-Them/幻灯片11.jpg" width="600px" height="450px"></p>
<p>  本文提到，在$Row1$与$Row3$加载相同的目标内容，并对其进行锤击操作，即Rowhammer攻击，则会使得$Row2$中对应的比特位发生比特翻转。经过试验证明，当$Row3-Row2-Row1$ 存储内容为$0-1-0$时，此时在Rowhammer攻击下很有可能发生比特翻转，而当$Row3-Row2-Row1$ 存储内容为$1-1-1$时，此时在Rowhammer攻击下发生比特翻转的可能性很小，因此，基于两种概率大小的不同，可以判断出目标信息中存储的绝大多数信息内容。其中$Row2$中存储的是已知内容。</p>
<h4 id="Frame-Feng-Shui"><a href="#Frame-Feng-Shui" class="headerlink" title="Frame Feng Shui"></a>Frame Feng Shui</h4><p>  上文提到，Feng Shui可以将目标信息加载到指定的存储空间中。如下图所示，红色部分存储目标信息，$A0,A1,A2$ 存储攻击者内容，因此根据比特翻转是否发生，则<strong>很有可能</strong>推断出指定比特位存储的信息。</p>
<p><img src="/2020/06/15/%C2%96%C2%96RAMBleed-Reading-Bits-in-Memory-Without-Accessing-Them/幻灯片17.jpg" width="600px" height="450px"></p>
<h4 id="RAMBleed-on-ECC-Memory"><a href="#RAMBleed-on-ECC-Memory" class="headerlink" title="RAMBleed on ECC Memory"></a>RAMBleed on ECC Memory</h4><p>  ECC Memory指的是Error-Correcting Code Memory，DRAM的纠错机制。</p>
<p><img src="/2020/06/15/%C2%96%C2%96RAMBleed-Reading-Bits-in-Memory-Without-Accessing-Them/幻灯片21.jpg" width="600px" height="450px"></p>
<p>  在<a href="https://www.computer.org/csdl/pds/api/csdl/proceedings/download-article/19skfwyNp5e/pdf?token=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJjc2RsX2FwaSIsImF1ZCI6ImNzZGxfYXBpX2Rvd25sb2FkX3Rva2VuIiwic3ViIjoiYW5vbnltb3VzQGNvbXB1dGVyLm9yZyIsImVtYWlsIjoiYW5vbnltb3VzQGNvbXB1dGVyLm9yZyIsImV4cCI6MTU5MjMxODY5OX0.uN4RLcw4bjEbBeqINhfDoXY7dyJM2-GWgE90zZJt2y4" target="_blank" rel="noopener">ECCPloit</a>这篇论文中指出，比特纠错所产生的时间延迟是十分明显的，这种情况下可根据纠错产生的时间延迟判断是否发生了比特翻转。</p>
<h3 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h3><p><img src="/2020/06/15/%C2%96%C2%96RAMBleed-Reading-Bits-in-Memory-Without-Accessing-Them/幻灯片19.jpg" width="600px" height="450px"></p>
<p>  相对来说，采用了ECC纠错的方式，获取到的结果更可信，而没有采取比特纠错方式获取的结果是在一定程度上可信的。本文通过实验测得，通过Feng Shui方式，成功将目标信息加载到指定存储位置也是有一定概率的，文中提到这个概率在83%， 通过Rowhammer攻击获取到比特翻转成功的概率为82%，因此，最终获取到目标信息的量在68%。由于此攻击针对的是秘钥信息，获取的秘钥信息量在27%以上，就可成功破解，因此，68%的信息量足以支持对秘钥的破译。综上，此方式是行得通的。</p>
<p>  本文的目的，旨在阐述这种攻击方式的行之有效，因此并未对其产生的额外代价、时间成本考虑在内。</p>
<p>  研究人员已向英特尔、AMD、OpenSSH、微软、苹果和红帽通报了调查结果，本论文发表在2020年5月举行的第41届IEEE安全和隐私研讨会。</p>
<h3 id="References"><a href="#References" class="headerlink" title="References"></a>References</h3><p>[1] <a href="https://blog.csdn.net/wojiuguowei/article/details/79377228" target="_blank" rel="noopener">伙伴分配器的一个极简实现</a></p>
<p>[2] <a href="https://www.freebuf.com/column/133871.html" target="_blank" rel="noopener">神乎其神的Rowhammer</a></p>
]]></content>
      <categories>
        <category>Security and Privacy</category>
      </categories>
      <tags>
        <tag>论文解读</tag>
        <tag>System Security</tag>
        <tag>Rowhammer attack</tag>
      </tags>
  </entry>
  <entry>
    <title>安全计算</title>
    <url>/2020/08/15/%E5%AE%89%E5%85%A8%E8%AE%A1%E7%AE%97/</url>
    <content><![CDATA[<h3 id="什么是安全计算"><a href="#什么是安全计算" class="headerlink" title="什么是安全计算"></a>什么是安全计算</h3><h4 id="安全计算"><a href="#安全计算" class="headerlink" title="安全计算"></a>安全计算</h4><p>安全多方计算，Secure Multi-party Computation（SMC）在保护数据安全的前提下实现多方计算，即，多个参与者将各自的数据凑在一起，并在这个大数据集上进行一定的计算，并得到最后的结果。</p>
<h4 id="实现方法"><a href="#实现方法" class="headerlink" title="实现方法"></a>实现方法</h4><h5 id="1-基于噪音"><a href="#1-基于噪音" class="headerlink" title="1.基于噪音"></a>1.基于噪音</h5><p>差分隐私（differential privacy）对计算过程利用噪声干扰，让原始数据淹没在噪音中，使得在引入噪声的数据中心无法推断出原始数据。（例如一张马赛克图片，无法推断出具体细节）</p>
<p>优点：效率高<br>缺点：得到的结果不够准确</p>
<h5 id="2-非噪音法"><a href="#2-非噪音法" class="headerlink" title="2.非噪音法"></a>2.非噪音法</h5><p>（这种方式一般通过密码学方法将数据编码或者加密，得到一些奇怪的数字，而且这些数字有一些性质，比如看上去很随机，但是保留了原始数据的线性关系，或者在打乱顺序的数据中心能够发现其与原始数据的映射关系。）</p>
<p>a.混淆电路（Garbled Circuit）</p>
<p>b.同态加密（Homomorphic Encryption）</p>
<p>c.秘钥分享（Secret Sharing）</p>
<p>以上提到的三种方式一般在源头将数据加密，计算操作看到的数据是密文，只要特定的假设条件满足，这类方法在计算过程中是不会泄露原始信息的。</p>
<p>优点：不会对计算过程添加干扰，因此得到的是准确值，且运用密码学理论，保障安全性<br>缺点：由于运用很多密码学方法，整个过程的计算量、通讯量很大，对于一些复杂的任务（训练几十个上百层的CNN）短时间内很难完成。</p>
<h3 id="差分隐私"><a href="#差分隐私" class="headerlink" title="差分隐私"></a>差分隐私</h3><h3 id="混淆电路"><a href="#混淆电路" class="headerlink" title="混淆电路"></a>混淆电路</h3><h3 id="同态加密"><a href="#同态加密" class="headerlink" title="同态加密"></a>同态加密</h3><h3 id="秘钥分享"><a href="#秘钥分享" class="headerlink" title="秘钥分享"></a>秘钥分享</h3>]]></content>
      <tags>
        <tag>TODO</tag>
        <tag>Homomorphic</tag>
      </tags>
  </entry>
  <entry>
    <title>泉城济南</title>
    <url>/2020/04/22/%E6%B3%89%E5%9F%8E%E6%B5%8E%E5%8D%97/</url>
    <content><![CDATA[<h3 id="泉城济南"><a href="#泉城济南" class="headerlink" title="泉城济南"></a>泉城济南</h3><p><img src="/2020/04/22/%E6%B3%89%E5%9F%8E%E6%B5%8E%E5%8D%97/济南-7.jpg" width="500px" height="400px"></p>
<p><img src="/2020/04/22/%E6%B3%89%E5%9F%8E%E6%B5%8E%E5%8D%97/济南-8.jpg" width="500px" height="400px"></p>
<p><img src="/2020/04/22/%E6%B3%89%E5%9F%8E%E6%B5%8E%E5%8D%97/济南-2.jpg" width="500px" height="400px"></p>
<p><img src="/2020/04/22/%E6%B3%89%E5%9F%8E%E6%B5%8E%E5%8D%97/济南-3.jpg" width="500px" height="350px"></p>
<p><img src="/2020/04/22/%E6%B3%89%E5%9F%8E%E6%B5%8E%E5%8D%97/济南-4.jpg" width="500px" height="390px"></p>
<p><img src="/2020/04/22/%E6%B3%89%E5%9F%8E%E6%B5%8E%E5%8D%97/济南-5.jpg" width="500px" height="400px"></p>
<p><img src="/2020/04/22/%E6%B3%89%E5%9F%8E%E6%B5%8E%E5%8D%97/济南-6.jpg" width="500px" height="400px"></p>
]]></content>
      <tags>
        <tag>picture</tag>
      </tags>
  </entry>
  <entry>
    <title>系统虚拟化</title>
    <url>/2020/12/09/%E7%B3%BB%E7%BB%9F%E8%99%9A%E6%8B%9F%E5%8C%96/</url>
    <content><![CDATA[<h3 id="第1章-开篇"><a href="#第1章-开篇" class="headerlink" title="第1章 开篇"></a>第1章 开篇</h3><p>1.1 形形色色的虚拟化<br>1.2 系统虚拟化<br>1.3 系统虚拟化简史<br>1.4 系统虚拟化的好处</p>
<h3 id="第2章-x86架构及操作系统概述"><a href="#第2章-x86架构及操作系统概述" class="headerlink" title="第2章 x86架构及操作系统概述"></a>第2章 x86架构及操作系统概述</h3><p>2.1 x86的历史和操作系统概要<br>2.1.1 x86的历史<br>2.1.2 操作系统概述<br>2.2 x86内存架构<br>2.2.1 地址空间<br>2.2.2 地址<br>2.2.3 x86内存管理机制<br>2.3 x86架构的基本运行环境<br>2.3.1 三种基本模式<br>2.3.2 基本寄存器组<br>2.3.3 权限控制<br>2.4 中断与异常<br>2.4.1 中断架构<br>2.4.2 异常架构<br>2.4.3 操作系统对中断/异常的处理流程<br>2.5 进程<br>2.5.1 上下文<br>2.5.2 上下文切换<br>2.6 I/O架构<br>2.6.1 x86的I/O架构<br>2.6.2 DMA<br>2.6.3 PCI设备<br>2.6.4 PCI Express<br>2.7 时钟<br>2.7.1 x86平台的常用时钟<br>2.7.2 操作系统的时钟观</p>
<h3 id="第3章-虚拟化概述"><a href="#第3章-虚拟化概述" class="headerlink" title="第3章 虚拟化概述"></a>第3章 虚拟化概述</h3><h4 id="3-1-可虚拟化架构与不可虚拟化架构"><a href="#3-1-可虚拟化架构与不可虚拟化架构" class="headerlink" title="3.1 可虚拟化架构与不可虚拟化架构"></a>3.1 可虚拟化架构与不可虚拟化架构</h4><h4 id="3-2-处理器虚拟化"><a href="#3-2-处理器虚拟化" class="headerlink" title="3.2 处理器虚拟化"></a>3.2 处理器虚拟化</h4><p>3.2.1 指令的模拟<br>3.2.2 中断和异常的模拟及注入<br>3.2.3 对称多处理器技术的模拟</p>
<h4 id="3-3-内存虚拟化"><a href="#3-3-内存虚拟化" class="headerlink" title="3.3 内存虚拟化"></a>3.3 内存虚拟化</h4><h4 id="3-4-I-O虚拟化"><a href="#3-4-I-O虚拟化" class="headerlink" title="3.4 I/O虚拟化"></a>3.4 I/O虚拟化</h4><p>3.4.1 概述<br>3.4.2 设备发现<br>3.4.3 访问截获<br>3.4.4 设备模拟<br>3.4.5 设备共享</p>
<h4 id="3-5-VMM的功能和组成"><a href="#3-5-VMM的功能和组成" class="headerlink" title="3.5 VMM的功能和组成"></a>3.5 VMM的功能和组成</h4><p>3.5.1 虚拟环境的管理<br>3.5.2 物理资源的管理<br>3.5.3 其他模块</p>
<h4 id="3-6-VMM的分类"><a href="#3-6-VMM的分类" class="headerlink" title="3.6 VMM的分类"></a>3.6 VMM的分类</h4><p>3.6.1 按虚拟平台分类<br>3.6.2 按VMM实现结构分类</p>
<h4 id="3-7-典型虚拟化产品及其特点"><a href="#3-7-典型虚拟化产品及其特点" class="headerlink" title="3.7 典型虚拟化产品及其特点"></a>3.7 典型虚拟化产品及其特点</h4><p>3.7.1 VMware<br>3.7.2 Microsoft<br>3.7.3 Xen<br>3.7.4 KVM<br>3.8 思考题</p>
<h3 id="第4章-基于软件的完全虚拟化"><a href="#第4章-基于软件的完全虚拟化" class="headerlink" title="第4章 基于软件的完全虚拟化"></a>第4章 基于软件的完全虚拟化</h3><p>4.1 概述<br>4.2 CPU虚拟化<br>4.2.1 解释执行<br>4.2.2 扫描与修补<br>4.2.3 二进制代码翻译<br>4.3 内存虚拟化<br>4.3.1 概述<br>4.3.2 影子页表<br>4.3.3 内存虚拟化的优化<br>4.4 I/O虚拟化<br>4.4.1 设备模型<br>4.4.2 设备模型的软件接口<br>4.4.3 接口拦截和模拟<br>4.4.4 功能实现<br>4.4.5 案例分析: IDE的DMA操作<br>4.5 思考题</p>
<h3 id="第5章-硬件辅助虚拟化"><a href="#第5章-硬件辅助虚拟化" class="headerlink" title="第5章 硬件辅助虚拟化"></a>第5章 硬件辅助虚拟化</h3><p>5.1 概述<br>5.2 CPU虚拟化的硬件支持<br>5.2.1 概述<br>5.2.2 VMCS<br>5.2.3 VMX操作模式<br>5.2.4 VM?Entry/VM?Exit<br>5.2.5 VM?Exit<br>5.3 CPU虚拟化的实现<br>5.3.1 概述<br>5.3.2 VCPU的创建<br>5.3.3 VCPU的运行<br>5.3.4 VCPU的退出<br>5.3.5 VCPU的再运行<br>5.3.6 进阶<br>5.4 中断虚拟化<br>5.4.1 概述<br>5.4.2 虚拟PIC<br>5.4.3 虚拟I/O APIC<br>5.4.4 虚拟Local APIC<br>5.4.5 中断采集<br>5.4.6 中断注入<br>5.4.7 案例分析<br>5.5 内存虚拟化<br>5.5.1 概述<br>5.5.2 EPT<br>5.5.3 VPID<br>5.6 I/O虚拟化的硬件支持<br>5.6.1 概述<br>5.6.2 VT?d技术<br>5.7 I/O虚拟化的实现<br>5.7.1 概述<br>5.7.2 设备直接分配<br>5.7.3 设备I/O地址空间的访问<br>5.7.4 设备发现<br>5.7.5 配置DMA重映射数据结构<br>5.7.6 设备中断虚拟化<br>5.7.7 案例分析: 网卡的直接分配在Xen里面的实现<br>5.7.8 进阶<br>5.8 时间虚拟化<br>5.8.1 操作系统的时间概念<br>5.8.2 客户机的时间概念<br>5.8.3 时钟设备仿真<br>5.8.4 实现客户机时间概念的一种方法<br>5.8.5 实现客户机时间概念的另一种方法<br>5.8.6 如何满足客户机时间不等于实际时间的需求<br>5.9 思考题</p>
<h3 id="第6章-类虚拟化技术"><a href="#第6章-类虚拟化技术" class="headerlink" title="第6章 类虚拟化技术"></a>第6章 类虚拟化技术</h3><p>6.1 概述<br>6.1.1 类虚拟化的由来<br>6.1.2 类虚拟化的系统实现<br>6.1.3 类虚拟化接口的标准化<br>6.2 类虚拟化体系结构<br>6.2.1 指令集<br>6.2.2 外部中断<br>6.2.3 物理内存空间<br>6.2.4 虚拟内存空间<br>6.2.5 内存管理<br>6.2.6 I/O子系统<br>6.2.7 时间与时钟服务<br>6.3 Xen的原理与实现<br>6.3.1 超调用<br>6.3.2 虚拟机与Xen的信息共享<br>6.3.3 内存管理<br>6.3.4 页表虚拟化<br>6.3.5 事件通道<br>6.3.6 授权表<br>6.3.7 I/O系统<br>6.3.8 实例分析: 块设备虚拟化<br>6.4 XenLinux的运行<br>6.5 思考题</p>
<h3 id="第7章-虚拟环境性能和优化"><a href="#第7章-虚拟环境性能和优化" class="headerlink" title="第7章 虚拟环境性能和优化"></a>第7章 虚拟环境性能和优化</h3><p>7.1 性能评测指标<br>7.2 性能评测工具<br>7.2.1 重用操作系统的性能评测工具<br>7.2.2 面向虚拟环境的性能评测工具<br>7.3 性能分析工具<br>7.3.1 Xenoprof<br>7.3.2 Xentrace<br>7.3.3 Xentop<br>7.4 性能优化方法<br>7.4.1 降低客户机退出事件发生频率<br>7.4.2 降低客户机退出事件处理时间<br>7.4.3 降低处理器利用率<br>7.5 性能分析案例<br>7.5.1 案例分析: Xenoprof<br>7.5.2 案例分析: Xentrace<br>7.6 可扩展性<br>7.6.1 宿主机的可扩展性<br>7.6.2 客户机的可扩展性<br>7.7 思考题</p>
<h3 id="第8章-虚拟化技术的应用模式"><a href="#第8章-虚拟化技术的应用模式" class="headerlink" title="第8章 虚拟化技术的应用模式"></a>第8章 虚拟化技术的应用模式</h3><p>8.1 常用技术介绍<br>8.1.1 虚拟机的动态迁移<br>8.1.2 虚拟机快照<br>8.1.3 虚拟机的克隆<br>8.1.4 案例分析: VMware VMotion 和VMware 快照<br>8.2 服务器整合<br>8.2.1 服务器整合技术<br>8.2.2 案例分析: VMware Infrastructure 3<br>8.3 灾难恢复<br>8.3.1 灾难恢复与虚拟化技术<br>8.3.2 案例分析: VMware Infrastructure 3<br>8.4 改善系统可用性<br>8.4.1 可用性的含义<br>8.4.2 虚拟化技术如何提高可用性<br>8.4.3 虚拟化技术带来的新契机<br>8.4.4 案例分析: VMware HA和 LUCOS<br>8.5 动态负载均衡<br>8.5.1 动态负载均衡的含义<br>8.5.2 案例分析: VMware DRS<br>8.6 增强系统可维护性<br>8.6.1 可维护性的含义<br>8.6.2 案例分析: VMware VirtualCenter<br>8.7 增强系统安全与可信任性<br>8.7.1 安全与可信任性的含义<br>8.7.2 虚拟化技术如何提高系统安全<br>8.7.3 虚拟化技术如何提高可信任性<br>8.7.4 案例分析: sHyper、VMware Infrastructure 3和CoVirt<br>8.8 Virtual Appliance</p>
<h3 id="第9章-前沿虚拟化技术"><a href="#第9章-前沿虚拟化技术" class="headerlink" title="第9章 前沿虚拟化技术"></a>第9章 前沿虚拟化技术</h3><p>9.1 基于容器的虚拟化技术<br>9.1.1 容器技术的基本概念和发展背景<br>9.1.2 基于容器的虚拟化技术<br>9.2 系统安全<br>9.2.1 基于虚拟化技术的恶意软件<br>9.2.2 虚拟机监控器的安全性<br>9.3 系统标准化<br>9.3.1 开放虚拟机格式<br>9.3.2 虚拟化的可管理性<br>9.3.3 虚拟机互操作性标准<br>9.4 电源管理<br>9.5 智能设备<br>9.5.1 多队列网卡<br>9.5.2 SR?IOV<br>9.5.3 其他<br>索引<br>参考文献</p>
]]></content>
      <tags>
        <tag>TODO</tag>
        <tag>虚拟化</tag>
      </tags>
  </entry>
  <entry>
    <title>虚拟化平台内存管理</title>
    <url>/2021/06/13/%E8%99%9A%E6%8B%9F%E5%8C%96%E5%B9%B3%E5%8F%B0%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/</url>
    <content><![CDATA[]]></content>
      <tags>
        <tag>TODO</tag>
      </tags>
  </entry>
  <entry>
    <title>虚拟机 系统与进程的通用平台</title>
    <url>/2020/07/17/%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%B3%BB%E7%BB%9F%E4%B8%8E%E8%BF%9B%E7%A8%8B%E7%9A%84%E9%80%9A%E7%94%A8%E5%B9%B3%E5%8F%B0/</url>
    <content><![CDATA[]]></content>
      <tags>
        <tag>TODO</tag>
        <tag>读书笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>概率图模型</title>
    <url>/2021/03/22/%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<h1 id="概率图模型"><a href="#概率图模型" class="headerlink" title="概率图模型"></a>概率图模型</h1><p><img src="/2021/03/22/%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B/Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20210326100944404.png" alt="image-20210326100944404"></p>
<p>可能用到的点：</p>
<blockquote>
<p>1、贝叶斯网络-&gt; 动态贝叶斯网络（时间序列）-&gt; 混沌时间序列模型</p>
<p>2、贝叶斯网络独立性</p>
<p>3、马尔科夫链</p>
<p>4、信念传播</p>
<p>5、信息论，信任传播衰减，边际效应递减</p>
<p>6、 边缘概率问题</p>
<p>7、 信任置信区间？</p>
</blockquote>
<p>按照概率图中变量关系的不同，概率图模型可以大致分为两类：</p>
<ul>
<li>贝叶斯网络：有向图模型，使用有向无环图表达关系（通常，变量间存在显式的因果关系）</li>
<li>马尔科夫网络：无向图模型，使用无图表达关系（通常，变量间存有关系，但是难以显式表达）</li>
</ul>
<h2 id="贝叶斯网络"><a href="#贝叶斯网络" class="headerlink" title="贝叶斯网络"></a>贝叶斯网络</h2><p>概率图模型作为一类有力的工具,能够简洁地表示复杂的概率分布,有效地(近似)计算边缘分布和条件分布,方便地学习概率模型中的参数和超参数.因此,它作为一种处理不确定性的形式化方法,被广泛应用于需要进行自动的概率推理的场合.</p>
<p>将知识陈述式地表示为概率模型,通过计算我们所关心变量的概率分布实现推理的途径具有独特优势: 首先,它提供了一个描述框架,使我们能够将不同领域的知识抽象为概率模型,将各种应用中的问题都归结为计算概率模型里某些变量的概率分布,从而将知识表示和推理分离开来.模型的设计主要关心如何根据领域知识设计出反映问题本质的概率模型,同时兼顾有效推理的可行性,而推理算法的设计只需关心如何有效地在一般的或者特定的概率模型中进行推理。这种一定程度上的正交性极大地扩展了概率模型的应用,也加快了它的发展速度. 其次,它能够评估未知量取值的可能性,对不同取值的概率给出量化的估计.这在涉及风险的决策系统中非常重要.</p>
<p><img src="/2021/03/22/%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B/贝叶斯网络.png"></p>
<p>贝叶斯网络中的三种独立性[2]</p>
<blockquote>
<ol>
<li>head-to-head</li>
<li>head-to-tail</li>
<li>tail-to-tail</li>
</ol>
</blockquote>
<p>访问者地图：</p>
<pre><code class="lang-js">&lt;script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=9nibrzSssCrLxZLVOV0AmZ9oXduSzwtvr83E1sae0y4&amp;cl=ffffff&amp;w=a"&gt;&lt;/script&gt;
</code></pre>
<h1 id="References"><a href="#References" class="headerlink" title="References"></a>References</h1><p>[1] <a href="https://www.cnblogs.com/leoo2sk/archive/2010/09/18/bayes-network.html" target="_blank" rel="noopener">https://www.cnblogs.com/leoo2sk/archive/2010/09/18/bayes-network.html</a></p>
<p>[2] <a href="https://zhuanlan.zhihu.com/p/30139208" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/30139208</a></p>
]]></content>
      <tags>
        <tag>贝叶斯网络</tag>
      </tags>
  </entry>
  <entry>
    <title>virtualization overview</title>
    <url>/2020/11/27/virtualization-overview/</url>
    <content><![CDATA[<h3 id="虚拟化技术概览"><a href="#虚拟化技术概览" class="headerlink" title="虚拟化技术概览"></a>虚拟化技术概览</h3><p>注：本文主要是整理了看过的博客以及部分论文。</p>
<p>​        虚拟化技术起源于20世纪60年代末，美国IBM公司当时开发了一套被称作虚拟机监视器（Virtual Machine Monitor）的软件，该软件作为计算机硬件层上面的一层软件抽象层，将计算机硬件虚拟分割成一个或多个虚拟机，并提供多用户对大型计算机的同时、交互访问。</p>
<p>​        虚拟化是计算机系统中的一个重要概念，基本上每个计算机系统都提供一个给上层软件的界面，从处理器提供的基本指令集到很多中间件系统提供的巨大的应用程序界面集。虚拟化本质上是扩展或替换一个现存界面来模仿另一个系统的行为，其对计算机系统的重要性主要体现在以下几个方面。</p>
<p>​        相比高层软件（比如中间件和应用软件），硬件和底层系统软件变化得比较快，也就是说，我们面对的一种情况是旧有软件的维护跟不上下层平台更新的步伐。通过移植旧有软件的底层接口到新平台，可使得一大类的现有软件可以立刻在新平台上工作。</p>
<p>​        在服务器机器上，一个组织为它提供的每个服务都分配一台虚拟机，接着，将虚拟机以最佳方式分配到物理服务器上。与进程不同，虚拟机能很简单地迁移到其他物理机器上，这增加了管理服务器基础设施的灵活性。这个方法能潜在地减少服务器计算机的投资并减少能量消耗，后者是大型服务器中心的关键问题。</p>
<p>​        虚拟化技术和云计算的提供极为相关。云计算采用了这样一个模型，即作为一个服务，提供云上创建的存储、计算和高层对象。所提供的服务覆盖从诸如物理体系结构等的底层方面（基础设施即服务IaaS）到诸如软件平台（平台即服务PaaS），再到任意应用层次的服务（软件即服务SaaS）。云服务的提供被虚拟化技术直接驱动，允许为云的用户提供一个或多个虚拟机，供用户自己使用。</p>
<p>​        分布式应用的需求也激发虚拟化解决方案的开发者去以很少的开销创建和销毁虚拟机。在可能需要动态地请求资源的应用中，这是必要的。例如对于多人在线游戏或分布式多媒体应用，通过采用合适的资源分配策略满足虚拟机服务质量需求，能提升对这样的应用的支持度。</p>
<p>​        另一个好处是，在单台计算机上提供对几个不同操作系统环境的便利访问，虚拟化可用于在一种物理体系结构上提供多种操作系统类型。</p>
<p>​        虚拟化技术起始于IBM370体系结构，它的VM操作系统能为运行在同一计算机上的不同程序提供几个完整的虚拟机。最近，人们对虚拟化的兴趣大增，有许多研究项目和商业系统为商用PC、服务器和云基础设施提供虚拟化解决方案。</p>
<p>IaaS, PaaS和SaaS是云计算的三种服务模式。</p>
<ol>
<li><p>SaaS：Software-as-a-Service（软件即服务）提供给客户的服务是运营商运行在云计算基础设施上的应用程序，用户可以在各种设备上通过客户端界面访问，如浏览器。消费者不需要管理或控制任何云计算基础设施，包括网络、服务器、操作系统、存储等等；</p>
</li>
<li><p>PaaS：Platform-as-a-Service（平台即服务）提供给消费者的服务是把客户采用提供的开发语言和工具（例如Java，python, .Net等）开发的或收购的应用程序部署到供应商的云计算基础设施上去。</p>
<p>客户不需要管理或控制底层的云基础设施，包括网络、服务器、操作系统、存储等，但客户能控制部署的应用程序，也可能控制运行应用程序的托管环境配置；</p>
</li>
<li><p>IaaS： Infrastructure-as-a-Service（基础设施即服务）提供给消费者的服务是对所有计算基础设施的利用，包括处理CPU、内存、存储、网络和其它基本的计算资源，用户能够部署和运行任意软件，包括操作系统和应用程序。</p>
</li>
</ol>
<h3 id="不同抽象层次的虚拟化技术"><a href="#不同抽象层次的虚拟化技术" class="headerlink" title="不同抽象层次的虚拟化技术"></a>不同抽象层次的虚拟化技术</h3><p>在介绍各种虚拟化概念之前，先介绍虚拟化中的两个重要名词。在虚拟化中，物理资源通常有一个定语称为宿主（Host），而虚拟出来的资源通常有一个定语称为客户（Guest）。</p>
<p>在计算机系统中，从底层至高层依次可分为：硬件层、操作系统层、函数库层、应用程序层，在对某层实施虚拟化时，该层和上一层之间的接口不发生变化，而只变化该层的实现方式。从使用虚拟资源的Guest的角度来看，虚拟化可发生在上述四层中的任一层。应当注意，在对Guest的某一层进行虚拟化时，并未对Host在哪一层实现它作出要求，这一点是时常引起混淆的地方。</p>
<h4 id="硬件抽象层上的虚拟化"><a href="#硬件抽象层上的虚拟化" class="headerlink" title="硬件抽象层上的虚拟化"></a>硬件抽象层上的虚拟化</h4><p>硬件抽象层上的虚拟化是指通过虚拟硬件抽象层来实现虚拟机，为客户机操作系统呈现和物理硬件相同或相近的硬件抽象层，又称为指令集级虚拟化，实现在此层的虚拟化粒度是最小的。</p>
<p>实现在此层的虚拟化技术可以对整个计算机系统进行虚拟，即可将一台物理计算机系统虚拟化为一台或多台虚拟计算机系统，故又可称作系统级虚拟化。每个虚拟计算机系统（简称为虚拟机）都拥有自己的虚拟硬件（如CPU、内存和设备等），来提供一个独立的虚拟机执行环境。每个虚拟机中的操作系统可以完全不同，并且它们的执行环境是完全独立的。由于客户机操作系统所能看到的是硬件抽象层，因此，客户机操作系统的行为和在物理平台上没有什么区别。</p>
<h4 id="操作系统层上的虚拟化"><a href="#操作系统层上的虚拟化" class="headerlink" title="操作系统层上的虚拟化"></a>操作系统层上的虚拟化</h4><p>操作系统层上的虚拟化是指操作系统的内核可以提供多个互相隔离的用户态实例。这些用户态实例（经常被称为容器）对于它的用户来说就像是一台真实的计算机，有自己独立的文件系统、网络、系统设置和库函数等。</p>
<p>由于这是操作系统内核主动提供的虚拟化，因此操作系统层上的虚拟化通常非常高效，它的虚拟化资源和性能开销非常小，也不需要有硬件的特殊支持。但它的灵活性相对较小，每个容器中的操作系统通常必须是同一种操作系统。另外，操作系统层上的虚拟化虽然为用户态实例间提供了比较强的隔离性，但其粒度是比较粗的。</p>
<h4 id="库函数层上的虚拟化"><a href="#库函数层上的虚拟化" class="headerlink" title="库函数层上的虚拟化"></a>库函数层上的虚拟化</h4><p>操作系统通常会通过应用级的库函数提供给应用程序一组服务，例如文件操作服务、时间操作服务等。这些库函数可以隐藏操作系统内部的一些细节，使得应用程序编程更为简单。不同的操作系统库函数有着不同的服务接口，例如Linux的服务接口是不同于Windows的。库函数层上的虚拟化就是通过虚拟化操作系统的应用级库函数的服务接口，使得应用程序不需要修改，就可以在不同的操作系统中无缝运行，从而提高系统间的互操作性。</p>
<p>例如，Wine就是在Linux上模拟了Windows的库函数接口，使得一个Windows应用程序能够在Linux上正常运行。</p>
<h4 id="编程语言层上的虚拟化"><a href="#编程语言层上的虚拟化" class="headerlink" title="编程语言层上的虚拟化"></a>编程语言层上的虚拟化</h4><p>另一大类编程语言层上的虚拟机称为语言级虚拟机，例如JVM（Java Virtual Machine）和微软的CLR（Common Language Runtime）。这一类虚拟机运行的是进程级的作业，所不同的是这些程序所针对的不是一个硬件上存在的体系结构，而是一个虚拟体系结构。这些程序的代码首先被编译为针对其虚拟体系结构的中间代码，再由虚拟机的运行时支持系统翻译为硬件的机器语言进行执行。</p>
<h3 id="系统级虚拟化"><a href="#系统级虚拟化" class="headerlink" title="系统级虚拟化"></a>系统级虚拟化</h3><p>系统级虚拟化即硬件抽象层上的虚拟化、指令集级虚拟化，是最早被提出和研究的一种虚拟化技术，当前存在多种此种技术的具体实现方案，在介绍它们之前，有必要先了解实现系统级虚拟化可采取的途径。</p>
<p>在每台虚拟机中都有属于它的虚拟硬件，通过虚拟化层的模拟，虚拟机中的操作系统认为自己仍然是独占一个系统在运行，这个虚拟化层被称为虚拟机监控器（Virtual Machine Monitor，VMM）。VMM对物理资源的虚拟可以归结为三个主要任务：处理器虚拟化、内存虚拟化和I/O虚拟化。其中，处理器虚拟化是VMM中最核心的部分，因为访问内存或进行I/O本身就是通过一些指令来实现的。</p>
<h4 id="可虚拟化架构和不可虚拟化架构"><a href="#可虚拟化架构和不可虚拟化架构" class="headerlink" title="可虚拟化架构和不可虚拟化架构"></a>可虚拟化架构和不可虚拟化架构</h4><p>在系统级虚拟化中，虚拟计算机系统和物理计算机系统可以是两个完全不同ISA（Instruction Set Architecture，指令集架构）的系统，例如，可以在一个x86的物理计算机上运行一个安腾的虚拟计算机。但是，不同的ISA使得虚拟机的每一条指令都需要在物理机上模拟执行，从而造成性能上的极大下降。</p>
<p>显然，相同体系结构的系统虚拟化通常会有比较好的性能，并且VMM实现起来也会比较简单。这种情况下虚拟机的大部分指令可以在处理器上直接运行，只有那些与硬件资源关系密切的敏感指令才会由VMM进行处理。此时面前的一个问题是，要能将这些敏感指令很好地筛选出来。但事实上，某些处理器在设计之初并没有充分考虑虚拟化的需求，导致没有办法识别出所有的敏感指令，因而不具备一个完备的可虚拟化结构。</p>
<p>大多数的现代计算机体系结构都有两个或两个以上的特权级，用来分隔系统软件和应用软件。系统中有一些操作和管理关键系统资源的指令会被定为特权指令，这些指令只有在最高特权级上才能够正确执行。如果在非最高特权级上运行，特权指令会引发一个异常，处理器会陷入到最高特权级，交由系统软件来处理。</p>
<p>在x86架构中，所有的特权指令都是敏感指令，然而并不是所有的敏感指令都是特权指令。</p>
<p>为了VMM可以完全控制系统资源，它不允许虚拟机上操作系统直接执行敏感指令。如果一个系统上所有敏感指令都是特权指令，则能够用一个很简单的方法来实现一个虚拟环境：将VMM运行在系统的最高特权级上，而将客户机操作系统运行在非最高特权级上，当客户机操作系统因执行敏感指令而陷入到VMM时，VMM模拟执行引起异常的敏感指令，这种方法被称为“陷入再模拟”。</p>
<p>总而言之，判断一个架构是否可虚拟化，其核心就在于该结构对敏感指令的支持上。如果一个架构中所有敏感指令都是特权指令，则称其为可虚拟化架构，否则称为不可虚拟化架构。</p>
<h4 id="按照实现方法分类"><a href="#按照实现方法分类" class="headerlink" title="按照实现方法分类"></a>按照实现方法分类</h4><p>系统级虚拟化有许多不同的具体实现方案，按照实现方法的不同，可划分为如下几个类别。</p>
<h5 id="仿真（Emulation）"><a href="#仿真（Emulation）" class="headerlink" title="仿真（Emulation）"></a>仿真（Emulation）</h5><p>我们已经知道，通过陷入再模拟敏感指令的执行来实现虚拟机的方法是有前提条件的：所有的敏感指令必须都是特权指令。如果一个体系结构上存在敏感指令不属于特权指令，那么其就存在虚拟化漏洞，可以采用一些方法来填补或避免这些漏洞。最简单直接的方法是，所有指令都采用模拟来实现，就是取一条指令，就模拟出这条指令执行的效果。这种方法称作仿真。</p>
<p>仿真是最复杂的虚拟化实现技术，使用仿真方法，可以在一个x86处理器上运行为PowerPC设计的操作系统，这在其它的虚拟化方案中是无法实现的。甚至可以运行多个虚拟机，每个虚拟机仿真一个不同的处理器。此外，这种方法不需要对宿主操作系统的特殊支持，虚拟机可以完全作为应用层程序运行。</p>
<p>正如前面提到的，使用仿真方法的主要问题是速度会非常慢。由于每条指令都必须在底层硬件上进行仿真，因此速度减慢100倍的情况也并不稀奇。若要实现高度保真的仿真，包括周期精度、CPU的缓存行为等，实际速度差距甚至可能会达到1000倍之多。</p>
<p>使用这种方式的典型实现是Bochs。</p>
<h5 id="完全虚拟化（Full-Virtualization）"><a href="#完全虚拟化（Full-Virtualization）" class="headerlink" title="完全虚拟化（Full Virtualization）"></a>完全虚拟化（Full Virtualization）</h5><p>在客户操作系统看来，完全虚拟化的虚拟平台和现实平台是一样的，客户机操作系统察觉不到是运行在一个虚拟平台上，这样的虚拟平台可以运行现有的操作系统，无须对操作系统进行任何修改，因此这种方式被称为完全虚拟化。</p>
<p>进一步说，客户机的行为是通过执行反映出来的，因此VMM需要能够正确处理所有可能的指令。在实现方式上，以x86架构为例，完全虚拟化经历了两个阶段：软件辅助的完全虚拟化和硬件辅助的完全虚拟化。</p>
<p>①软件实现的完全虚拟化</p>
<p>在x86虚拟化技术的早期，没有在硬件层次上对虚拟化提供支持，因此完全虚拟化只能通过软件实现。一个典型的做法是二进制代码翻译（Binary Translation）。</p>
<p>二进制代码翻译的思想是，通过扫描并修改客户机的二进制代码，将难以虚拟化的指令转化为支持虚拟化的指令。VMM通常会对操作系统的二进制代码进行扫描，一旦发现需要处理的指令，就将其翻译成为支持虚拟化的指令块（Cache Block）。这些指令块可以与VMM合作访问受限的虚拟资源，或者显式地触发异常让VMM进一步处理。</p>
<p>这种技术虽然能够实现完全虚拟化，但很难在架构上保证其完整性。因此，x86厂商在硬件上加入了对虚拟化的支持，从而在硬件架构上实现了虚拟化。</p>
<p>②硬件辅助完全虚拟化</p>
<p>可以预料，如果硬件本身加入足够的虚拟化功能，可以截获操作系统对敏感指令的执行或者对敏感资源的访问，从而通过异常的方式报告给VMM，这样就解决了虚拟化的问题。硬件虚拟化时一种完备的虚拟化方法，因而内存和外设的访问本身也是由指令来承载，对处理器指令级别的截获就意味着VMM可以模拟一个与真实主机完全一样的环境。</p>
<p>Intel的VT-x和AMD的AMD-V是这一方向的代表。以VT-x为例，其在处理器上引入了一个新的执行模式用于运行虚拟机，当虚拟机执行在这个特殊模式中时，它仍然面对的是一套完整的处理器寄存器集合和执行环境，只是任何敏感操作都会被处理器截获并报告给VMM。</p>
<p>在当前的系统级虚拟化解决方案中，全虚拟化应用得非常普遍，典型的有知名的产品有VirtualBox、KVM、VMware Workstation和VMware ESX（它在其4.0版，被改名为VMware vSphere）、Xen（也支持全虚拟化）。</p>
<h5 id="类虚拟化（Para-Virtualization）"><a href="#类虚拟化（Para-Virtualization）" class="headerlink" title="类虚拟化（Para-Virtualization）"></a>类虚拟化（Para-Virtualization）</h5><p>这样的虚拟平台需要对所运行的客户机操作系统进行或多或少的修改使之适应虚拟环境，因此客户机操作系统知道其运行在虚拟平台上，并且会去主动适应。这种方式被称为类虚拟化，有时也称作半虚拟化。另外，值得指出的是，一个VMM可以既提供完全虚拟化的虚拟平台，又提供类虚拟化的虚拟平台。</p>
<p>类虚拟化是通过在源代码级别修改指令以回避虚拟化漏洞的方式来使VMM 能够对物理资源实现虚拟化。上面谈到x86 存在一些难以虚拟化的指令，完全虚拟化通过Binary Translation在二进制代码级别上来避免虚拟化漏洞。类虚拟化采取的是另一种思路，即修改操作系统内核的代码，使得操作系统内核完全避免这些难以虚拟化的指令。</p>
<p>既然内核代码已经需要修改，类虚拟化进一步可以被用于优化I/O。也就是说，类虚拟化不是去模拟真实世界中的设备，因为太多的寄存器模拟会降低性能．相反，类虚拟化可以自定义出高度优化的协议I/O。这种I/O协议完全基于事务，可以达到近似物理机的速度。</p>
<p>这种虚拟技术以Xen为代表，微软的Hyper-V所采用技术和Xen类似，也可以把Hyper-V归属于半虚拟化。</p>
<h4 id="按照实现结构分类"><a href="#按照实现结构分类" class="headerlink" title="按照实现结构分类"></a>按照实现结构分类</h4><p>在系统级虚拟化的实现中，VMM是一个关键角色，前面已介绍过VMM的组成部分。从Host实现VMM的角度出发，还可以将当前主流的虚拟化技术按照实现结构分为如下三类。</p>
<h5 id="Hypervisor模型"><a href="#Hypervisor模型" class="headerlink" title="Hypervisor模型"></a>Hypervisor模型</h5><p>Hypervisor这个术语是在 20 世纪 70 年代出现的，在早期计算机界，操作系统被称为Supervisor，因而能够在其他操作系统上运行的操作系统被称为 Hypervisor。</p>
<p>在Hypervisor模型中，VMM首先可以被看做是一个完备的操作系统，不过和传统操作系统不同的是，VMM是为虚拟化而设计的，因此还具备虚拟化功能。从架构上来看，首先，所有的物理资源如处理器、内存和I/O设备等都归VMM所有，因此，VMM承担着管理物理资源的责任；其次，VMM需要向上提供虚拟机用于运行客户机操作系统，因此，VMM还负责虚拟环境的创建和管理。</p>
<p>由于VMM同时具备物理资源的管理功能和虚拟化功能，因此，物理资源虚拟化的效率会更高一些。在安全方面，虚拟机的安全只依赖于VMM的安全。Hypervisor模型在拥有虚拟化高效率的同时也有其缺点。由于VMM完全拥有物理资源，因此，VMM需要进行物理资源的管理，包括设备的驱动。我们知道，设备驱动开发的工作量是很大的。因此，对于Hypervisor模型来说这是个很大的挑战。事实上，在实际的产品中，基于Hypervisor模型的VMM通常会根据产品定位，有选择地挑选一些I/O设备来支持，而不是支持所有的I/O设备。</p>
<p>采用这种模型的典型是面向企业级应用的VMware vSphere。</p>
<h5 id="宿主模型"><a href="#宿主模型" class="headerlink" title="宿主模型"></a>宿主模型</h5><p>与Hypervisor模型不同。在宿主模型中，物理资源由宿主机操作系统管理。宿主机操作系统是传统操作系统，如Windows 、Linux等，这些传统操作系统并不是为虚拟化而设计的，因此本身并不具备虚拟化功能，实际的虚拟化功能由VMM来提供。VMM通常是宿主机操作系统独立的内核模块，有些实现中还包括用户态进程，如负责I/O虚拟化的用户态设备模型。 VMM通过调用宿主机操作系统的服务来获得资源， 实现处理器、内存和I/O设备的虚拟化。VMM创建出虚拟机之后，通常将虚拟机作为宿主机操作系统的一个进程参与调度。</p>
<p>宿主模型的优缺点和Hypervisor模型恰好相反。宿主模型最大的优点是可以充分利用现有操作系统的设备驱动程序，VMM无须为各类I/O设备重新实现驱动程序，可以专注于物理资源的虚拟化。考虑到I/O设备种类繁多，千变万化， 设备驱动程序开发的工作量非常大，因此，这个优点意义重大。此外，宿主模型也可以利用宿主机操作系统的其他功能，例如调度和电源管理等，这些都不需要VMM重新实现就可以直接使用。</p>
<p>宿主模型当然也有缺点，由于物理资源由宿主机操作系统控制，VMM得要调用宿主机操作系统的服务来获取资源进行虚拟化，而那些系统服务在设计开发之初并没有考虑虚拟化的支持，因此，VMM虚拟化的效率和功能会受到一定影响。此外，在安全方面，由于VMM是宿主机操作系统内核的一部分，因此，如果宿主机操作系统内核是不安全的，那么，VMM也是不安全的，相应地运行在虚拟机之上的客户机操作系统也是不安全的。换言之，虚拟机的安全不仅依赖于VMM的安全，也依赖于宿主机操作系统的安全。</p>
<p>采用这种模型的典型是KVM、VirtualBox和VMware Workstation。</p>
<h5 id="混合模型"><a href="#混合模型" class="headerlink" title="混合模型"></a>混合模型</h5><p>混合模型是上述两种模式的汇合体。VMM依然位于最低层，拥有所有的物理资源。与Hypervisor模式不同的是，VMM 会主动让出大部分I/O设备的控制权，将它们交由一个运行在特权虚拟机中的特权操作系统控制。相应地，VMM 虚拟化的职责也被分担．处理器和内存的虚拟化依然由VMM来完成，而I/O的虚拟化则由VMM和特权操作系统共同合作来完成。</p>
<p>I/O设备虚拟化由VMM和特权操作系统共同完成，因此，设备模型模块位于特权操作系统中，并且通过相应的通信机制与VMM合作。</p>
<p>混合模型集中了上述两种模型的优点。 VMM可以利用现有操作系统的I/O设备驱动程序，不需要另外开发。VMM直接控制处理器、内存等物理资源，虚拟化的效率也比较高。</p>
<p>在安全方面，如果对特权操作系统的权限控制得当，虚拟机的安全性只依赖于VMM。当然，混合模型也存在缺点。由于特权操作系统运行在虚拟机上，当需要特权操作系统提供服务时，VMM需要切换到特权操作系统，这里面就产生上下文切换的开销。当切换比较频繁时，上下文切换的开销会造成性能的明显下降。出于性能方面的考虑，很多功能还是必须在VMM 中实现，如调度程序和电源管理等。</p>
<p>采用这种模型的典型是Xen。</p>
<h3 id="操作系统级虚拟化"><a href="#操作系统级虚拟化" class="headerlink" title="操作系统级虚拟化"></a>操作系统级虚拟化</h3><p>在操作系统虚拟化技术中，每个节点上只有唯一的系统内核，不虚拟任何硬件设备。通过使用操作系统提供的功能，多个虚拟环境之间可以相互隔离。通常所说的容器（Container）技术，如目前为止最流行的容器系统Docker，即属于操作系统级虚拟化。此外，在不同的场景中，隔离出的虚拟环境也被称作虚拟环境（即VE，Virtual Environment）或虚拟专用服务器（即VPS，Virtual Private Server）。</p>
<p>以容器技术为例，它有自己独特的优点，它的出现，一方面解决了传统操作系统所忽视和缺乏的应用程序间的独立性问题，另一方面，它避免了相对笨重的系统级虚拟化，是一种轻量级的虚拟化解决方案。</p>
<p>操作系统领域一直以来面临的一个主要挑战来自于应用程序间存在的相互独立性和资源互操作性之间的矛盾，即每个应用程序都希望能运行在一个相对独立的系统环境下，不受到其他程序的干扰，同时又能以方便快捷的方式与其他程序交换和共享系统资源。当前通用操作系统更强调程序间的互操作性，而缺乏对程序间相对独立性的有效支持，然而对于许多分布式系统如Web服务、数据库、游戏平台等应用领域，提供高效的资源互操作同保持程序间的相对独立性具有同等重要的意义。</p>
<p>主流虚拟化产品VMware和Xen等均采用Hypervisor模型（Xen采用的混合模型与Hypervisor模型差别不大，可统称为Hypervisor模型）。该模型通过将应用程序运行在多个不同虚拟机内，实现对上层应用程序的隔离。但由于Hypervisor 模型倾向于每个虚拟机都拥有一份相对独立的系统资源，以提供更为完全的独立性，这种策略造成处于不同虚拟机内的应用程序间实现互操作非常困难。例如， 即使是运行在同一台物理机器上，如果处于不同虚拟机内，那么应用程序间仍然只能通过网络进行数据交换，而非共享内存或者文件。而如果使用容器技术，由于各容器共享同一个宿主操作系统，能够在满足基本的独立性需求的同时提供高效的系统资源共享支持。</p>
<p>容器技术还可以更高效地使用系统资源，由于容器不需要进行硬件虚拟以及运行完整操作系统等额外开销，相比虚拟机技术，一个相同配置的主机，往往可以运行更多数量的应用。此外，容器还具有更快速的启动时间，传统的虚拟机技术启动应用服务往往需要数分钟，而对于容器由于，直接运行于宿主内核，无需启动完整的操作系统，因此可以做到秒级、甚至毫秒级的启动时间，大大的节约了应用开发、测试、部署的时间。</p>
<h3 id="典型虚拟化技术实现及其特点"><a href="#典型虚拟化技术实现及其特点" class="headerlink" title="典型虚拟化技术实现及其特点"></a>典型虚拟化技术实现及其特点</h3><h4 id="系统级虚拟化实现"><a href="#系统级虚拟化实现" class="headerlink" title="系统级虚拟化实现"></a>系统级虚拟化实现</h4><h5 id="VMware"><a href="#VMware" class="headerlink" title="VMware"></a>VMware</h5><p>VMware是x86 虚拟化软件的主流广商之一。VMware的5位创始人中的3位曾在斯坦福大学研究操作系统虚拟化，项目包括SimOS系统模拟器和Disco虚拟机监控器。1998年，他们与另外两位创始人共同创建了VMware 公司，总部位于美国加州Palo Alto。</p>
<p>VMware提供一系列的虚拟化产品，产品的应用领域从服务器到桌面。下面是VMware主要产品的简介，包括VMware ESX、VMware Server和VMware Workstation。</p>
<p>VMware ESX Server是VMware的旗舰产品，后续版本改称VMware vSphere。ESX Server基于Hypervisor模型，在性能和安全性方面都得到了优化，是一款面向企业级应用的产品。VMware ESX Server支持完全虚拟化，可以运行Windows 、Linux、Solaris和Novell Netware等客户机操作系统。VMware ESX Server也支持类虚拟化，可以运行Linux 2. 6. 21 以上的客户机操作系统。ESX Server的早期版本采用软件虚拟化的方式，基于Binary Translation技术。自ESX Server 3开始采用硬件虚拟化的技术，支持Intel VT技术和AMD-V技术。</p>
<p>VMware Server之前叫VMware GSX Server，是VMware面向服务器端的入门级产品。VMware Server采用了宿主模型，宿主机操作系统可以是Windows或者Linux。VMware Server的功能与ESX Server类似，但是在性能和安全性上与ESX Server有所差距。VMware Server也有自己的优点，由于采用了宿主模型，因此VMware Server支持的硬件种类要比ESX Server多。</p>
<p>VMware Workstation是VMware面向桌面的主打产品。与VMware Server类似，VMware Workstation也是基于宿主模型，宿主机操作系统可以是Windows或者Linux。VMware Workstation也支持完全虚拟化，可以运行Windows、Linux、Solaris、Novell Netware和FreeBSD等客户机操作系统。与VMware Server不同， VMware Workstation专门针对桌面应用做了优化，如为虚拟机分配USB设备，为虚拟机显卡进行3D加速等。</p>
<h5 id="Microsoft"><a href="#Microsoft" class="headerlink" title="Microsoft"></a>Microsoft</h5><p>微软在虚拟化产品方面起步比VMware晚，但是在认识到虚拟化的重要性之后，微软通过外部收购和内部开发，推出了一系列虚拟化产品，目前已经形成了比较完整的虚拟化产品线。微软的虚拟化产品涵盖了服务器虚拟化（Hyper-V）和桌面虚拟化（Virtual PC）。</p>
<p>Virtual PC是而向桌面的虚拟化产品，最早由Connectix公司开发，后来该产品被微软公司收购。Virtual PC是基于宿主模型的虚拟机产品，宿主机操作系统是Windows。早期版本也采用软件虚拟化方式，基于Binary Translation技术。之后版本已经支持硬件虚拟化技术。</p>
<p>Windows Server 2008是微软推出的服务器操作系统，其中一项重要的新功能是虚拟化功能。其虚拟化架构采用的是混合模型，重要组件之一Hyper-V作为Hypervisor运行在最底层，Server 2008本身作为特权操作系统运行在Hyper-V之上。Server 2008采用硬件虚拟化技术，必须运行在支持Intel VT技术或者AMD-V 技术的处理器上。</p>
<h5 id="Xen"><a href="#Xen" class="headerlink" title="Xen"></a>Xen</h5><p>​        Xen是一款基于GPL授权方式的开源虚拟机软件。Xen起源于英国剑桥大学Ian Pratt领导的一个研究项目，之后，Xen独立出来成为一个社区驱动的开源软件项目。Xen社区吸引了许多公司和科研院所的开发者加入，发展非常迅速。之后，Ian成立了XenSource公司进行Xen的商业化应用，并且推出了基于Xen的产品Xen Server。2007年，Ctrix公司收购了XenSource公司，继续推广Xen的商业化应用，Xen开源项目本身则被独立到www.xen.org。</p>
<p>​        从技术角度来说，Xen基于混合模型，特权操作系统（ 在Xen中称作Domain 0）可以是Linux、Solaris以及NetBSD，理论上，其他操作系统也可以移植作为Xen的特权操作系统。Xen最初的虚拟化思路是类虚拟化，通过修改Linux内核，实现处理器和内存的虚拟化，通过引入I/O的前端驱动/后端驱动（front / backend）架构实现设备的类虚拟化。之后也支持了完全虚拟化和硬件虚拟化技术。</p>
<h5 id="KVM"><a href="#KVM" class="headerlink" title="KVM"></a>KVM</h5><p>​        KVM（Kernel-based Virtual Machine）也是一款基于GPL授权方式的开源虚拟机软件。KVM 最早由Qumranet公司开发，在2006年出现在Linux内核的邮件列表上，并于2007年被集成到了Linux 2.6.20内核中，成为内核的一部分。</p>
<p>​        KVM支持硬件虚拟化方法，并结合QEMU来提供设备虚拟化。KVM的特点在于和Linux内核结合得非常好，而且和Xen一样，作为开源软件，KVM的移植性也很好。</p>
<h5 id="Oracle-VM-VirtualBox"><a href="#Oracle-VM-VirtualBox" class="headerlink" title="Oracle VM VirtualBox"></a>Oracle VM VirtualBox</h5><p>​        VirtualBox是一款开源虚拟机软件，类似于VMware Workstation。VirtualBox 是由德国Innotek公司开发，由Sun Microsystems公司出品的软件，使用Qt编写，在 Sun 被 Oracle 收购后正式更名成 Oracle VM VirtualBox。Innotek 以 GNU General Public License (GPL) 释出 VirtualBox。用户可以在VirtualBox上安装并且执行Solaris、Windows、DOS、Linux、BSD等系统作为客户端操作系统。现在由甲骨文公司进行开发，是甲骨文公司VM虚拟化平台技术的一部分。</p>
<h5 id="Bochs"><a href="#Bochs" class="headerlink" title="Bochs"></a>Bochs</h5><pre><code>  Bochs 是一个 x86 计算机仿真器，它在很多平台上（包括 x86、PowerPC、Alpha、SPARC 和 MIPS）都可以移植和运行。使 Bochs 不仅可以对处理器进行仿真，还可以对整个计算机进行仿真，包括计算机的外围设备，比如键盘、鼠标、视频图像硬件、网卡（NIC）等。
</code></pre><p>​        Bochs 可以配置作为一个老式的 Intel® 386 或其后继处理器使用，例如 486、Pentium、Pentium Pro 或 64 位处理器。它甚至还可以对一些可选的图形指令进行仿真，例如 MMX 和 3DNow。</p>
<h5 id="QEMU"><a href="#QEMU" class="headerlink" title="QEMU"></a>QEMU</h5><pre><code>     QEMU是一套由Fabrice Bellard所编写的模拟处理器的自由软件。它与Bochs，PearPC近似，但其具有某些后两者所不具备的特性，如高速度及跨平台的特性，qemu可以虚拟出不同架构的虚拟机，如在x86平台上可以虚拟出power机器。kqemu为qemu的加速器，经由kqemu这个开源的加速器，QEMU能模拟至接近真实电脑的速度。
</code></pre><p>​        QEMU本身可以不依赖于KVM，但是如果有 KVM的存在并且硬件(处理器)支持比如Intel VT功能，那么QEMU在对处理器虚拟化这一块可以利用KVM提供的功能来提升性能。换言之，KVM缺乏设备虚拟化以及相应的用户空间管理虚拟机的工具，所以它借用了QEMU的代码并加以精简，连同KVM一起构成了一个完整的虚拟化解决方案，不妨称之为：KVM+QEMU。</p>
<h4 id="操作系统级虚拟化实现"><a href="#操作系统级虚拟化实现" class="headerlink" title="操作系统级虚拟化实现"></a>操作系统级虚拟化实现</h4><h5 id="chroot"><a href="#chroot" class="headerlink" title="chroot"></a>chroot</h5><p>容器的概念始于 1979 年的 UNIX chroot，它是一个 UNIX 操作系统上的系统调用，用于将一个进程及其子进程的根目录改变到文件系统中的一个新位置，让这些进程只能访问到该目录。这个功能的想法是为每个进程提供独立的磁盘空间。其后在 1982年，它被加入到了 BSD 系统中。</p>
<h5 id="LXC"><a href="#LXC" class="headerlink" title="LXC"></a>LXC</h5><p>LXC 的意思是 LinuX Containers，它是第一个最完善的 Linux 容器管理器的实现方案，是通过 cgroups 和 Linux 名字空间namespace实现的。LXC 存在于 liblxc 库中，提供了各种编程语言的 API 实现，包括 Python3、Python2、Lua、Go、Ruby 和 Haskell 等。与其它容器技术不同的是， LXC 可以工作在普通的 Linux 内核上，而不需要增加补丁。现在 LXC project 是由 Canonical 公司赞助并托管的。</p>
<h5 id="Docker"><a href="#Docker" class="headerlink" title="Docker"></a>Docker</h5><p>Docker 是到现在为止最流行和使用广泛的容器管理系统。它最初是一个叫做 dotCloud 的 PaaS 服务公司的内部项目，后来该公司改名为 Docker。Docker 开始阶段使用的也是 LXC ，之后采用自己开发的 libcontainer 替代了它。不像其它的容器平台，Docker 引入了一整个管理容器的生态系统，这包括高效、分层的容器镜像模型、全局和本地的容器注册库、清晰的 REST API、命令行等等。稍后的阶段， Docker 推动实现了一个叫做 Docker Swarm 的容器集群管理方案。</p>
<p>2008 年，Docker 公司凭借与公司同名的容器技术<a href="https://blog.docker.com/2013/10/dotcloud-is-becoming-docker-inc/" target="_blank" rel="noopener">通过 dotCloud</a> 登上了舞台。Docker 技术带来了很多新的概念和工具，包括可运行和构建新的分层镜像的简单命令行界面、服务器守护进程、含有预构建容器镜像的库以及注册表服务器概念。通过综合运用这些技术，用户可以快速构建新的分层容器，并轻松地与他人共享这些容器。</p>
<p>我们可通过 3 个主要标准，来确保各种容器技术间的互操作性，即 OCI <a href="https://github.com/opencontainers/image-spec/" target="_blank" rel="noopener">镜像</a>、分发和<a href="https://github.com/opencontainers/runtime-spec/" target="_blank" rel="noopener">运行时</a>规范。通过遵循上述规范，社区项目、商用产品和云技术提供商可以构建可互操作的容器技术（可将您自行构建的镜像，推送至云技术提供商的注册表服务器——完成这一操作后，镜像才能正常工作）。当前，红帽和 Docker 等公司都是<a href="https://www.opencontainers.org/" target="_blank" rel="noopener">开放容器计划</a>（OCI）的成员，致力于实现容器技术的开放行业标准化。[4]</p>
<h5 id="docker-plus-容器技术发展历史"><a href="#docker-plus-容器技术发展历史" class="headerlink" title="docker plus (容器技术发展历史)"></a>docker plus (容器技术发展历史)</h5><p>我们现在称为容器技术的概念最初出现在 2000 年，当时称为 <a href="https://www.freebsd.org/doc/handbook/jails.html" target="_blank" rel="noopener">FreeBSD jail</a>，这种技术可将 <a href="https://www.freebsd.org/" target="_blank" rel="noopener">FreeBSD</a> 系统分区为多个子系统（也称为 Jail）。Jail 是作为安全环境而开发的，系统管理员可与企业内部或外部的多个用户共享这些 Jail。</p>
<p>2001 年，通过 Jacques Gélinas 的 <a href="http://linux-vserver.org/Welcome_to_Linux-VServer.org" target="_blank" rel="noopener">VServer 项目，</a>隔离环境的实施进入了 Linux 领域。在完成了这项针对 Linux 中多个受控制用户空间的基础性工作后，Linux 容器开始逐渐成形并最终发展成了现在的模样。</p>
<p>很快，更多技术结合进来，让这种隔离方法从构想变为现实。控制组（cgroups）是一项内核功能，能够控制和限制一个进程或多组进程的资源使用。而 <a href="https://www.freedesktop.org/wiki/Software/systemd/" target="_blank" rel="noopener">systemd</a> 初始化系统可设置用户空间，并且管理它们的进程，cgroups 使用该系统来更严密地控制这些隔离进程。这两种技术在增加对 Linux 的整体控制的同时，也成为了保持环境隔离的重要框架。 [4]</p>
<h5 id="Linux-VServer"><a href="#Linux-VServer" class="headerlink" title="Linux VServer"></a>Linux VServer</h5><p>  Linux-VServer 也是一个操作系统级虚拟化解决方案。Linux-VServer 对 Linux 内核进行虚拟化，这样多个用户空间环境—又称为 Virtual Private Server（VPS） 就可以单独运行，而不需要互相了解。Linux-VServer 通过修改 Linux 内核实现用户空间的隔离。</p>
<p>Linux-VServer 也使用了 chroot 来为每个 VPS 隔离 root 目录。虽然 chroot 允许指定新 root 目录，但还是需要其他一些功能（称为 Chroot-Barrier）来限制 VPS 脱离其隔离的 root 目录回到上级目录。给定一个隔离的 root 目录之后，每个 VPS 就可以拥有自己的用户列表和 root 密码。</p>
<p>2.4 和 2.6 版本的 Linux 内核支持 Linux-VServer，它可以运行于很多平台之上，包括 x86、x86-64、SPARC、MIPS、ARM 和 PowerPC。</p>
<h5 id="Virtuozzo-OpenVZ"><a href="#Virtuozzo-OpenVZ" class="headerlink" title="Virtuozzo/OpenVZ"></a>Virtuozzo/OpenVZ</h5><p>Virtuozzo是SWsoft公司（目前SWsoft已经改名为Parallels）的操作系统虚拟化软件的命名，Virtuozzo是商业解决方案，而OpenVZ是以Virtuozzo为基础的开源项目，它们采用的也是操作系统级虚拟化技术。OpenVZ 类似于 Linux-VServer，它通过对 Linux 内核进行补丁来提供虚拟化、隔离、资源管理和状态检查。每个 OpenVZ 容器都有一套隔离的文件系统、用户及用户组等。</p>
<h3 id="工业云"><a href="#工业云" class="headerlink" title="工业云"></a>工业云</h3><p>阿里云、腾讯云服务器采用的是KVM虚拟化解决方案，华为云服务器采用的是XEN虚拟化解决方案。</p>
<h3 id="技术对比"><a href="#技术对比" class="headerlink" title="技术对比"></a>技术对比</h3><h4 id="全虚拟化与半虚拟化"><a href="#全虚拟化与半虚拟化" class="headerlink" title="全虚拟化与半虚拟化"></a>全虚拟化与半虚拟化</h4><p>ring0是指CPU的运行级别，ring0是最高级别，ring1次之，ring2更次之……<br>        拿Linux+x86来说，操作系统（内核）的代码运行在最高运行级别ring0上，可以使用特权指令，控制中断、修改页表、访问设备等等。<br>        应用程序的代码运行在最低运行级别上ring3上，不能做受控操作。如果要做，比如要访问磁盘，写文件，那就要通过执行系统调用（函数），执行系统调用的时候，CPU的运行级别会发生从ring3到ring0的切换，并跳转到系统调用对应的内核代码位置执行，这样内核就为你完成了设备访问，完成之后再从ring0返回ring3。这个过程也称作用户态和内核态的切换。</p>
<p>​        那么，虚拟化在这里就遇到了一个难题，因为宿主操作系统是工作在ring0的，客户操作系统就不能也在ring0了，但是它不知道这一点，以前执行什么指令，现在还是执行什么指令，那肯定不行啊，没权限啊，玩不转啊。所以这时候虚拟机管理程序（VMM）就要避免这件事情发生。<br>（VMM在ring0上，一般以驱动程序的形式体现，驱动程序都是工作在ring0上，否则驱动不了设备）<br>一般是这样做，客户操作系统执行特权指令时，会触发异常（CPU机制，没权限的指令，触发异常），然后VMM捕获这个异常，在异常里面做翻译，模拟，最后返回到客户操作系统内，客户操作系统认为自己的特权指令工作正常，继续运行。但是这个性能损耗，就非常的大，你想想原来，简单的一条指令，执行完，了事，现在却要通过复杂的异常处理过程。</p>
<p>​        这时候半虚拟化就来了，半虚拟化的思想就是，让客户操作系统知道自己是在虚拟机上跑的，工作在非ring0状态，那么它原先在物理机上执行的一些特权指令，就会修改成其他方式，这种方式是可以和VMM约定好的，这就相当于，我通过修改代码把操作系统移植到一种新的架构上来，就是定制化。所以像XEN这种半虚拟化技术，客户机操作系统都是有一个专门的定制内核版本，和x86、mips、arm这些内核版本等价。这样以来，就不会有捕获异常、翻译、模拟的过程了，性能损耗非常低。这就是XEN这种半虚拟化架构的优势。这也是为什么XEN只支持虚拟化Linux，无法虚拟化windows原因，微软不改代码啊。</p>
<p>​        可以后来，CPU厂商，开始支持虚拟化了，情况有发生变化，拿X86 CPU来说，引入了Intel-VT 技术，支持Intel-VT 的CPU，有VMX root operation 和 VMX non-root operation两种模式，两种模式都支持Ring 0 ~ Ring 3 这 4 个运行级别。这下好了，VMM可以运行在VMX root operation模式下，客户OS运行在VMX non-root operation模式下。也就说，硬件这层做了些区分，这样全虚拟化下，有些靠“捕获异常-翻译-模拟”的实现就不需要了。而且CPU厂商，支持虚拟化的力度越来越大，靠硬件辅助的全虚拟化技术的性能逐渐逼近半虚拟化，再加上全虚拟化不需要修改客户操作系统这一优势，全虚拟化技术应该是未来的发展趋势。</p>
<p>​        XEN是最典型的半虚拟化，不过现在XEN也支持硬件辅助的全虚拟化，大趋势，拗不过啊。。。<br>KVM、VMARE这些一直都是全虚拟化。</p>
<h4 id="虚拟化与容器"><a href="#虚拟化与容器" class="headerlink" title="虚拟化与容器"></a>虚拟化与容器</h4><p><img src="/2020/11/27/virtualization-overview/virtualization-vs-containers.png" height="200px"></p>
<p>两者为互补关系：</p>
<ul>
<li><a href="https://www.redhat.com/zh/topics/virtualization" target="_blank" rel="noopener">虚拟化</a>使得操作系统（Windows 或 Linux）可同时在单个硬件系统上运行。</li>
<li>容器则可共享同一个操作系统内核，将应用进程与系统其他部分隔离开。例如：ARM Linux 系统运行 ARM Linux 容器，x86 Linux 系统运行 x86 Linux 容器，x86 Windows 系统运行 x86 Windows 容器。Linux 容器具有极佳的可移植性，但前提是它们必须与底层系统兼容。</li>
</ul>
<p>这意味着什么？虚拟化会使用虚拟机监控程序模拟硬件，从而使多个操作系统能够并行运行。但这不如容器轻便。事实上，在仅拥有容量有限的有限资源时，您需要能够可以进行密集部署的轻量级应用。Linux 容器在本机操作系统上运行，与所有容器共享该操作系统，因此应用和服务能够保持轻巧，并行化快速运行。</p>
<p>Linux 容器是我们开发、部署和管理应用方式的又一次飞跃。Linux 容器镜像提供了可移植性和版本控制，确保能够在开发人员的笔记本电脑上运行的应用，同样也能在生产环境中正常运行。相较于虚拟机，Linux 容器在运行时所占用的资源更少，使用的是标准接口（启动、停止、环境变量等），并会与应用隔离开；此外，作为（包含多个容器）大型应用的一部分时更加易于管理，而且这些多容器应用可以跨多个云环境进行编排。 [4]</p>
<h4 id="Xen-VS-KVM"><a href="#Xen-VS-KVM" class="headerlink" title="Xen VS KVM"></a>Xen VS KVM</h4><p><img src="/2020/11/27/virtualization-overview/xen-kvm.png" height="200"></p>
<h3 id="Xen分析"><a href="#Xen分析" class="headerlink" title="Xen分析"></a>Xen分析</h3><p><img src="/2020/11/27/virtualization-overview/Xen.png" height="200px"></p>
<h4 id="Xen-architecture"><a href="#Xen-architecture" class="headerlink" title="Xen architecture"></a>Xen architecture</h4><p>​        Xen是运行在裸机上的虚拟化管理程序（HyperVisor），是半虚拟化（Para-Virtualization）技术的典型代表。英文前缀“Para”直译为“侧”、“旁”、“近旁”的意思，“Para-Virtualization”可以理解为“在Guest VM旁边运行着的管理VM”，Xen称这个特别的VM为Dom0，虚拟机操作系统被称做DomU。管理VM负责管理整个硬件平台上的所有输入输出设备驱动，半虚拟化中的Hypervisor不对I/O设备作模拟，而仅仅对CPU和内存做模拟，这就是“Para-Virtualization”被翻译成“半虚拟化”的原因。半虚拟化还有一个叫法：操作系统辅助虚拟化（OS Assisted Virtualization），这是因为Guest VM自身不带设备驱动，需要向“管理VM”寻求帮助。这种虚拟化技术允许虚拟化操作系统感知到自己运行在XEN HyperVisor上而不是直接运行在硬件上，同时也可以识别出其他运行在相同环境中的虚拟机。</p>
<p><img src="/2020/11/27/virtualization-overview/Xen-architecture.png" height="260"></p>
<h4 id="Dom0-与-Hypervisor"><a href="#Dom0-与-Hypervisor" class="headerlink" title="Dom0 与 Hypervisor"></a>Dom0 与 Hypervisor</h4><p>​        Dom0是Xen虚拟机管理程序在启动时启动的初始域。 Dom0是“域0”（Domain 0）的缩写（有时写为“域零”或“主机域”）。 Dom0是一个特权域，该特权域首先启动并管理DomU非特权域。如果没有Dom0，则无法使用Xen虚拟机管理程序。本质上，这是“主机”操作系统（或者，如果愿意，可以是“服务控制台”）。结果，Dom0运行Xen管理工具堆栈，并具有特殊的特权，例如能够直接访问硬件。Dom0具有用于硬件的驱动程序，它为来宾（分别称为domU（非特权域））提供Xen虚拟磁盘和网络访问。对于可用于其他域的硬件（例如网络接口和磁盘），它将运行BackendDriver，该驱动程序将多路复用并转发到每个DomU中来自FrontendDriver的硬件请求。</p>
<p>​        简言之，Xen为了精简自身VMM的代码量以及需要管理的任务，将非必须的操作转移到Dom0上进行。在部署Xen虚拟机的OS上，其OS称为Dom0，用于创建、管理、销毁客户虚拟机。Dom0可以看做是被Xen虚拟出来的一个具有特权级别的虚拟机。</p>
<p><img src="/2020/11/27/virtualization-overview/Xen-Ring.png" height="300"></p>
<h4 id="Hypercall"><a href="#Hypercall" class="headerlink" title="Hypercall"></a>Hypercall</h4><p>​        在之前的博文中提到过增加<code>Hypercall</code>的具体技术细节，这里主要讲一下提供给用户的<code>Hypercall</code>接口。</p>
<p>​        <code>Hypercall</code>与 OS中的系统调用类似，调用时权限由<code>Ring3</code> 变为<code>Ring0</code>。在<code>Xen</code>的虚拟化环境中，从<code>Guest OS</code>的<code>Ring 1</code>（特权级）到 <code>Xen</code>的<code>Ring 0</code>的跳转等同于<code>Linux</code>系统中的系统调用，其提供的特权操作，采用的是 <code>int $0x82</code> 软中断。<code>Xen</code>同时在<code>Ring 3</code>的应用程序提供了调用<code>Hypercall</code>的接口，即<code>privcmd</code> 驱动程序，这需要<code>Linux ioctl</code> 系统调用的支持。</p>
<h3 id="Xen攻击"><a href="#Xen攻击" class="headerlink" title="Xen攻击"></a>Xen攻击</h3><p>【后面增加对Xen的细节分析，暂时先放在这里】</p>
<h4 id="恶意Hypervisor"><a href="#恶意Hypervisor" class="headerlink" title="恶意Hypervisor"></a>恶意Hypervisor</h4><p>​        BLUEPILL和Vitriol都是比较流行的软件项目，可以在运行时给系统安装上恶意的hypervisor（系统管理程序）。原本系统是纯净的，什么都没有，但是这些软件可以即时的向系统中插入一段恶意代码，不需要重启就可以取得操作系统的控制权。很多安全分析人员都预言，在不久的将来， 很多系统都将默认的构建在一些hypervisor之上，这给攻击者带来了很多机会，但同时也是挑战。</p>
<h4 id="渗透"><a href="#渗透" class="headerlink" title="渗透"></a>渗透</h4><p>​        如果渗透进入合法的hypervisor，修改了其代码，也可以达到BLUEPILL和Vitriol相类似的效果。不过还有优点的是，在合法的 hypervisor中无需再像恶意的hypervisor一样隐藏所有的副作用痕迹，它们都可以归为合法hypervisor正常执行的操作范围之内。 除此之外，合法系统几乎提供了所有的底层功能，减轻了攻击者的代码劳动负担，直接使用即可。</p>
<h4 id="进入特权级别"><a href="#进入特权级别" class="headerlink" title="进入特权级别"></a>进入特权级别</h4><p>官网公布的漏洞 <a href="http://xenbits.xen.org/xsa/advisory-105.html" target="_blank" rel="noopener"> XSA-105</a>  可以实现从Ring3 到 Ring0 [2] 的权限升级。</p>
<h4 id="Xen-自我保护"><a href="#Xen-自我保护" class="headerlink" title="Xen 自我保护"></a>Xen 自我保护</h4><p>​        在某些体系结构下，hypervisor实行了自我保护，防止运行时外界对自身代码的篡改，即使攻击者获得了OS的最高特权，也不见得行得通。例如 Xen的例子，即使在dom0域下获得了管理员权限，也无法于运行时修改其代码，所以Xen 认为被入侵的重要标志是Hypervisor的重启。(但是不一定保证所有的入侵均不会在运行时修改代码)</p>
<h3 id="References"><a href="#References" class="headerlink" title="References"></a>References</h3><p>[1] <a href="https://github.com/hardenedlinux/grsecurity-101-tutorials/blob/master/virt_security.md" target="_blank" rel="noopener">https://github.com/hardenedlinux/grsecurity-101-tutorials/blob/master/virt_security.md</a></p>
<p>[2] <a href="https://labs.bitdefender.com/wp-content/uploads/downloads/2014/10/Gaining-kernel-privileges-using-the-Xen-emulator.pdf" target="_blank" rel="noopener">https://labs.bitdefender.com/wp-content/uploads/downloads/2014/10/Gaining-kernel-privileges-using-the-Xen-emulator.pdf</a></p>
<p>[3] <a href="https://blog.csdn.net/mumuriyue/article/details/85714900" target="_blank" rel="noopener">https://blog.csdn.net/mumuriyue/article/details/85714900</a></p>
<p>[4] <a href="https://www.redhat.com/zh/topics/containers/whats-a-linux-container" target="_blank" rel="noopener">https://www.redhat.com/zh/topics/containers/whats-a-linux-container</a></p>
]]></content>
      <tags>
        <tag>xen</tag>
        <tag>virtualization</tag>
      </tags>
  </entry>
  <entry>
    <title>Optimization of Serverless</title>
    <url>/2021/06/30/Optimization-of-Serverless/</url>
    <content><![CDATA[<h2 id="abstract"><a href="#abstract" class="headerlink" title="abstract"></a>abstract</h2><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">序号</th>
<th style="text-align:left">属性</th>
<th style="text-align:center">内容</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:left">原文PDF</td>
<td style="text-align:center"><a href="https://asplos-conference.org/2021/abstracts/asplos21-paper212-extended_abstract.pdf" target="_blank" rel="noopener">paper</a> <a href="https://mykrobin.github.io/files/docs/vHive-asplos21.pdf">slides</a></td>
</tr>
<tr>
<td style="text-align:center">2</td>
<td style="text-align:left">作者信息</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">3</td>
<td style="text-align:left">核心内容</td>
<td style="text-align:center">优化serverless服务的冷启动响应时间</td>
</tr>
<tr>
<td style="text-align:center">4</td>
<td style="text-align:left">研究领域</td>
<td style="text-align:center">Serverless</td>
</tr>
<tr>
<td style="text-align:center">5</td>
<td style="text-align:left">全文总览</td>
</tr>
</tbody>
</table>
</div>
<h2 id="总览"><a href="#总览" class="headerlink" title="总览"></a>总览</h2>]]></content>
      <categories>
        <category>ASPLOS</category>
      </categories>
      <tags>
        <tag>TODO</tag>
        <tag>论文解读</tag>
        <tag>Storage</tag>
      </tags>
  </entry>
</search>
